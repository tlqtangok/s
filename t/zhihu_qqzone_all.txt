人工智能的一些思考
一切都是为了数据数据在人工智能中处于中心地位。所有的公司都想方设法获利数据，然后进行大数据分析，以得出用户画像，给便提供个性化的服务（或者作恶），如航空公司的价格歧视。隐私问题或无解。

大数据可以使得智能算法更趋向精确，避免黑天鹅。简单的建模往往更适合机器。机器将比人类更有效益，最终在大部分岗位上取代人类。人在机器面前将失去尊严。


很多需要艰苦卓绝的工作将变得更加轻松，如律师和高级医师，也将面临低级岗位被机器取代。被取代而消失的岗位不会被创造，一两代人的牺牲才能换得世界的稳定。努力成为2%。

医疗难题如癌症或将有解，可以利用人工智能提供差异化的药物，穷举所有的可能。

2017-4-10　22:19





?

?写文章
?




nodejs_dep_cluster_product

jdtangjdtang・
2 个月前2017 年 4月 5 日星期三中午 11 点 35 分


*********************
scews_test.js
*********************
#!node
/*
 * requirements:
 *   - node.js version > = v7.6.0
 *      on Linux, just copy /slowfs/us01dwt2p448/linqi/archiver/node-v7.6.0-linux-x64 to somewhere, and
 *         add the node's "bin" to path. if node.js updates

 *   - dep.js           : have some basic library functions. Very easy to understand!
 *      R(0,3)          : will return 0,1,2, but R(11,13) will return 11-11,12-11, says 0,1 ;
 *      print           : is just a alias for console.log()
 *      count_arc_info( big_str, target_list)   : return obj that contain the numbers for all target in list
 *         sleep_sync_sec(1.3)  : sleep 1.3 seconds

 * short readme
 *  target_list sensitive word-list,
 *  arr_cmd is cmd you will run
 *  this program will create many slave threads  in master CPU ,
 *  based the numbers of cmd arr, and run in parallel , after
 *  finishing, return the data to the master CPU.
 *  master CPU will deal with the data, and then give out the cmd that
 *  has rebrand issue.
 *  [
 *    written by Jidor Tang<linqi@SNPSCOM> || 2017-3-2
 *  ]
 */


//*** program start here ***
var fs = require("fs");
var execFileSync = require("child_process").execFileSync;
var execSync = require("child_process").execSync;
require("../lib/dep.js");    // utils => R(5) print() sleep_sync_sec() count_arc_info()
/*** sub list ***/


var split_arr_by_quato_to_file_then_run = function(arr,quato){

        var cmd_bin  = "node scews_test.js";   // if > quato , need split , then run each split file
        var split_number_total= Math.floor(arr.length/quato) + 1;

        //      print ( "split_number_total:", split_number_total );

        var i = 0;


        for ( i=0;i<split_number_total; i++ ){
                var filename_each = "cq_"+i+".txt" ;
                if ( i == (split_number_total-1) ){
                        fs.writeFileSync ( filename_each,   arr.slice(i*quato).join("\n") );
                }
                else {
                        fs.writeFileSync ( filename_each,  arr.slice(i*quato,(i+1)*quato).join("\n") );
                }
                var output = execSync( cmd_bin  + " "+  filename_each  );
                print (output.toString());
                fs.unlinkSync(filename_each);

        }

        return split_number_total;

}

// *** global var ***

const quato = 1000;
var arr_cmd = [];
const expect_argv_len = 3 ;
process.argv.length != expect_argv_len &&  ( arr_cmd = read_config_file_sync( "../config/cmd_queue.txt" ) ) ;
process.argv.length == expect_argv_len &&  ( arr_cmd = read_config_file_sync( process.argv[2] ) );   // argv[2] is cmd_queue.txt file



if ( arr_cmd.length > quato ){

        var split_file_num = split_arr_by_quato_to_file_then_run( arr_cmd, quato );
        process.exit(1);
}

//print ( arr_cmd_test );
var target_list = [];
target_list = read_config_file_sync( "../config/target_list.txt" )  ;
const ignore_list  = [ "archive","search", "system","memory", "ARChitect" , "character"];
const IF_PRINT_OUTPUT = 0 ;   // to see what is rebrand lines... , one can set it to 1 and redirect output to a file...

// *** end global var ***



var cluster = require("cluster");
var exec = require("child_process").exec;
var execSync= require("child_process").execSync;
var spawnSync= require("child_process").spawnSync;




if ( cluster.isMaster ){

        let exit_worker_cnt = 0;   // cnt the exited workers
        let time_used= `\n\n### All ${arr_cmd.length} Cluster.workers end. Time Spend: `;
        console.time( time_used );    // cnt time used

        {
                print ( "# test againist  "+ target_list.length+ " numbers of ARC info");
                var target_list_showout = target_list.map((v)=>{return "  "+v+"\n";});
                print ( target_list_showout.join("") );
                print ( "" );
        }
        {
                print ( "# test on these "+ arr_cmd.length+ " commands");
                var arr_cmd_showout = arr_cmd.map((v)=>{return "  "+v+"\n";});
                print ( arr_cmd_showout.join("") );
                print ( "\n### TEST FAILED ON THESE COMMANDS ###" );
        }


        for ( let i of arr_cmd ){   cluster.fork();   }

        for ( let i in cluster.workers ){

                cluster.workers[i].on('message', (msg) => {
                                //print ( msg );
                                var obj_msg = JSON.parse(msg);
                                let ans = [];
                                let cmd = obj_msg["cmd"];
                                let err_code = obj_msg["err_code"];  //print (err_code);
                                let stdout = obj_msg["stdout"];
                                let stderr = obj_msg["stderr"];

                                ans.push("cmd: ",cmd, "err_code: ",err_code,"stdout: ",stdout, "stderr: ",stderr);
                                //print ( ans.toString() );

                                obj_cnt  = count_arc_info( ans.toString(), target_list ) ;   // get { ARC:0 ===> DETAILS :xxxx: :yy: :zz: }
                                var cnt_zero_num = 0;
                                var cnt_all_ele = 0;

                                for ( let k in obj_cnt ) {
                                obj_cnt[k].toString()[0]-0 == 0 && cnt_zero_num++;   // no number,but we need numbers! so deconstruct str to numbers
                                cnt_all_ele++;
                                }
                                if ( cnt_zero_num != cnt_all_ele ){
                                        print (  `\ncmd : ${cmd}` ); //print ( obj_cnt );

                                        for( let i in obj_cnt ){
                                                if ( obj_cnt[i].toString()[0]-0 != 0 ){
                                                        print ( ' - '+ i + ': ' + obj_cnt[i] );
                                                }
                                        }


                                        IF_PRINT_OUTPUT && print ( ans );  // output all message to see where has ARC info
                                }
                } );



                cluster.workers[i].on('exit', (err) => {
                                let ii = i-1;

                                exit_worker_cnt++;

                                if (exit_worker_cnt == arr_cmd.length ) {
                                        console.timeEnd(time_used);    // cnt time used
                                }



                                IF_PRINT_OUTPUT && console.error( `- closing ${ii} ...` );
                                } );
        }
}  // end if Master
else {
        let id = cluster.worker.id - 1 ;
        //print (id-1);

        let cmd_ = arr_cmd[id];
        //print ( arr_cmd[id] );

        var t_id = exec( cmd_,  (err, stdout, stderr) => {
                        //console.log ( ` (err => ${err}, stdout=>${stdout}, stderr=>${stderr}) `);
                        var err_code = (err? err.code:0);  // err_code
                        var stdout_1 = stdout.toString();
                        var stderr_2 = stderr.toString();
                        stdout_1 =stdout_1.replace(/(\\r)?\\n/g, " " );  // no LR
                        stdout_1 =stdout_1.replace(/\s+/g," ");
                        stderr_2 =stderr_2.replace(/(\\r)?\\n/g, " " );  // no LR
                        stderr_2 =stderr_2.replace(/\s+/g," ");
                        var arr_msg = { cmd: cmd_, err_code: err_code , stdout: stdout_1, stderr: stderr_2 };   // assemble to objects

                        var to_send = JSON.stringify(arr_msg);  // no LR
                        to_send = do_ignore_some_str( to_send, ignore_list );

                        process.send ( to_send );
                        setTimeout( () => process.exit(0),  1 ) ;
                        }  // end cb of exec ()
                        );   // end exec
}






/*** END ***/












*********************
../lib/dep.js
*********************
#!node
// written by Jidor Tang<linqi@SNPSCOM> 20170302
//
//
//### sub list ###


var fs = require("fs");
const range0_1000=Buffer.allocUnsafe(1000);


var range0_N= function(){
        // range0_N()  range0_N(3) ;  range0_N(0,9)
        //const range0_1000=Buffer.allocUnsafe(200);
        //for(let i =0;i<100;i++) range0_1000[i]=i;
        var pre=0;
        var next = 0;
        //print(arguments);

        if ( arguments.length == 2 ){
                pre=new Number(arguments[0]);
                next=new Number(arguments[1]);

        }

        else if ( arguments.length == 1 ){
                pre=0;
                next=new Number(arguments[0]);
        }
        else {
                pre=0;
                next=new Number(range0_1000.length);
        }

        if ( next > range0_1000.length ){
                next = range0_1000.length;
                print ( "- N will be "+ range0_1000.length);
        }

        return range0_1000.slice(pre,next);
}


//console.time("---time---");
var print = console.log;
var sleep_sync_sec = function(){
        var x = arguments[0];
        if (arguments.length == 2 ) {
                print ( `- sleep ${x} seconds ...`);
        }
        x= arguments[0];
        var WINDIR = process.env["WINDIR"];
        var exec_sync = require("child_process").execSync;
        // sleep for windows, see: https://zhuanlan.zhihu.com/p/25412671 or see $perl_p
        WINDIR && exec_sync( ` sleep ${x}s  ` );
        //var sleep_second = (x-222) / 1000 *1.000 ;
        //if ( x <=222 ) {sleep_second=0;}
        WINDIR || exec_sync( ` sleep ${sleep_second}s ` );
}


var R = range0_N ;





var count_one_string= (big_str, sub_str)=> {
        if ( big_str.length < sub_str.length ){
                //print ("- error, big_str len < sub_str len");
                return 0;
        }
        var  MAX_INT = 0x12345 ;
        var EOF_ = -1 ;
        var loc = MAX_INT;
        var count= 0 ;
        var trunc_word_bord = 22 ;   // grep out the words left , and right info
        var word_of_bord = "";
        var arr_word_bord_all = [];

        var loc_L=0; var loc_R=0;
        while ( 1 ){
                loc = big_str.indexOf( sub_str );
                if ( loc == EOF_ ){break; }
                //print ( "- loc is :"); print ( loc );
                //
                loc_L = loc-trunc_word_bord;
                loc_R = loc+trunc_word_bord;
                if ( loc_L <=0 ){
                        loc_L=0;
                }
                if ( loc_R >= big_str.length ){
                        loc_R = 0;
                }

                word_of_bord = big_str.substr( loc_L, loc_R-loc_L );

                arr_word_bord_all.push( `\t: ${word_of_bord} :` );


                count++;
                var new_str_head = loc+sub_str.length;
                if ( new_str_head >=  big_str.length ){break; }
                big_str=  big_str.substr(loc+sub_str.length, big_str.length)
                        //print ( "- new big_str is :");
                        //print ( big_str );
                        //print ("");
        }

        // the matched lines and its context , and its numbers
        return [count, arr_word_bord_all]  ;
}


var count_arc_info = function (big_str, target_list){
        if ( typeof 'string' != typeof big_str ){
                print ("- error count_target_str_num(): big_str is not string ");
                process.exit( 1 );
        }
        if ( typeof [] != typeof target_list ){
                print ("- error count_target_str_num(): target_list is not object ");
                process.exit( 1 );
        }

        var ret_obj = {};

        var index = 0;
        var details_line_info = []; // contains info of the matched lines
        var cnt_idx0 = 0;
        while( index < target_list.length ){
                [cnt_idx0, details_line_info] = count_one_string (big_str, target_list[index] ) ;
                if ( cnt_idx0==0 ){
                        details_line_info = [""];
                }
                // now , no number!!! need deconstruct the Str[0]
                ret_obj[ target_list[index] ] = cnt_idx0 + " ===> DETAILS\n" + details_line_info.join("\n") + "\n";
                index++;
        }

        return ret_obj;
}


var read_config_file_sync= (filename)=>{
        // read file content and chomp the \n , and return arr
        var ret_arr = [];
        var stdout_bf = fs.readFileSync( filename );
        var arr_cmd = stdout_bf.toString().split(/\r?\n/);
        ret_arr = arr_cmd.filter( ($_)=>    { return ( $_.match(/^\#/) || !($_) ) ? 0:1; } );
        ret_arr = ret_arr.map ( ($_) => {return $_.replace(/(\w)\s*$/,"$1") } );   // strip space in the tail
        return ret_arr ;
};



var do_ignore_some_str = function(big_str, ignore_list){
        var return_str = big_str;
        for ( let i in ignore_list ){
                var regex_t = new RegExp(`${ignore_list[i]}`, "gi");
                return_str = return_str.replace(  regex_t , `ignore_list[${i}]` );
        }
        return return_str;
}


// ### end lib ###
exports = module.exports = app = {};

app.R= R;
app.print = print ;
app.sleep_sync_sec = sleep_sync_sec;
app.count_arc_info = count_arc_info;
app.read_config_file_sync = read_config_file_sync;
app.do_ignore_some_str = do_ignore_some_str;

Object.keys(app).forEach(function (cmd) {
                global[cmd] = app[cmd];
                });



EOF




Node.js


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论






?

?写文章
?




tf_oop_c_k_h_k_cnn

jdtangjdtang・
2 个月前2017 年 4月 4 日星期二晚上 8 点 58 分


import math
from tensorflow.examples.tutorials.mnist import input_data
import tensorflow as tf

mnist = input_data.read_data_sets( "MNIST_data/",one_hot=True)





sess = tf.InteractiveSession()


        
def create_x_y_W1_b1_W2_b2_by_h1( x_dim, y_dim, h1_dim, keep_prob=0.75 ):
    x = tf.placeholder( tf.float32, [None,x_dim] )
    y = tf.placeholder( tf.float32, [None,y_dim] )
    W1  = tf.Variable( tf.truncated_normal( [x_dim,h1_dim ],  stddev=0.1 ) )
    b1 = tf.Variable( tf.zeros( [ h1_dim ] ) )
    W2 = tf.Variable( tf.truncated_normal( [h1_dim, y_dim ],  stddev=0.1 ) )
    b2 = tf.Variable( tf.zeros( [ y_dim ] ) ) 
    y_ = via_h1_cal_y_(x,W1,b1,keep_prob, W2,b2)
    return [ x, y, W1,b1, W2,b2,y_]

class ML(object):
    def __init__(self, x_dim ,y_dim ,OBJ_ML_CONST):
        
        x = tf.placeholder( tf.float32, [None,x_dim] )
        y = tf.placeholder( tf.float32, [None,y_dim] )
        keep_prob = tf.placeholder(tf.float32)
        
        sz = int ( math.sqrt( float( x_dim ) )  ) 
        
        img = tf.reshape(x, [-1,sz,sz,1])
        self.x = x
        self.y = y
        self.img = img 
        # OBJ_ML_CONST
        self.lr = OBJ_ML_CONST["lr"]
        self.iter_times = OBJ_ML_CONST["iter_times"]
        self.batch_size = OBJ_ML_CONST["batch_size"]
        self.keep_prob_rate = OBJ_ML_CONST["keep_prob_rate"]
        self.accu_percent = OBJ_ML_CONST["accu_percent"]
        self.id_train = OBJ_ML_CONST["id_train"]
        
        self.flat_ele = "FLAT_ELE INIT"
        self.keep_prob = keep_prob 

    
    def say(self):
        print ("- self.x: ", self.x)
        print ("- self.y: ", self.y)
        print ("- self.img: ", self.img)
        
        print("- self.lr: %.2f" % self.lr)
        print("- self.iter_times: ", self.iter_times)
        print("- self.batch_size: ", self.batch_size)
        print("- self.keep_prob_rate: ", self.keep_prob_rate)
        
        print("- self.accu_percent: ", self.accu_percent)
        print ("- self.id_train: ", self.id_train)
        return self
        
    

    def tf_w_b_by_k(self, k ):
        w_ = tf.truncated_normal(k, stddev=0.1)
        w = tf.Variable(w_)
        b_ = tf.constant(0.1, shape=k[-1:])
        b = tf.Variable(b_)
        return [w,b]
    
    def conv2d_by_k( self, k, act_fun="relu" ):
        [w,b] = self.tf_w_b_by_k(k)
        id_conv_ = tf.nn.conv2d(self.img,w, strides=[1,1,1,1], padding='SAME')
        id_conv = tf.nn.relu( id_conv_ + b )
        self.img = id_conv 
        return self
    
    
    def pool_2x2(self):
        id_p = tf.nn.max_pool( self.img, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME' )
        self.img = id_p
        return self

    def cal_w_b_by_k(self, k, act_fun="relu"):
        [w,b] = self.tf_w_b_by_k(k)
        h_ = tf.matmul(self.img, w) + b
        if act_fun == "relu" :
            h = tf.nn.relu(h_)
            self.img = h 
            return self
        if act_fun == "softmax" :
            h = tf.nn.softmax(h_)
            self.img = h 
            return self
        raise  ValueError('- act_fun is "relu" or "softmax"! ')
    
   
        
    def tf_dropout(self, keep_prob_):
        #keep_prob is NOT a number
        hh = tf.nn.dropout(self.img, keep_prob_)
        self.img = hh 
        return self
    
    def loss_fun(self,str_type="entropy"):
        a_y = self.y
        a_y_ = self.img        
        if str_type == "entropy":
            loss = tf.reduce_mean( -1*tf.reduce_sum( a_y*tf.log(a_y_) , reduction_indices=[1] ) )
            self.loss = loss
            #return tf.reduce_mean( -1*tf.reduce_sum( y*tf.log(y_) , reduction_indices=[1] ) )
        else:
            raise  ValueError('- only entropy can be used!')
    

    def set_train_args(self):
        if self.loss == "LOSS INIT":
            raise  ValueError('- please set loss func')
        else:
            id_train = tf.train.AdamOptimizer(self.lr).minimize(self.loss)
            self.id_train = id_train
            return id_train

    def cal_accu_percent(self):
        a_y = self.y
        a_y_ = self.img
        vec_0_1 = tf.equal (tf.argmax(a_y,1),tf.argmax(a_y_,1)) 
        accu_percent = tf.reduce_mean( tf.cast(vec_0_1,tf.float32) )
        self.accu_percent = accu_percent
        return self.accu_percent


    def start_train_loop(self):
        tf.global_variables_initializer().run()
        
        for i in range(self.iter_times):
            #s_i = np.random.randint(0,x_data.shape[0]-batch_size)
            #bd_0 =  np.reshape( x_data[s_i:s_i+batch_size,:], [batch_size,2] )
            #bd_1 =  np.reshape( y_data[s_i:s_i+batch_size,:], [batch_size,2] )
            if self.accu_percent == "ACCU_PERCENT INIT":
                raise  ValueError('- please set accu_percent : cal_accu_percent(y,y_)')
             
            batch = mnist.train.next_batch(self.batch_size)
            bd_0 = batch[0]
            bd_1 = batch[1]
            
            if self.id_train == "ID_TRAIN INIT":
                raise  ValueError('- please set id_train : set_train_args()')
            
            if i%100 == 0:
                a_rate_e = self.accu_percent.eval( feed_dict = {self.x:bd_0, self.y:bd_1, self.keep_prob: 1.0} )  # y_ and y
                print ("- train %d, accuracy: %g" %(i,a_rate_e))
                pass
            self.id_train.run( feed_dict = {self.x:bd_0, self.y:bd_1, self.keep_prob: self.keep_prob_rate } ) 
        feed_content = {self.x:mnist.test.images,self.y:mnist.test.labels,self.keep_prob:1.0}
        print ("- the test accuracy %g " % self.accu_percent.eval( feed_dict=feed_content ))
        return self
        
    @property
    def flat(self):
        #self.img
        shape_line_list = self.img.shape[1:]
        type(shape_line_list)
        print (shape_line_list)
        shape_mul = 1
        for i in shape_line_list:
            #print ( int(i)+111 )
            shape_mul = shape_mul*int(i)
        shape_of_k = [-1, shape_mul ]
        img = tf.reshape( self.img, shape_of_k )
        self.img = img
        self.flat_ele = shape_mul 
        return self.img 
     

"""

(None,28*28)  : din , x 
(None, 28*28).reshape = (28,28,1) : .reshape
(28,28,1,1)*[5,5,1,32] = (28,28,32,1)  : c1
(28,28,32,1)./2 = (14,14,32,1)  : p1
(14,14,32,1)*[5,5,32,64]= (14,14,64,1)  : c2
(14,14,64,1)./2 = (7,7,64,1)  : p2
(7,7,64,1).reshape = (1,7*7*64)  : .reshape
(1,7*7*64)x[7*7*64,1024] = (1,1024) : h1
(1,1024).dropout = (1,1024)  : .dropout
(1,1024) x [1024,10] = (1,10)  : dout_ , y_

"""
OBJ_ML_CONST={
"lr": 1e-4,
"iter_times": 100,
"batch_size": 50,
"keep_prob_rate": 0.511 ,
"loss": "LOSS INIT" , 
"accu_percent": "ACCU_PERCENT INIT" , 
"id_train": "ID_TRAIN INIT" , 
}




x_dim = 28*28
y_dim = 10

ml = ML( x_dim ,y_dim ,OBJ_ML_CONST )

ml.c = ml.conv2d_by_k
ml.p = ml.pool_2x2
ml.cal = ml.cal_w_b_by_k
ml.dropout=ml.tf_dropout




k1=[5,5,1,32]
ml.conv2d_by_k( k1, act_fun="relu" )
ml.pool_2x2()

k2=[5,5,32,64]
ml.conv2d_by_k(k2, act_fun="relu")
ml.pool_2x2()

#print ( ml.img )
ml.flat

h_in_k = [ml.flat_ele, 1024]
ml.cal_w_b_by_k(h_in_k, act_fun="relu")

ml.tf_dropout( ml.keep_prob )

h_out_k = [1024,10]
ml.cal_w_b_by_k(h_out_k, act_fun="softmax")

y_ = ml.img 

ml.loss_fun()
ml.cal_accu_percent()  # self.accu_percent
ml.set_train_args()

ml.say()


print ("- start trainning process")

ml.start_train_loop()

"""
k1=[5,5,1,32]
k2=[5,5,32,64]

ml.c(k1).p().c(k2).p()
h_in_k = [ml.flat_ele, 1024]
ml.cal(h_in_k).dropout(h_in_k)
"""


""" output 
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
(7, 7, 64)
('- self.x: ', <tf.Tensor 'Placeholder_3:0' shape=(?, 784) dtype=float32>)
('- self.y: ', <tf.Tensor 'Placeholder_4:0' shape=(?, 10) dtype=float32>)
('- self.img: ', <tf.Tensor 'Softmax_1:0' shape=(?, 10) dtype=float32>)
- self.lr: 0.00
('- self.iter_times: ', 100)
('- self.batch_size: ', 50)
('- self.keep_prob_rate: ', 0.511)
('- self.accu_percent: ', <tf.Tensor 'Mean_3:0' shape=() dtype=float32>)
('- self.id_train: ', <tf.Operation 'Adam_1' type=NoOp>)
- start trainning process
- train 0, accuracy: 0.06
- the test accuracy 0.8054 
...

- 0.9911111
'\nk1=[5,5,1,32]\nk2=[5,5,32,64]\n\nml.c(k1).p().c(k2).p()\nh_in_k = [ml.flat_ele, 1024]\nml.cal(h_in_k).dropout(h_in_k)\n'
"""
        
        




卷积神经网络（CNN）


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




python_x_lenet_conv_p1_h1_y_

jdtangjdtang・
2 个月前2017 年 4月 1 日星期六下午 2 点 25 分


import math
from tensorflow.examples.tutorials.mnist import input_data
import tensorflow as tf

mnist = input_data.read_data_sets( "MNIST_data/",one_hot=True)

sess = tf.InteractiveSession()


        
def create_x_y_W1_b1_W2_b2_by_h1( x_dim, y_dim, h1_dim, keep_prob=0.75 ):
    x = tf.placeholder( tf.float32, [None,x_dim] )
    y = tf.placeholder( tf.float32, [None,y_dim] )
    W1  = tf.Variable( tf.truncated_normal( [x_dim,h1_dim ],  stddev=0.1 ) )
    b1 = tf.Variable( tf.zeros( [ h1_dim ] ) )
    W2 = tf.Variable( tf.truncated_normal( [h1_dim, y_dim ],  stddev=0.1 ) )
    b2 = tf.Variable( tf.zeros( [ y_dim ] ) ) 
    y_ = via_h1_cal_y_(x,W1,b1,keep_prob, W2,b2)
    return [ x, y, W1,b1, W2,b2,y_]

class ML(object):
    def __init__(self, x_dim ,y_dim ,OBJ_ML_CONST):
        
        x = tf.placeholder( tf.float32, [None,x_dim] )
        y = tf.placeholder( tf.float32, [None,y_dim] )
        keep_prob = tf.placeholder(tf.float32)
        
        sz = int ( math.sqrt( float( x_dim ) )  ) 
        
        img = tf.reshape(x, [-1,sz,sz,1])
        self.x = x
        self.y = y
        self.img = img 
        # OBJ_ML_CONST
        self.lr = OBJ_ML_CONST["lr"]
        self.iter_times = OBJ_ML_CONST["iter_times"]
        self.batch_size = OBJ_ML_CONST["batch_size"]
        self.keep_prob_rate = OBJ_ML_CONST["keep_prob_rate"]
        self.accu_percent = OBJ_ML_CONST["accu_percent"]
        self.id_train = OBJ_ML_CONST["id_train"]
        
        self.flat_ele = "FLAT_ELE INIT"
        self.keep_prob = keep_prob 

    
    def say(self):
        print ("- self.x: ", self.x)
        print ("- self.y: ", self.y)
        print ("- self.img: ", self.img)
        
        print("- self.lr: %.2f" % self.lr)
        print("- self.iter_times: ", self.iter_times)
        print("- self.batch_size: ", self.batch_size)
        print("- self.keep_prob_rate: ", self.keep_prob_rate)
        
        print("- self.accu_percent: ", self.accu_percent)
        print ("- self.id_train: ", self.id_train)
        return self
        
    

    def tf_w_b_by_k(self, k ):
        w_ = tf.truncated_normal(k, stddev=0.1)
        w = tf.Variable(w_)
        b_ = tf.constant(0.1, shape=k[-1:])
        b = tf.Variable(b_)
        return [w,b]
    
    def conv2d_by_k( self, k, act_fun="relu" ):
        [w,b] = self.tf_w_b_by_k(k)
        id_conv_ = tf.nn.conv2d(self.img,w, strides=[1,1,1,1], padding='SAME')
        id_conv = tf.nn.relu( id_conv_ + b )
        self.img = id_conv 
        return self
    
    def pool_2x2(self):
        id_p = tf.nn.max_pool( self.img, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME' )
        self.img = id_p
        return self

    def cal_w_b_by_k(self, k, act_fun="relu"):
        [w,b] = self.tf_w_b_by_k(k)
        h_ = tf.matmul(self.img, w) + b
        if act_fun == "relu" :
            h = tf.nn.relu(h_)
            self.img = h 
            return self
        if act_fun == "softmax" :
            h = tf.nn.softmax(h_)
            self.img = h 
            return self
        raise  ValueError('- act_fun is "relu" or "softmax"! ')
    
   
        
    def tf_dropout(self, keep_prob_):
        #keep_prob is NOT a number
        hh = tf.nn.dropout(self.img, keep_prob_)
        self.img = hh 
        return self
    
    def loss_fun(self,str_type="entropy"):
        a_y = self.y
        a_y_ = self.img        
        if str_type == "entropy":
            loss = tf.reduce_mean( -1*tf.reduce_sum( a_y*tf.log(a_y_) , reduction_indices=[1] ) )
            self.loss = loss
            #return tf.reduce_mean( -1*tf.reduce_sum( y*tf.log(y_) , reduction_indices=[1] ) )
        else:
            raise  ValueError('- only entropy can be used!')
    

    def set_train_args(self):
        if self.loss == "LOSS INIT":
            raise  ValueError('- please set loss func')
        else:
            id_train = tf.train.AdamOptimizer(self.lr).minimize(self.loss)
            self.id_train = id_train
            return id_train

    def cal_accu_percent(self):
        a_y = self.y
        a_y_ = self.img
        vec_0_1 = tf.equal (tf.argmax(a_y,1),tf.argmax(a_y_,1)) 
        accu_percent = tf.reduce_mean( tf.cast(vec_0_1,tf.float32) )
        self.accu_percent = accu_percent
        return self.accu_percent


    def start_train_loop(self):
        tf.global_variables_initializer().run()
        
        for i in range(self.iter_times):
            #s_i = np.random.randint(0,x_data.shape[0]-batch_size)
            #bd_0 =  np.reshape( x_data[s_i:s_i+batch_size,:], [batch_size,2] )
            #bd_1 =  np.reshape( y_data[s_i:s_i+batch_size,:], [batch_size,2] )
            if self.accu_percent == "ACCU_PERCENT INIT":
                raise  ValueError('- please set accu_percent : cal_accu_percent(y,y_)')
             
            batch = mnist.train.next_batch(self.batch_size)
            bd_0 = batch[0]
            bd_1 = batch[1]
            
            if self.id_train == "ID_TRAIN INIT":
                raise  ValueError('- please set id_train : set_train_args()')
            
            if i%100 == 0:
                a_rate_e = self.accu_percent.eval( feed_dict = {self.x:bd_0, self.y:bd_1, self.keep_prob: 1.0} )  # y_ and y
                print ("- train %d, accuracy: %g" %(i,a_rate_e))
                pass
            self.id_train.run( feed_dict = {self.x:bd_0, self.y:bd_1, self.keep_prob: self.keep_prob_rate } ) 
        feed_content = {self.x:mnist.test.images,self.y:mnist.test.labels,self.keep_prob:1.0}
        print ("- the test accuracy %g " % self.accu_percent.eval( feed_dict=feed_content ))
        
    @property
    def flat(self):
        #self.img
        shape_line_list = self.img.shape[1:]
        type(shape_line_list)
        print (shape_line_list)
        shape_mul = 1
        for i in shape_line_list:
            #print ( int(i)+111 )
            shape_mul = shape_mul*int(i)
        shape_of_k = [-1, shape_mul ]
        img = tf.reshape( self.img, shape_of_k )
        self.img = img
        self.flat_ele = shape_mul 
        return self.img 
     

"""

(None,28*28)  : din , x 
(None, 28*28).reshape = (28,28,1) : .reshape
(28,28,1,1)*[5,5,1,32] = (28,28,32,1)  : c1
(28,28,32,1)./2 = (14,14,32,1)  : p1
(14,14,32,1)*[5,5,32,64]= (14,14,64,1)  : c2
(14,14,64,1)./2 = (7,7,64,1)  : p2
(7,7,64,1).reshape = (1,7*7*64)  : .reshape
(1,7*7*64)x[7*7*64,1024] = (1,1024) : h1
(1,1024).dropout = (1,1024)  : .dropout
(1,1024) x [1024,10] = (1,10)  : dout_ , y_

"""
OBJ_ML_CONST={
"lr": 1e-4,
"iter_times": 600,
"batch_size": 50,
"keep_prob_rate": 0.511 ,
"loss": "LOSS INIT" , 
"accu_percent": "ACCU_PERCENT INIT" , 
"id_train": "ID_TRAIN INIT" , 
}


x_dim = 28*28
y_dim = 10

ml = ML( x_dim ,y_dim ,OBJ_ML_CONST )
k1=[5,5,1,32]
ml.conv2d_by_k( k1, act_fun="relu" )
ml.pool_2x2()

k2=[5,5,32,64]
ml.conv2d_by_k(k2, act_fun="relu")
ml.pool_2x2()

#print ( ml.img )
ml.flat

h_in_k = [ml.flat_ele, 1024]
ml.cal_w_b_by_k(h_in_k, act_fun="relu")

ml.tf_dropout( ml.keep_prob )

h_out_k = [1024,10]
ml.cal_w_b_by_k(h_out_k, act_fun="softmax")

y_ = ml.img 

ml.loss_fun()
ml.cal_accu_percent()  # self.accu_percent
ml.set_train_args()

ml.say()


print ("- start trainning process")

ml.start_train_loop()


        
        




#---------------------------------------------------------------------

from tensorflow.examples.tutorials.mnist import input_data
import tensorflow as tf

mnist = input_data.read_data_sets( "MNIST_data/",one_hot=True)

sess = tf.InteractiveSession()

    
        
"""

(None,28*28)  : din , x 
(None, 28*28).reshape = (28,28,1) : .reshape
(28,28,1,1)*[5,5,1,32] = (28,28,32,1)  : c1
(28,28,32,1)./2 = (14,14,32,1)  : p1
(14,14,32,1)*[5,5,32,64]= (14,14,64,1)  : c2
(14,14,64,1)./2 = (7,7,64,1)  : p2
(7,7,64,1).reshape = (1,7*7*64)  : .reshape
(1,7*7*64)x[7*7*64,1024] = (1,1024) : h1
(1,1024).dropout = (1,1024)  : .dropout
(1,1024) x [1024,10] = (1,10)  : dout_ , y_

"""


def pool_2x2(img):
    id_p = tf.nn.max_pool( img, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME' )
    return id_p


def tf_w_b(k):
    w_ = tf.truncated_normal(k, stddev=0.1)
    w = tf.Variable(w_)
    b_ = tf.constant(0.1, shape=k[-1:])
    b = tf.Variable(b_)
    return [w,b]
    
    
def conv2d_by_k_relu( img, k ):
    [w,b] = tf_w_b(k)
    id_conv_ = tf.nn.conv2d(img,w, strides=[1,1,1,1], padding='SAME')
    id_conv = tf.nn.relu( id_conv_ + b )
    return id_conv 

def cal_w_b(x_data, k, act_fun="relu"):
    w = tf_w(k)  # [5,5,1,32]
    b = tf_b(k[-1:])  # [32]
    h_ = tf.matmul(x_data, w) + b
    if act_fun == "relu" :
        h = tf.nn.relu(h_)
        return h
    if act_fun == "softmax" :
        h = tf.nn.softmax(h_)
        return h
    raise  ValueError('- act_fun is "relu" or "softmax"! ')

def tf_dropout(h, keep_prob_):
    #keep_prob is NOT a number
    hh = tf.nn.dropout(h, keep_prob_)
    return hh    

def loss_fun(y,y_,str_type="entropy"):
    if str_type == "entropy":
        return tf.reduce_mean( -1*tf.reduce_sum( y*tf.log(y_) , reduction_indices=[1] ) )
    else:
         raise  ValueError('- only entropy can be used!')

def set_train_args(lr, loss_fun):
    id_train = tf.train.AdamOptimizer(lr).minimize(loss_fun)
    return id_train

def start_train_loop_with_keep_prob(id_train, iter_times, batch_size ,accu_percent,keep_prob_rate=0.75):
    tf.global_variables_initializer().run()
    for i in range(iter_times):
        #s_i = np.random.randint(0,x_data.shape[0]-batch_size)
        #bd_0 =  np.reshape( x_data[s_i:s_i+batch_size,:], [batch_size,2] )
        #bd_1 =  np.reshape( y_data[s_i:s_i+batch_size,:], [batch_size,2] )
        batch = mnist.train.next_batch(batch_size)
        bd_0 = batch[0]
        bd_1 = batch[1]
        if i%100 == 0:
            a_rate_e = accu_percent.eval( feed_dict = {x:bd_0, y:bd_1, keep_prob: 1.0} )  # y_ and y
            print ("- train %d, accuracy: %g" %(i,a_rate_e))
            pass
        id_train.run( feed_dict = {x:bd_0, y:bd_1, keep_prob: keep_prob_rate } )  
        pass

def cal_accu_percent(y,y_):
    vec_0_1 = tf.equal (tf.argmax(y,1),tf.argmax(y_,1)) 
    accu_percent = tf.reduce_mean( tf.cast(vec_0_1,tf.float32) )
    return accu_percent





lr = 1e-4
iter_times = 2000
batch_size = 50
keep_prob_rate = 0.5111



x = tf.placeholder(tf.float32, [None, 28*28])
#x = din
y = tf.placeholder( tf.float32, [None,10])
#y = dout

in_img = tf.reshape( x, [-1,28,28,1] )

k1 = [5,5,1,32]
c1 = conv2d_by_k_relu(in_img, k1 )

p1 = pool_2x2(c1)

k2 = [5,5,32,64]
c2 = conv2d_by_k_relu(p1, k2)

p2 = pool_2x2(c2)

shape_of_flat = [-1,7*7*64]
p2_flat = tf.reshape(p2, shape_of_flat )

h1_k = [7*7*64,1024]
h1 = cal_w_b( p2_flat, h1_k, act_fun = "relu" )

keep_prob = tf.placeholder(tf.float32)
h1_dropout = tf_dropout(h1,keep_prob)

dout_k = [1024,10]
y_ = cal_w_b( h1_dropout, dout_k, act_fun = "softmax" )
#y_ = dout_ 


loss = loss_fun(y, y_)
id_train = set_train_args(lr,loss)

accu_percent = cal_accu_percent(y,y_)
start_train_loop_with_keep_prob(id_train, iter_times, batch_size ,accu_percent, keep_prob_rate )


print ("- the test accuracy %g " % accu_percent.eval( feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0} ))


""" ouput
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
- train 0, accuracy: 0.1
- train 100, accuracy: 0.8
- train 200, accuracy: 0.94
- train 300, accuracy: 0.86
- train 400, accuracy: 0.98
- train 500, accuracy: 0.94
- train 600, accuracy: 1
- train 700, accuracy: 0.98
- train 800, accuracy: 0.88
- train 900, accuracy: 0.98
- train 1000, accuracy: 0.94
- train 1100, accuracy: 0.94
- train 1200, accuracy: 1
- train 1300, accuracy: 0.98
- train 1400, accuracy: 0.96
- train 1500, accuracy: 0.98
- train 1600, accuracy: 1
- train 1700, accuracy: 1
- train 1800, accuracy: 0.98
- train 1900, accuracy: 0.98
- the test accuracy 0.9744 

"""




TensorFlow


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




python_oop

jdtangjdtang・
2 个月前2017 年 4月 1 日星期六下午 1 点 52 分


class A(object):
    static="static_value"
    
    __doc__= "help doc"
    @classmethod
    def static_fun(Self):
        print( "- Self.static : " + Self.static )
        Self.static= "new static value"
        return Self.static
    
    def __init__(self, a):
        self.a = a
        pass


    @property
    def dec(self):
        self.a-=1
        pass
    def call_fun(self):
        news=A.static_fun()
        print("- static value new:", news, "\n")
        dic_ = self.__dict__
        print ("- dic:\n", dic_,"\n")
        dir_ = dir(self)
        print ("- dir:\n", dir_, "\n")
        self.dec
        print ("- self.a should be :",self.a, "\n")
        pass
        


class B(A):
    def __init__(self,a,b):
        super(B,self).__init__(a)
        self.b =b 
        pass

    def call_fun(self):
        super(B,self).call_fun()
        print ("- new added attri self.b is : " , self.b)
        pass

id_a = A(999)
id_a.call_fun()
print( id_a.__doc__ )

print("")

id_b = B(2,22)
id_b.call_fun()
    


     


""" output 
- Self.static : static_value
('- static value new:', 'new static value', '\n')
('- dic:\n', {'a': 999}, '\n')
('- dir:\n', ['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'a', 'call_fun', 'dec', 'static', 'static_fun'], '\n')
('- self.a should be :', 998, '\n')
help doc

- Self.static : new static value
('- static value new:', 'new static value', '\n')
('- dic:\n', {'a': 2, 'b': 22}, '\n')
('- dir:\n', ['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'a', 'b', 'call_fun', 'dec', 'static', 'static_fun'], '\n')
('- self.a should be :', 1, '\n')
('- new added attri self.b is : ', 22)

"""

    




Python 入门


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




tensorflow_custom_use_common_version

jdtangjdtang・
2 个月前2017 年 3月 27 日星期一下午 3 点 30 分


# train MLP , need steps = 0..6 -> 7 # 
import numpy as np
import matplotlib.pyplot as plt

#from tensorflow.examples.tutorials.mnist import input_data
#mnist = input_data.read_data_sets( "MNIST_data/", one_hot=1)


import tensorflow as tf
sess = tf.InteractiveSession()


    
### start define defs ### 
# 0
def gen_sets_and_label(x_items, x_dim):
    x_data = (np.random.random([x_items,x_dim])-0.5) *2
    x_data=x_data.astype(np.float32)
    y_data = np.random.random([x_items,x_dim])
    y_data=y_data.astype(np.float32)
    for a in range(x_data.shape[0]):
        if ((x_data[a][0])**2+(x_data[a][1])**2>0.5 ):
            y_data[a]=np.mat([1,0])
        else:
            y_data[a]=np.mat( [0,1])
    return [x_data, y_data]

# call by 1
def via_h1_cal_y_(x,W1,b1,keep_prob_rate, W2,b2):
    h1 = tf.nn.relu( tf.matmul(x,W1) + b1 )
    h1_drop = tf.nn.dropout ( h1, keep_prob_rate )
    y_= tf.nn.softmax (tf.matmul(h1_drop,W2) + b2)
    return y_

# 1
def create_x_y_W1_b1_W2_b2_by_h1( x_dim, y_dim, h1_dim, keep_prob=0.75 ):
    x = tf.placeholder( tf.float32, [None,x_dim] )
    y = tf.placeholder( tf.float32, [None,y_dim] )
    W1  = tf.Variable( tf.truncated_normal( [x_dim,h1_dim ],  stddev=0.1 ) )
    b1 = tf.Variable( tf.zeros( [ h1_dim ] ) )
    W2 = tf.Variable( tf.truncated_normal( [h1_dim, y_dim ],  stddev=0.1 ) )
    b2 = tf.Variable( tf.zeros( [ y_dim ] ) ) 
    y_ = via_h1_cal_y_(x,W1,b1,keep_prob, W2,b2)
    return [ x, y, W1,b1, W2,b2,y_]

# 2
def loss_fun(str_type,y,y_):
    if str_type == "entropy":
        return tf.reduce_mean( -1*tf.reduce_sum( y*tf.log(y_) , reduction_indices=[1] ) )
    else:
         raise  ValueError('- only entropy can be used!')
# 3
def set_train_args_has_h1(lr, loss_fun):
    id_train = tf.train.AdagradOptimizer(lr).minimize(loss_fun)
    return id_train

# 4
def start_train_loop_with_h1_keep_prob(id_train, x_data,y_data, iter_times, batch_size ,accu_percent,keep_prob_rate=0.75):
    tf.global_variables_initializer().run()
    for i in range(iter_times):
        s_i = np.random.randint(0,x_data.shape[0]-batch_size)
        bd_0 =  np.reshape( x_data[s_i:s_i+batch_size,:], [batch_size,2] )
        bd_1 =  np.reshape( y_data[s_i:s_i+batch_size,:], [batch_size,2] )
        if i%100 == 0:
            a_rate_e = accu_percent.eval({x:bd_0, y:bd_1, keep_prob: 1.0})
            print ("- train %d, accuracy: %g" %(i,a_rate_e))
        id_train.run( {x:bd_0, y:bd_1, keep_prob: keep_prob_rate } )  
        pass
# 5    
def cal_accu_percent(y_r0,y_predict):
    vec_0_1 = tf.equal (tf.argmax(y_r0,1),tf.argmax(y_predict,1)) 
    accu_percent = tf.reduce_mean( tf.cast(vec_0_1,tf.float32) )
    return accu_percent

# 6    
def predict_sets_to_num_via_W1_b1_h1_W2_b2(x,idx,W1,b1,W2,b2):
    #def via_h1_cal_y_(x,W1,b1,keep_prob_rate, W2,b2):
    keep_prob = 1.0
    y_ = via_h1_cal_y_(x[idx:idx+1] ,W1,b1,  keep_prob ,  W2,b2 )  # cal to y_
    return tf.argmax(y_ , 1).eval()[0]    

### define global var ### 
x_items = 2000    
x_dim = 2
y_dim = 2
h1_dim = x_dim**8

lr=0.5

iter_times = 1000
batch_size = 155

str_type = "entropy"
keep_prob_rate = 0.91
keep_prob = tf.placeholder( tf.float32 )



[x_data, y_data] = gen_sets_and_label(x_items,x_dim)
[x_test, y_test] = gen_sets_and_label(x_items*3,x_dim)



if ( 0 ):
    print(x_data)
    L_()
    print(y_data)
    pass


### training ### 
[x,y,W1,b1,W2,b2,y_] = create_x_y_W1_b1_W2_b2_by_h1(x_dim, y_dim, h1_dim, keep_prob_rate )

loss = loss_fun(str_type,y,y_) 

# set train args #
id_train = set_train_args_has_h1(lr, loss)
accu_percent = cal_accu_percent(y,y_)

start_train_loop_with_h1_keep_prob( id_train, x_data,y_data, iter_times, batch_size , accu_percent,keep_prob_rate)


### evaluating ### 

print ( "- acc train:" )
print ( accu_percent.eval({x:x_data,y:y_data, keep_prob:1.0})  )
print ("- acc of test")
print ( accu_percent.eval({ x:x_test, y:y_test, keep_prob: 1.0 }))

tt = y_.eval({x:x_test,y:y_test,keep_prob:1})
print ("---")
print (tt[0,:])
print ("---")


for i in range(3):
    #W= [W1,W2]
    #b= [b1,b2]
    idx=i
    int_num = predict_sets_to_num_via_W1_b1_h1_W2_b2(x_test,idx,W1,b1,W2,b2)
    
    print ("- test data")
    print ( x_test[i] )
    print ( int_num ) 
    print ("- y_test ")
    print ( y_test[i])
    print ("")


# show figure #
c_all = []
for i in range(y_test.shape[0]):
    if ( y_test[i,0]==1 ):
        c_all.append(1)
    else:
        c_all.append(0)

plt.figure(figsize=(6,6))
plt.scatter(x_test[:,0],x_test[:,1], c=c_all )  
axis_x_y = np.linspace(-1.5,1.5,6) 
plt.xticks(axis_x_y)
plt.yticks(axis_x_y)
plt.show()

# _END_ #




#--------------------------------------------------------
import numpy as np
import matplotlib.pyplot as plt







#from tensorflow.examples.tutorials.mnist import input_data
#mnist = input_data.read_data_sets( "MNIST_data/", one_hot=1)


import tensorflow as tf
sess = tf.InteractiveSession()

def show_train_img(ii):
    img_all=[]
    for i in range(28*28):
        tt = int(mnist.train.images[ii][i]*255)
        if tt<int(255/2):
            img_all.append(  " " )
        else:
            img_all.append(  "●" )     
        if i%28==0 :
            img_all.append("\n")
    print ( "".join(img_all) )

def show_test_img(ii):
    img_all=[]
    for i in range(28*28):
        tt = int(mnist.test.images[ii][i]*255)
        if tt<int(255/2):
            img_all.append(  " " )
        else:
            img_all.append(  "●" )     
        if i%28==0 :
            img_all.append("\n")
    print ( "".join(img_all) )


def W_b(x,y):
    tt=[tf.Variable(tf.zeros([x.shape[1],y.shape[1]])), tf.Variable(tf.zeros([y.shape[1]]) )]
    #tf.global_variables_initializer().run()
    return tt

def cal_y_(x,W,b):
    return tf.nn.softmax( tf.matmul(x,W)+b )

def create_in_out(in_width,out_width):
    return [tf.placeholder(tf.float32, [None, in_width]), tf.placeholder(tf.float32,[None,out_width])  ]

def loss_fun(str_type,y,y_):
    if str_type == "entropy":
        return tf.reduce_mean( -1*tf.reduce_sum( y*tf.log(y_) , reduction_indices=[1] ) )
    else:
         raise  ValueError('- only entropy!')

def set_train_args(lr, loss_fun):
    return tf.train.GradientDescentOptimizer(lr).minimize(loss_fun)

def start_train_loop(train_step_, iter_times, batch_size ):
    tf.global_variables_initializer().run()
    for i in range(iter_times):
        bd = mnist.train.next_batch(batch_size)
        train_step_.run({x:bd[0], y:bd[1]})

def start_train_loop_com(train_step_, x_data,y_data, iter_times, batch_size ):
    tf.global_variables_initializer().run()
    for i in range(iter_times):
        s_i = np.random.randint(0,x_data.shape[0]-batch_size)
        #print (s_i)
        
        bd_0 =  np.reshape( x_data[s_i:s_i+batch_size,:], [batch_size,2] )
        bd_1 =  np.reshape( y_data[s_i:s_i+batch_size,:], [batch_size,2] )
        train_step_.run({x:bd_0, y:bd_1})        
        
def cal_accu_percent(y_r0,y_predict):
    vec_0_1 = tf.equal (tf.argmax(y_r0,1),tf.argmax(y_predict,1)) 
    accu_percent = tf.reduce_mean( tf.cast(vec_0_1,tf.float32) )
    return accu_percent

def predict_img_to_num(img_sets,img_idx ,W,b):
    #[img_sets,img_idx ,W,b] = struc_input
    y_predict = cal_y_(img_sets[img_idx:img_idx+1] ,W,b)  # cal to y_
    return tf.argmax(y_predict,1).eval()[0]

def create_x_y_W_b_y_ (x_dim,y_dim):
    [x,y]=create_in_out(x_dim, y_dim)
    [W,b] = W_b(x,y)
    y_ = cal_y_(x,W,b)
    return [x,y,W,b,y_]
    
def gen_sets_and_label(x_items, x_dim):
    x_data = (np.random.random([x_items,x_dim])-0.5) *2
    x_data=x_data.astype(np.float32)
    y_data = np.random.random([x_items,x_dim])
    y_data=y_data.astype(np.float32)
    for a in range(x_data.shape[0]):
        if (x_data[a][0]>x_data[a][1] ):
            y_data[a]=np.mat([1,0])
        else:
            y_data[a]=np.mat( [0,1])
    return [x_data, y_data]
    
### start define vars ### 
x_dim = 2
y_dim = 2
lr=0.5/2
iter_times = 200
batch_size = iter_times/4
str_type = "entropy"



x_items = 5500
x_dim = 2
[x_data, y_data] = gen_sets_and_label(x_items,x_dim)
[x_test, y_test] = gen_sets_and_label(x_items,x_dim)  




[x,y,W,b,y_] = create_x_y_W_b_y_( x_dim, y_dim )  

loss = loss_fun(str_type,y,y_)
id_train = set_train_args(lr, loss)
start_train_loop_com(id_train, x_data,y_data, iter_times, batch_size )



accu_percent = cal_accu_percent( y, y_)




print ( "- acc train:" )
print ( accu_percent.eval({x:x_data,y:y_data})  )
print ("- acc of test")
print ( accu_percent.eval({ x:x_test,y:y_test })  )


for i in range(3):
    int_num = predict_img_to_num ( x_test,i,W,b )
    print ("- train data")
    print ( x_data[i] )
    print ("- test data")
    print ( x_test[i] )
    print ( int_num ) 
    print ("- y_test ")
    print ( y_test[i])
    print ("")
    
   
    


print ("- Variables:")
W_e = W.eval()
b_e = b.eval()
print ("- W is:")
print ( W_e )
print ("- b is:")
print ( b_e )

list_ele = [ [2,3],[3,2] ] 
xx= np.mat( list_ele ).astype(np.float32)

print ( "\n- "+ str( list_ele ) + " cal to be :" )
print ( xx* W_e + b_e  ) 




###－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets( "MNIST_data/", one_hot=1)


import tensorflow as tf
sess = tf.InteractiveSession()

def show_train_img(ii):
    img_all=[]
    for i in range(28*28):
        tt = int(mnist.train.images[ii][i]*255)
        if tt<int(255/2):
            img_all.append(  " " )
        else:
            img_all.append(  "●" )     
        if i%28==0 :
            img_all.append("\n")
    print ( "".join(img_all) )

def show_test_img(ii):
    img_all=[]
    for i in range(28*28):
        tt = int(mnist.test.images[ii][i]*255)
        if tt<int(255/2):
            img_all.append(  " " )
        else:
            img_all.append(  "●" )     
        if i%28==0 :
            img_all.append("\n")
    print ( "".join(img_all) )


def W_b(x,y):
    tt=[tf.Variable(tf.zeros([x.shape[1],y.shape[1]])), tf.Variable(tf.zeros([y.shape[1]]) )]
    #tf.global_variables_initializer().run()
    return tt

def cal_y_(x,W,b):
    return tf.nn.softmax( tf.matmul(x,W)+b )

def create_in_out(in_width,out_width):
    return [tf.placeholder(tf.float32, [None, in_width]), tf.placeholder(tf.float32,[None,out_width])  ]

def loss_fun(str_type,y,y_):
    if str_type == "entropy":
        return tf.reduce_mean( -1*tf.reduce_sum( y*tf.log(y_) , reduction_indices=[1] ) )
    else:
         raise  ValueError('- only entropy!')

def set_train_args(lr, loss_fun):
    return tf.train.GradientDescentOptimizer(lr).minimize(loss_fun)

def start_train_loop(train_step_, iter_times, batch_size ):
    tf.global_variables_initializer().run()
    for i in range(iter_times):
        bd = mnist.train.next_batch(batch_size)
        train_step_.run({x:bd[0], y:bd[1]})

def cal_accu_percent(y_r0,y_predict):
    vec_0_1 = tf.equal (tf.argmax(y_r0,1),tf.argmax(y_predict,1)) 
    accu_percent = tf.reduce_mean( tf.cast(vec_0_1,tf.float32) )
    return accu_percent

def predict_img_to_num(struc_input):
    [img_sets,img_idx ,W,b] = struc_input
    y_predict = cal_y_(img_sets[img_idx:img_idx+1] ,W,b)  # cal to y_
    return tf.argmax(y_predict,1).eval()[0]

def create_x_y_W_b_y_ (x_dim,y_dim):
    [x,y]=create_in_out(x_dim, y_dim)
    [W,b] = W_b(x,y)
    y_ = cal_y_(x,W,b)
    return [x,y,W,b,y_]
    

### start define vars ### 
lr = 0.5    
x_dim_n = 28*28
y_dim_n = 10
train_iter_time = 1000
train_batch_size = 100


[x,y, W,b, y_] = create_x_y_W_b_y_(x_dim_n,y_dim_n)
loss = loss_fun("entropy",y,y_)




### start train process ### 
id_train = set_train_args(lr,loss)
start_train_loop(id_train, train_iter_time,train_batch_size)

### start estimate ans ###
accu_percent = cal_accu_percent(y, y_)
print( "- accurancy from test sets:" )
print( accu_percent.eval( { x:mnist.test.images[0:], y:mnist.test.labels[0:] } )  )
print( "- accurancy from train sets:" )
print( accu_percent.eval( { x:mnist.train.images[0:], y:mnist.train.labels[0:] } )  )


img_idx=5
show_test_img(img_idx)
int_num = predict_img_to_num( [mnist.test.images,img_idx,W,b] )
print ( int_num )
show_train_img(img_idx)
int_num = predict_img_to_num( [mnist.train.images,img_idx,W,b] )
print( int_num )

### show argument val ###
We = W.eval()
be = b.eval()
import matplotlib.pyplot as plt
plt.plot(be )
#print (be)
plt.show()




TensorFlow


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




tf_tensorflow_code_all

jdtangjdtang・
3 个月前2017 年 3月 21 日星期二晚上 9 点 03 分


 
1_hello_tensorflow Last Checkpoint: 11 minutes ago (autosaved)  
Python 2 
?	File 
?	Edit 
?	View 
?	Insert 
?	Cell 
?	Kernel 
?	Help 
Hello, TensorFlow
A beginner-level, getting started, basic introduction to TensorFlow
TensorFlow is a general-purpose system for graph-based computation. A typical use is machine learning. In this notebook, we'll introduce the basic concepts of TensorFlow using some simple examples.
TensorFlow gets its name from tensors, which are arrays of arbitrary dimensionality. A vector is a 1-d array and is known as a 1st-order tensor. A matrix is a 2-d array and a 2nd-order tensor. The "flow" part of the name refers to computation flowing through a graph. Training and inference in a neural network, for example, involves the propagation of matrix computations through many nodes in a computational graph.
When you think of doing things in TensorFlow, you might want to think of creating tensors (like matrices), adding operations (that output other tensors), and then executing the computation (running the computational graph). In particular, it's important to realize that when you add an operation on tensors, it doesn't execute immediately. Rather, TensorFlow waits for you to define all the operations you want to perform. Then, TensorFlow optimizes the computation graph, deciding how to execute the computation, before generating the data. Because of this, a tensor in TensorFlow isn't so much holding the data as a placeholder for holding the data, waiting for the data to arrive when a computation is executed.
Adding two vectors in TensorFlow
Let's start with something that should be simple. Let's add two length four vectors (two 1st-order tensors):
[1.1.1.1.]+[2.2.2.2.]=[3.3.3.3.][1.1.1.1.]+[2.2.2.2.]=[3.3.3.3.]
 
from __future__ import print_function

import tensorflow as tf

with tf.Session():
    input1 = tf.constant([1.0, 1.0, 1.0, 1.0])
    input2 = tf.constant([2.0, 2.0, 2.0, 2.0])
    output = tf.add(input1, input2)
    result = output.eval()
    print("result: ", result)
result:  [  3.  13.   3.   3.]
What we're doing is creating two vectors, [1.0, 1.0, 1.0, 1.0] and [2.0, 2.0, 2.0, 2.0], and then adding them. Here's equivalent code in raw Python and using numpy:
 
print([x + y for x, y in zip([1.0] * 4, [2.0] * 4)])

[3.0, 3.0, 3.0, 3.0]
 
import numpy as np
x, y = np.full(4, 1.0), np.full(4, 2.0)
print("{} + {} = {}".format(x, y, x + y))

[ 1.  1.  1.  1.] + [ 2.  2.  2.  2.] = [ 3.  3.  3.  3.]
Details of adding two vectors in TensorFlow
The example above of adding two vectors involves a lot more than it seems, so let's look at it in more depth.
import tensorflow as tf
This import brings TensorFlow's public API into our IPython runtime environment.
with tf.Session():
When you run an operation in TensorFlow, you need to do it in the context of a Session. A session holds the computation graph, which contains the tensors and the operations. When you create tensors and operations, they are not executed immediately, but wait for other operations and tensors to be added to the graph, only executing when finally requested to produce the results of the session. Deferring the execution like this provides additional opportunities for parallelism and optimization, as TensorFlow can decide how to combine operations and where to run them after TensorFlow knows about all the operations. 
input1 = tf.constant([1.0, 1.0, 1.0, 1.0])
input2 = tf.constant([2.0, 2.0, 2.0, 2.0])
The next two lines create tensors using a convenience function called constant, which is similar to numpy's array and numpy's full. If you look at the code for constant, you can see the details of what it is doing to create the tensor. In summary, it creates a tensor of the necessary shape and applies the constant operator to it to fill it with the provided values. The values to constant can be Python or numpy arrays. constant can take an optional shape parameter, which works similarly to numpy's fill if provided, and an optional name parameter, which can be used to put a more human-readable label on the operation in the TensorFlow operation graph.
output = tf.add(input1, input2)
You might think add just adds the two vectors now, but it doesn't quite do that. What it does is put the add operation into the computational graph. The results of the addition aren't available yet. They've been put in the computation graph, but the computation graph hasn't been executed yet.
result = output.eval()
print result
eval() is also slightly more complicated than it looks. Yes, it does get the value of the vector (tensor) that results from the addition. It returns this as a numpy array, which can then be printed. But, it's important to realize it also runs the computation graph at this point, because we demanded the output from the operation node of the graph; to produce that, it had to run the computation graph. So, this is the point where the addition is actually performed, not when add was called, as add just put the addition operation into the TensorFlow computation graph.
Multiple operations
To use TensorFlow, you add operations on tensors that produce tensors to the computation graph, then execute that graph to run all those operations and calculate the values of all the tensors in the graph.
Here's a simple example with two operations:
 
import tensorflow as tf

with tf.Session():
    input1 = tf.constant(1.0, shape=[4])
    input2 = tf.constant(2.0, shape=[4])
    input3 = tf.constant(3.0, shape=[4])
    output = tf.add(tf.add(input1, input2), input3)
    result = output.eval()
    print(result)
[ 6.  6.  6.  6.]
This version uses constant in a way similar to numpy's fill, specifying the optional shape and having the values copied out across it.
The add operator supports operator overloading, so you could try writing it inline as input1 + input2 instead as well as experimenting with other operators.
 
with tf.Session():
    input1 = tf.constant(1.0, shape=[4])
    input2 = tf.constant(2.0, shape=[4])
    output = input1 + input2
    print(output.eval())
[ 3.  3.  3.  3.]
Adding two matrices
Next, let's do something very similar, adding two matrices:
[1.1.1.1.1.1.]+[1.4.2.5.3.6.]=[2.5.3.6.4.7.][1.1.1.1.1.1.]+[1.2.3.4.5.6.]=[2.3.4.5.6.7.]
 
import tensorflow as tf
import numpy as np

with tf.Session():
    input1 = tf.constant(1.0, shape=[2, 3])
    input2 = tf.constant(np.reshape(np.arange(1.0, 7.0, dtype=np.float32), (2, 3)))
    output = tf.add(input1, input2)
    print(output.eval())
    
[[ 2.  3.  4.]
 [ 5.  6.  7.]]
Recall that you can pass numpy or Python arrays into constant.
In this example, the matrix with values from 1 to 6 is created in numpy and passed into constant, but TensorFlow also has range, reshape, and tofloat operators. Doing this entirely within TensorFlow could be more efficient if this was a very large matrix.
Try experimenting with this code a bit -- maybe modifying some of the values, using the numpy version, doing this using, adding another operation, or doing this using TensorFlow's range function.
Multiplying matrices
Let's move on to matrix multiplication. This time, let's use a bit vector and some random values, which is a good step toward some of what we'll need to do for regression and neural networks.
 
#@test {"output": "ignore"}
import tensorflow as tf
import numpy as np

with tf.Session():
    input_features = tf.constant(np.reshape([1, 0, 0, 1], (1, 4)).astype(np.float32))
    weights = tf.constant(np.random.randn(4, 2).astype(np.float32))
    output = tf.matmul(input_features, weights)
    print("Input:")
    print(input_features.eval())
    print("Weights:")
    print(weights.eval())
    print("Output:")
    print(output.eval())
Input:
[[ 1.  0.  0.  1.]]
Weights:
[[ 0.3949919  -0.83823347]
 [ 0.25941893 -1.58861065]
 [-1.11733329 -0.60435963]
 [ 1.04782867  0.18336453]]
Output:
[[ 1.44282055 -0.65486896]]
Above, we're taking a 1 x 4 vector [1 0 0 1] and multiplying it by a 4 by 2 matrix full of random values from a normal distribution (mean 0, stdev 1). The output is a 1 x 2 matrix.
You might try modifying this example. Running the cell multiple times will generate new random weights and a new output. Or, change the input, e.g., to [0 0 0 1]), and run the cell again. Or, try initializing the weights using the TensorFlow op, e.g., random_normal, instead of using numpy to generate the random weights.
What we have here is the basics of a simple neural network already. If we are reading in the input features, along with some expected output, and change the weights based on the error with the output each time, that's a neural network.
Use of variables
Let's look at adding two small matrices in a loop, not by creating new tensors every time, but by updating the existing values and then re-running the computation graph on the new data. This happens a lot with machine learning models, where we change some parameters each time such as gradient descent on some weights and then perform the same computations over and over again.
 
#@test {"output": "ignore"}
import tensorflow as tf
import numpy as np

with tf.Session() as sess:
    # Set up two variables, total and weights, that we'll change repeatedly.
    total = tf.Variable(tf.zeros([1, 2]))
    weights = tf.Variable(tf.random_uniform([1,2]))

    # Initialize the variables we defined above.
    tf.global_variables_initializer().run()

    # This only adds the operators to the graph right now. The assignment
    # and addition operations are not performed yet.
    update_weights = tf.assign(weights, tf.random_uniform([1, 2], -1.0, 1.0))
    update_total = tf.assign(total, tf.add(total, weights))
  
    for _ in range(5):
        # Actually run the operation graph, so randomly generate weights and then
        # add them into the total. Order does matter here. We need to update
        # the weights before updating the total.
        sess.run(update_weights)
        sess.run(update_total)
    
        print(weights.eval(), total.eval())
[[ -7.29560852e-05   8.01583767e-01]] [[ -7.29560852e-05   8.01583767e-01]]
[[ 0.64477301 -0.03944111]] [[ 0.64470005  0.76214266]]
[[-0.07470274 -0.76814342]] [[ 0.56999731 -0.00600076]]
[[-0.34230471 -0.42372179]] [[ 0.2276926  -0.42972255]]
[[ 0.67873812  0.65932178]] [[ 0.90643072  0.22959924]]
This is more complicated. At a high level, we create two variables and add operations over them, then, in a loop, repeatedly execute those operations. Let's walk through it step by step.
Starting off, the code creates two variables, total and weights. total is initialized to [0, 0] and weights is initialized to random values between -1 and 1.
Next, two assignment operators are added to the graph, one that updates weights with random values from [-1, 1], the other that updates the total with the new weights. Again, the operators are not executed here. In fact, this isn't even inside the loop. We won't execute these operations until the eval call inside the loop.
Finally, in the for loop, we run each of the operators. In each iteration of the loop, this executes the operators we added earlier, first putting random values into the weights, then updating the totals with the new weights. This call uses eval on the session; the code also could have called eval on the operators (e.g. update_weights.eval).
It can be a little hard to wrap your head around exactly what computation is done when. The important thing to remember is that computation is only performed on demand.
Variables can be useful in cases where you have a large amount of computation and data that you want to use over and over again with just a minor change to the input each time. That happens quite a bit with neural networks, for example, where you just want to update the weights each time you go through the batches of input data, then run the same operations over again.
What's next?
This has been a gentle introduction to TensorFlow, focused on what TensorFlow is and the very basics of doing anything in TensorFlow. If you'd like more, the next tutorial in the series is Getting Started with TensorFlow, also available in the notebooks directory.


#@test {"output": "ignore"}
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

# Set up the data with a noisy linear relationship between X and Y.
num_examples = 50
X = np.array([np.linspace(-2, 4, num_examples), np.linspace(-6, 6, num_examples)])
# Add random noise (gaussian, mean 0, stdev 1)
X += np.random.randn(2, num_examples)
# Split into x and y
x, y = X
# Add the bias node which always has a value of 1
x_with_bias = np.array([(1., a) for a in x]).astype(np.float32)

# Keep track of the loss at each iteration so we can chart it later
losses = []
# How many iterations to run our training
training_steps = 50
# The learning rate. Also known has the step size. This changes how far
# we move down the gradient toward lower error at each step. Too large
# jumps risk inaccuracy, too small slow the learning.
learning_rate = 0.002

# In TensorFlow, we need to run everything in the context of a session.
with tf.Session() as sess:
    # Set up all the tensors.
    # Our input layer is the x value and the bias node.
    input = tf.constant(x_with_bias)
    # Our target is the y values. They need to be massaged to the right shape.
    target = tf.constant(np.transpose([y]).astype(np.float32))
    # Weights are a variable. They change every time through the loop.
    # Weights are initialized to random values (gaussian, mean 0, stdev 0.1)
    weights = tf.Variable(tf.random_normal([2, 1], 0, 0.1))

    # Initialize all the variables defined above.
    tf.global_variables_initializer().run()

    # Set up all operations that will run in the loop.
    # For all x values, generate our estimate on all y given our current
    # weights. So, this is computing y = w2 * x + w1 * bias
    yhat = tf.matmul(input, weights)
    # Compute the error, which is just the difference between our 
    # estimate of y and what y actually is.
    yerror = tf.subtract(yhat, target)
    # We are going to minimize the L2 loss. The L2 loss is the sum of the
    # squared error for all our estimates of y. This penalizes large errors
    # a lot, but small errors only a little.
    loss = tf.nn.l2_loss(yerror)

    # Perform gradient descent. 
    # This essentially just updates weights, like weights += grads * learning_rate
    # using the partial derivative of the loss with respect to the
    # weights. It's the direction we want to go to move toward lower error.
    update_weights = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)

    # At this point, we've defined all our tensors and run our initialization
    # operations. We've also set up the operations that will repeatedly be run
    # inside the training loop. All the training loop is going to do is 
    # repeatedly call run, inducing the gradient descent operation, which has the effect of
    # repeatedly changing weights by a small amount in the direction (the
    # partial derivative or gradient) that will reduce the error (the L2 loss).
    for _ in range(training_steps):
        # Repeatedly run the operations, updating the TensorFlow variable.
        sess.run(update_weights)

        # Here, we're keeping a history of the losses to plot later
        # so we can see the change in loss as training progresses.
        losses.append(loss.eval())

    # Training is done, get the final values for the charts
    betas = weights.eval()
    yhat = yhat.eval()

# Show the results.
fig, (ax1, ax2) = plt.subplots(1, 2)
plt.subplots_adjust(wspace=.3)
fig.set_size_inches(10, 4)
ax1.scatter(x, y, alpha=.7)
ax1.scatter(x, np.transpose(yhat)[0], c="g", alpha=.6)
line_x_range = (-4, 6)
ax1.plot(line_x_range, [betas[0] + a * betas[1] for a in line_x_range], "g", alpha=0.6)
ax2.plot(range(0, training_steps), losses)
ax2.set_ylabel("Loss")
ax2.set_xlabel("Training steps")
plt.show()

DDDDDDDDDDDDDDDDDD

 
3_mnist_from_scratch (unsaved changes)  
Python 2 
?	File 
?	Edit 
?	View 
?	Insert 
?	Cell 
?	Kernel 
?	Help 
MNIST from scratch
This notebook walks through an example of training a TensorFlow model to do digit classification using the MNIST data set. MNIST is a labeled set of images of handwritten digits.
An example follows.
 
from __future__ import print_function

from IPython.display import Image
import base64
Image(data=base64.decodestring("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".encode('utf-8')), embed=True)
/opt/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:5: DeprecationWarning: decodestring() is a deprecated alias, use decodebytes()

We're going to be building a model that recognizes these digits as 5, 0, and 4.
Imports and input data
We'll proceed in steps, beginning with importing and inspecting the MNIST data. This doesn't have anything to do with TensorFlow in particular -- we're just downloading the data archive.
 
import os
from six.moves.urllib.request import urlretrieve

SOURCE_URL = 'http://yann.lecun.com/exdb/mnist/'
WORK_DIRECTORY = "/tmp/mnist-data"

def maybe_download(filename):
    """A helper to download the data files if not present."""
    if not os.path.exists(WORK_DIRECTORY):
        os.mkdir(WORK_DIRECTORY)
    filepath = os.path.join(WORK_DIRECTORY, filename)
    if not os.path.exists(filepath):
        filepath, _ = urlretrieve(SOURCE_URL + filename, filepath)
        statinfo = os.stat(filepath)
        print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')
    else:
        print('Already downloaded', filename)
    return filepath

train_data_filename = maybe_download('train-images-idx3-ubyte.gz')
train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')
test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')
test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')
Already downloaded train-images-idx3-ubyte.gz
Already downloaded train-labels-idx1-ubyte.gz
Already downloaded t10k-images-idx3-ubyte.gz
Already downloaded t10k-labels-idx1-ubyte.gz
Working with the images
Now we have the files, but the format requires a bit of pre-processing before we can work with it. The data is gzipped, requiring us to decompress it. And, each of the images are grayscale-encoded with values from [0, 255]; we'll normalize these to [-0.5, 0.5].
Let's try to unpack the data using the documented format:
[offset] [type]          [value]          [description] 
0000     32 bit integer  0x00000803(2051) magic number 
0004     32 bit integer  60000            number of images 
0008     32 bit integer  28               number of rows 
0012     32 bit integer  28               number of columns 
0016     unsigned byte   ??               pixel 
0017     unsigned byte   ??               pixel 
........ 
xxxx     unsigned byte   ??               pixel
Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).
We'll start by reading the first image from the test data as a sanity check.
 
import gzip, binascii, struct, numpy
import matplotlib.pyplot as plt

with gzip.open(test_data_filename) as f:
    # Print the header fields.
    for field in ['magic number', 'image count', 'rows', 'columns']:
        # struct.unpack reads the binary data provided by f.read.
        # The format string '>i' decodes a big-endian integer, which
        # is the encoding of the data.
        print(field, struct.unpack('>i', f.read(4))[0])
    
    # Read the first 28x28 set of pixel values. 
    # Each pixel is one byte, [0, 255], a uint8.
    buf = f.read(28 * 28)
    image = numpy.frombuffer(buf, dtype=numpy.uint8)
  
    # Print the first few values of image.
    print('First 10 pixels:', image[:10])
magic number 2051
image count 10000
rows 28
columns 28
First 10 pixels: [0 0 0 0 0 0 0 0 0 0]
The first 10 pixels are all 0 values. Not very interesting, but also unsurprising. We'd expect most of the pixel values to be the background color, 0.
We could print all 28 * 28 values, but what we really need to do to make sure we're reading our data properly is look at an image.
 
%matplotlib inline

# We'll show the image and its pixel value histogram side-by-side.
_, (ax1, ax2) = plt.subplots(1, 2)

# To interpret the values as a 28x28 image, we need to reshape
# the numpy array, which is one dimensional.
ax1.imshow(image.reshape(28, 28), cmap=plt.cm.Greys);

ax2.hist(image, bins=20, range=[0,255]);

The large number of 0 values correspond to the background of the image, another large mass of value 255 is black, and a mix of grayscale transition values in between.
Both the image and histogram look sensible. But, it's good practice when training image models to normalize values to be centered around 0.
We'll do that next. The normalization code is fairly short, and it may be tempting to assume we haven't made mistakes, but we'll double-check by looking at the rendered input and histogram again. Malformed inputs are a surprisingly common source of errors when developing new models.
 
# Let's convert the uint8 image to 32 bit floats and rescale 
# the values to be centered around 0, between [-0.5, 0.5]. 
# 
# We again plot the image and histogram to check that we 
# haven't mangled the data.
scaled = image.astype(numpy.float32)
scaled = (scaled - (255 / 2.0)) / 255
_, (ax1, ax2) = plt.subplots(1, 2)
ax1.imshow(scaled.reshape(28, 28), cmap=plt.cm.Greys);
ax2.hist(scaled, bins=20, range=[-0.5, 0.5]);

Great -- we've retained the correct image data while properly rescaling to the range [-0.5, 0.5].
Reading the labels
Let's next unpack the test label data. The format here is similar: a magic number followed by a count followed by the labels as uint8 values. In more detail:
[offset] [type]          [value]          [description] 
0000     32 bit integer  0x00000801(2049) magic number (MSB first) 
0004     32 bit integer  10000            number of items 
0008     unsigned byte   ??               label 
0009     unsigned byte   ??               label 
........ 
xxxx     unsigned byte   ??               label
As with the image data, let's read the first test set value to sanity check our input path. We'll expect a 7.
 
with gzip.open(test_labels_filename) as f:
    # Print the header fields.
    for field in ['magic number', 'label count']:
        print(field, struct.unpack('>i', f.read(4))[0])

    print('First label:', struct.unpack('B', f.read(1))[0])
magic number 2049
label count 10000
First label: 7
Indeed, the first label of the test set is 7.
Forming the training, testing, and validation data sets
Now that we understand how to read a single element, we can read a much larger set that we'll use for training, testing, and validation.
Image data
The code below is a generalization of our prototyping above that reads the entire test and training data set.
 
IMAGE_SIZE = 28
PIXEL_DEPTH = 255

def extract_data(filename, num_images):
    """Extract the images into a 4D tensor [image index, y, x, channels].
  
    For MNIST data, the number of channels is always 1.

    Values are rescaled from [0, 255] down to [-0.5, 0.5].
    """
    print('Extracting', filename)
    with gzip.open(filename) as bytestream:
        # Skip the magic number and dimensions; we know these values.
        bytestream.read(16)

        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images)
        data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)
        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH
        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, 1)
        return data

train_data = extract_data(train_data_filename, 60000)
test_data = extract_data(test_data_filename, 10000)
Extracting /tmp/mnist-data/train-images-idx3-ubyte.gz
Extracting /tmp/mnist-data/t10k-images-idx3-ubyte.gz
A crucial difference here is how we reshape the array of pixel values. Instead of one image that's 28x28, we now have a set of 60,000 images, each one being 28x28. We also include a number of channels, which for grayscale images as we have here is 1.
Let's make sure we've got the reshaping parameters right by inspecting the dimensions and the first two images. (Again, mangled input is a very common source of errors.)
 
print('Training data shape', train_data.shape)
_, (ax1, ax2) = plt.subplots(1, 2)
ax1.imshow(train_data[0].reshape(28, 28), cmap=plt.cm.Greys);
ax2.imshow(train_data[1].reshape(28, 28), cmap=plt.cm.Greys);
Training data shape (60000, 28, 28, 1)

Looks good. Now we know how to index our full set of training and test images.
Label data
Let's move on to loading the full set of labels. As is typical in classification problems, we'll convert our input labels into a 1-hot encoding over a length 10 vector corresponding to 10 digits. The vector [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], for example, would correspond to the digit 1.
 
NUM_LABELS = 10

def extract_labels(filename, num_images):
    """Extract the labels into a 1-hot matrix [image index, label index]."""
    print('Extracting', filename)
    with gzip.open(filename) as bytestream:
        # Skip the magic number and count; we know these values.
        bytestream.read(8)
        buf = bytestream.read(1 * num_images)
        labels = numpy.frombuffer(buf, dtype=numpy.uint8)
    # Convert to dense 1-hot representation.
    return (numpy.arange(NUM_LABELS) == labels[:, None]).astype(numpy.float32)

train_labels = extract_labels(train_labels_filename, 60000)
test_labels = extract_labels(test_labels_filename, 10000)
Extracting /tmp/mnist-data/train-labels-idx1-ubyte.gz
Extracting /tmp/mnist-data/t10k-labels-idx1-ubyte.gz
As with our image data, we'll double-check that our 1-hot encoding of the first few values matches our expectations.
 
print('Training labels shape', train_labels.shape)
print('First label vector', train_labels[0])
print('Second label vector', train_labels[1])
Training labels shape (60000, 10)
First label vector [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]
Second label vector [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
The 1-hot encoding looks reasonable.
Segmenting data into training, test, and validation
The final step in preparing our data is to split it into three sets: training, test, and validation. This isn't the format of the original data set, so we'll take a small slice of the training data and treat that as our validation set.
 
VALIDATION_SIZE = 5000

validation_data = train_data[:VALIDATION_SIZE, :, :, :]
validation_labels = train_labels[:VALIDATION_SIZE]
train_data = train_data[VALIDATION_SIZE:, :, :, :]
train_labels = train_labels[VALIDATION_SIZE:]

train_size = train_labels.shape[0]

print('Validation shape', validation_data.shape)
print('Train size', train_size)
Validation shape (5000, 28, 28, 1)
Train size 55000
Defining the model
Now that we've prepared our data, we're ready to define our model.
The comments describe the architecture, which fairly typical of models that process image data. The raw input passes through several convolution and max pooling layers with rectified linear activations before several fully connected layers and a softmax loss for predicting the output class. During training, we use dropout.
We'll separate our model definition into three steps:
1.	Defining the variables that will hold the trainable weights.
2.	Defining the basic model graph structure described above. And,
3.	Stamping out several copies of the model graph for training, testing, and validation.
We'll start with the variables.
 
import tensorflow as tf

# We'll bundle groups of examples during training for efficiency.
# This defines the size of the batch.
BATCH_SIZE = 60
# We have only one channel in our grayscale images.
NUM_CHANNELS = 1
# The random seed that defines initialization.
SEED = 42

# This is where training samples and labels are fed to the graph.
# These placeholder nodes will be fed a batch of training data at each
# training step, which we'll write once we define the graph structure.
train_data_node = tf.placeholder(
  tf.float32,
  shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))
train_labels_node = tf.placeholder(tf.float32,
                                   shape=(BATCH_SIZE, NUM_LABELS))

# For the validation and test data, we'll just hold the entire dataset in
# one constant node.
validation_data_node = tf.constant(validation_data)
test_data_node = tf.constant(test_data)

# The variables below hold all the trainable weights. For each, the
# parameter defines how the variables will be initialized.
conv1_weights = tf.Variable(
  tf.truncated_normal([5, 5, NUM_CHANNELS, 32],  # 5x5 filter, depth 32.
                      stddev=0.1,
                      seed=SEED))
conv1_biases = tf.Variable(tf.zeros([32]))
conv2_weights = tf.Variable(
  tf.truncated_normal([5, 5, 32, 64],
                      stddev=0.1,
                      seed=SEED))
conv2_biases = tf.Variable(tf.constant(0.1, shape=[64]))
fc1_weights = tf.Variable(  # fully connected, depth 512.
  tf.truncated_normal([IMAGE_SIZE // 4 * IMAGE_SIZE // 4 * 64, 512],
                      stddev=0.1,
                      seed=SEED))
fc1_biases = tf.Variable(tf.constant(0.1, shape=[512]))
fc2_weights = tf.Variable(
  tf.truncated_normal([512, NUM_LABELS],
                      stddev=0.1,
                      seed=SEED))
fc2_biases = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS]))

print('Done')
Done
Now that we've defined the variables to be trained, we're ready to wire them together into a TensorFlow graph.
We'll define a helper to do this, model, which will return copies of the graph suitable for training and testing. Note the train argument, which controls whether or not dropout is used in the hidden layer. (We want to use dropout only during training.)
 
def model(data, train=False):
    """The Model definition."""
    # 2D convolution, with 'SAME' padding (i.e. the output feature map has
    # the same size as the input). Note that {strides} is a 4D array whose
    # shape matches the data layout: [image index, y, x, depth].
    conv = tf.nn.conv2d(data,
                        conv1_weights,
                        strides=[1, 1, 1, 1],
                        padding='SAME')

    # Bias and rectified linear non-linearity.
    relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))

    # Max pooling. The kernel size spec ksize also follows the layout of
    # the data. Here we have a pooling window of 2, and a stride of 2.
    pool = tf.nn.max_pool(relu,
                          ksize=[1, 2, 2, 1],
                          strides=[1, 2, 2, 1],
                          padding='SAME')
    conv = tf.nn.conv2d(pool,
                        conv2_weights,
                        strides=[1, 1, 1, 1],
                        padding='SAME')
    relu = tf.nn.relu(tf.nn.bias_add(conv, conv2_biases))
    pool = tf.nn.max_pool(relu,
                          ksize=[1, 2, 2, 1],
                          strides=[1, 2, 2, 1],
                          padding='SAME')

    # Reshape the feature map cuboid into a 2D matrix to feed it to the
    # fully connected layers.
    pool_shape = pool.get_shape().as_list()
    reshape = tf.reshape(
        pool,
        [pool_shape[0], pool_shape[1] * pool_shape[2] * pool_shape[3]])
  
    # Fully connected layer. Note that the '+' operation automatically
    # broadcasts the biases.
    hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)

    # Add a 50% dropout during training only. Dropout also scales
    # activations such that no rescaling is needed at evaluation time.
    if train:
        hidden = tf.nn.dropout(hidden, 0.5, seed=SEED)
    return tf.matmul(hidden, fc2_weights) + fc2_biases

print('Done')
Done
Having defined the basic structure of the graph, we're ready to stamp out multiple copies for training, testing, and validation.
Here, we'll do some customizations depending on which graph we're constructing. train_prediction holds the training graph, for which we use cross-entropy loss and weight regularization. We'll adjust the learning rate during training -- that's handled by the exponential_decay operation, which is itself an argument to the MomentumOptimizer that performs the actual training.
The vaildation and prediction graphs are much simpler the generate -- we need only create copies of the model with the validation and test inputs and a softmax classifier as the output.
 
# Training computation: logits + cross-entropy loss.
logits = model(train_data_node, True)
loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(
  labels=train_labels_node, logits=logits))

# L2 regularization for the fully connected parameters.
regularizers = (tf.nn.l2_loss(fc1_weights) + tf.nn.l2_loss(fc1_biases) +
                tf.nn.l2_loss(fc2_weights) + tf.nn.l2_loss(fc2_biases))
# Add the regularization term to the loss.
loss += 5e-4 * regularizers

# Optimizer: set up a variable that's incremented once per batch and
# controls the learning rate decay.
batch = tf.Variable(0)
# Decay once per epoch, using an exponential schedule starting at 0.01.
learning_rate = tf.train.exponential_decay(
  0.01,                # Base learning rate.
  batch * BATCH_SIZE,  # Current index into the dataset.
  train_size,          # Decay step.
  0.95,                # Decay rate.
  staircase=True)
# Use simple momentum for the optimization.
optimizer = tf.train.MomentumOptimizer(learning_rate,
                                       0.9).minimize(loss,
                                                     global_step=batch)

# Predictions for the minibatch, validation set and test set.
train_prediction = tf.nn.softmax(logits)
# We'll compute them only once in a while by calling their {eval()} method.
validation_prediction = tf.nn.softmax(model(validation_data_node))
test_prediction = tf.nn.softmax(model(test_data_node))

print('Done')
Done
Training and visualizing results
Now that we have the training, test, and validation graphs, we're ready to actually go through the training loop and periodically evaluate loss and error.
All of these operations take place in the context of a session. In Python, we'd write something like:
with tf.Session() as s:
  ...training / test / evaluation loop...
But, here, we'll want to keep the session open so we can poke at values as we work out the details of training. The TensorFlow API includes a function for this, InteractiveSession.
We'll start by creating a session and initializing the varibles we defined above.
 
# Create a new interactive session that we'll use in
# subsequent code cells.
s = tf.InteractiveSession()

# Use our newly created session as the default for 
# subsequent operations.
s.as_default()

# Initialize all the variables we defined above.
tf.global_variables_initializer().run()
Now we're ready to perform operations on the graph. Let's start with one round of training. We're going to organize our training steps into batches for efficiency; i.e., training using a small set of examples at each step rather than a single example.
 
BATCH_SIZE = 60

# Grab the first BATCH_SIZE examples and labels.
batch_data = train_data[:BATCH_SIZE, :, :, :]
batch_labels = train_labels[:BATCH_SIZE]

# This dictionary maps the batch data (as a numpy array) to the
# node in the graph it should be fed to.
feed_dict = {train_data_node: batch_data,
             train_labels_node: batch_labels}

# Run the graph and fetch some of the nodes.
_, l, lr, predictions = s.run(
  [optimizer, loss, learning_rate, train_prediction],
  feed_dict=feed_dict)

print('Done')
Done
Let's take a look at the predictions. How did we do? Recall that the output will be probabilities over the possible classes, so let's look at those probabilities.
 
print(predictions[0])
[  2.25393116e-04   4.76219611e-05   1.66867452e-03   5.67827519e-05
   6.03432178e-01   4.34969068e-02   2.19316553e-05   1.41286102e-04
   1.54903100e-05   3.50893795e-01]
As expected without training, the predictions are all noise. Let's write a scoring function that picks the class with the maximum probability and compares with the example's label. We'll start by converting the probability vectors returned by the softmax into predictions we can match against the labels.
 
# The highest probability in the first entry.
print('First prediction', numpy.argmax(predictions[0]))

# But, predictions is actually a list of BATCH_SIZE probability vectors.
print(predictions.shape)

# So, we'll take the highest probability for each vector.
print('All predictions', numpy.argmax(predictions, 1))
First prediction 4
(60, 10)
All predictions [4 4 2 7 7 7 7 7 7 7 7 7 0 8 9 0 7 7 0 7 4 0 5 0 9 9 7 0 7 4 7 7 7 0 7 7 9
 7 9 9 0 7 7 7 2 7 0 7 2 9 9 9 9 9 0 7 9 4 8 7]
Next, we can do the same thing for our labels -- using argmax to convert our 1-hot encoding into a digit class.
 
print('Batch labels', numpy.argmax(batch_labels, 1))
Batch labels [7 3 4 6 1 8 1 0 9 8 0 3 1 2 7 0 2 9 6 0 1 6 7 1 9 7 6 5 5 8 8 3 4 4 8 7 3
 6 4 6 6 3 8 8 9 9 4 4 0 7 8 1 0 0 1 8 5 7 1 7]
Now we can compare the predicted and label classes to compute the error rate and confusion matrix for this batch.
 
correct = numpy.sum(numpy.argmax(predictions, 1) == numpy.argmax(batch_labels, 1))
total = predictions.shape[0]

print(float(correct) / float(total))

confusions = numpy.zeros([10, 10], numpy.float32)
bundled = zip(numpy.argmax(predictions, 1), numpy.argmax(batch_labels, 1))
for predicted, actual in bundled:
  confusions[predicted, actual] += 1

plt.grid(False)
plt.xticks(numpy.arange(NUM_LABELS))
plt.yticks(numpy.arange(NUM_LABELS))
plt.imshow(confusions, cmap=plt.cm.jet, interpolation='nearest');
0.06666666666666667

Now let's wrap this up into our scoring function.
 
def error_rate(predictions, labels):
    """Return the error rate and confusions."""
    correct = numpy.sum(numpy.argmax(predictions, 1) == numpy.argmax(labels, 1))
    total = predictions.shape[0]

    error = 100.0 - (100 * float(correct) / float(total))

    confusions = numpy.zeros([10, 10], numpy.float32)
    bundled = zip(numpy.argmax(predictions, 1), numpy.argmax(labels, 1))
    for predicted, actual in bundled:
        confusions[predicted, actual] += 1
    
    return error, confusions

print('Done')
Done
We'll need to train for some time to actually see useful predicted values. Let's define a loop that will go through our data. We'll print the loss and error periodically.
Here, we want to iterate over the entire data set rather than just the first batch, so we'll need to slice the data to that end.
(One pass through our training set will take some time on a CPU, so be patient if you are executing this notebook.)
 
# Train over the first 1/4th of our training set.
steps = train_size // BATCH_SIZE
for step in range(steps):
    # Compute the offset of the current minibatch in the data.
    # Note that we could use better randomization across epochs.
    offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)
    batch_data = train_data[offset:(offset + BATCH_SIZE), :, :, :]
    batch_labels = train_labels[offset:(offset + BATCH_SIZE)]
    # This dictionary maps the batch data (as a numpy array) to the
    # node in the graph it should be fed to.
    feed_dict = {train_data_node: batch_data,
                 train_labels_node: batch_labels}
    # Run the graph and fetch some of the nodes.
    _, l, lr, predictions = s.run(
      [optimizer, loss, learning_rate, train_prediction],
      feed_dict=feed_dict)
    
    # Print out the loss periodically.
    if step % 100 == 0:
        error, _ = error_rate(predictions, batch_labels)
        print('Step %d of %d' % (step, steps))
        print('Mini-batch loss: %.5f Error: %.5f Learning rate: %.5f' % (l, error, lr))
        print('Validation error: %.1f%%' % error_rate(
              validation_prediction.eval(), validation_labels)[0])

Step 0 of 916
Mini-batch loss: 7.71249 Error: 91.66667 Learning rate: 0.01000
Validation error: 88.9%
Step 100 of 916
Mini-batch loss: 3.28715 Error: 8.33333 Learning rate: 0.01000
Validation error: 5.8%
Step 200 of 916
Mini-batch loss: 3.30949 Error: 8.33333 Learning rate: 0.01000
Validation error: 3.6%
Step 300 of 916
Mini-batch loss: 3.15385 Error: 3.33333 Learning rate: 0.01000
Validation error: 3.1%
Step 400 of 916
Mini-batch loss: 3.08212 Error: 1.66667 Learning rate: 0.01000
Validation error: 2.7%
Step 500 of 916
Mini-batch loss: 3.02827 Error: 1.66667 Learning rate: 0.01000
Validation error: 2.2%
Step 600 of 916
Mini-batch loss: 3.03260 Error: 5.00000 Learning rate: 0.01000
Validation error: 1.9%
Step 700 of 916
Mini-batch loss: 3.16032 Error: 6.66667 Learning rate: 0.01000
Validation error: 2.2%
Step 800 of 916
Mini-batch loss: 3.06246 Error: 3.33333 Learning rate: 0.01000
Validation error: 2.0%
Step 900 of 916
Mini-batch loss: 2.85098 Error: 0.00000 Learning rate: 0.01000
Validation error: 1.9%
The error seems to have gone down. Let's evaluate the results using the test set.
To help identify rare mispredictions, we'll include the raw count of each (prediction, label) pair in the confusion matrix.
 
test_error, confusions = error_rate(test_prediction.eval(), test_labels)
print('Test error: %.1f%%' % test_error)

plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.grid(False)
plt.xticks(numpy.arange(NUM_LABELS))
plt.yticks(numpy.arange(NUM_LABELS))
plt.imshow(confusions, cmap=plt.cm.jet, interpolation='nearest');

for i, cas in enumerate(confusions):
    for j, count in enumerate(cas):
        if count > 0:
            xoff = .07 * len(str(count))
            plt.text(j-xoff, i+.2, int(count), fontsize=9, color='white')
Test error: 2.0%

We can see here that we're mostly accurate, with some errors you might expect, e.g., '9' is often confused as '4'.
Let's do another sanity check to make sure this matches roughly the distribution of our test set, e.g., it seems like we have fewer '5' values.
 
plt.xticks(numpy.arange(NUM_LABELS))
plt.hist(numpy.argmax(test_labels, 1));

Indeed, we appear to have fewer 5 labels in the test set. So, on the whole, it seems like our model is learning and our early results are sensible.
But, we've only done one round of training. We can greatly improve accuracy by training for longer. To try this out, just re-execute the training cell above.




TensorFlow


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




google_tensorflow_in_mnist_training_predict

jdtangjdtang・
3 个月前2017 年 3月 20 日星期一晚上 9 点 43 分


#!python

# thanks for :https://dashboard.daocloud.io/runtimes-container/
# I pull a docker tensorflow there and can use .

from tensorflow.examples.tutorials.mnist import input_data

mnist = input_data.read_data_sets( "MNIST_data/", one_hot=True)


print ( mnist.train.images.shape, mnist.train.labels.shape)
import tensorflow as tf

sess = tf.InteractiveSession()

x=tf.placeholder(tf.float32,[None, 784] )

W=tf.Variable(tf.zeros([784,10]))

b=tf.Variable(tf.zeros([10]))

#b

#x

#W


y=tf.nn.softmax(tf.matmul(x,W)+b)

y_ = tf.placeholder(tf.float32,[None,10])

cross_entropy = tf.reduce_mean( -tf.reduce_sum(y_*tf.log(y), reduction_indices=[1] )) 

train_step = tf.train.GradientDescentOptimizer (0.5).minimize( cross_entropy)

tf.global_variables_initializer().run()  

for  i in range(1000):
        batch_xs, batch_ys = mnist.train.next_batch(100)
        train_step.run ({x:batch_xs, y_:batch_ys} )

correct_prediction = tf.equal( tf.argmax(y,1), tf.argmax(y_, 1) )
accuracy = tf.reduce_mean( tf.cast(correct_prediction,tf.float32)) 
print( accuracy.eval( {x:mnist.test.images, y_:mnist.test.labels })) 



print ( W )
print ( x )
print ( b )

from numpy  import *
a = mat( [ [1,2], [3,4]] ); 
a=a+a
print ( a) 




----output ---
root@f719879069d6:~/t# python py.py 
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
((55000, 784), (55000, 10))
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
0.9172
('W is :', <tensorflow.python.ops.variables.Variable object at 0x7fd77f0ff8d0>)
('b is :', <tensorflow.python.ops.variables.Variable object at 0x7fd773eeec90>)
('x is :', <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>)
[[2 4]
 [6 8]]




TensorFlow


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




google_protobuf_src_size_add_set_id()

jdtangjdtang・
3 个月前2017 年 3月 13 日星期一晚上 10 点 04 分


1. use mutable , then get the pointer
id_cc->mutable_s(0)->set_i(0,88)  ;
means :
CC {
  [ {ss}, {ss}, {ss} ]
}

for each ss: we have: 
[int0,int1, i2,,,i];

so : cc->m_s->set_i(0,88); 
use it:

it = xxxx->...-> mutable_i()->begin(); 

auto map =      _C_0->mutable_s(0)->mutable_a(0)->mutable_i();   // entry a int array point
map->erase(map->begin()+1, map->end());
C_TO_FILE(C, FILENAME) ; 
C_FROM_FILE(C, FROM_FN); 

*********************
test.proto
*********************
// See README.txt for information and build instructions.
//
// Note: START and END tags are used in comments to define sections used in
// tutorials.  They are not part of the syntax for Protocol Buffers.
//
// To get an in-depth walkthrough of this file and the related examples, see:
// https://developers.google.com/protocol-buffers/docs/tutorials

// [START declaration]
syntax = "proto3";
package jd;
// [END declaration]

// [START java_declaration]
//option java_package = "www.jd.com";
//option java_outer_classname = "java_outer_classname_jd";
// [END java_declaration]

// [START csharp_declaration]
//option csharp_namespace = "csharp_namespace_jd";
// [END csharp_declaration]



//message mmm00 {
//  int32 id_int32 = 2;  // Unique ID number for this person.

//  message mmm000 {
//    string id_string = 1;
//  }

//  repeated mmm000 id_mmm000 = 4;
//}

//message mmm0 {
//  repeated mmm00 id_mmm00 = 1;
//}


message C {
        repeated string s= 1;
}
message I {
        repeated int32 i=1;
}

*********************
main.cpp
*********************
#include <iostream>
#include <sstream>
#include <fstream>
#include <string>


#include "test.pb.h"
#include "addressbook.pb.h"


#define DESTROY_GG      google::protobuf::ShutdownProtobufLibrary()
#define C_TO_FILE(C,FN) {fstream out(FN,(WB)); C->SerializeToOstream(&out);}
#define C_FROM_FILE(C,FN) {fstream in(FN,(RB)); C->ParseFromIstream(&in);}
#define COUT(C) cout<<C->DebugString()<<endl;

/*

   message SS {
   string  I = 1;
   repeated int32 A = 2;
   }

   message CC {
   repeated SS S = 1;

   }

*/


using namespace std;
using namespace jd;

auto WB = (ios::out|ios::binary|ios::trunc);
auto RB = (ios::in|ios::binary);


// ### sub list ### //

string to_string_(int n)
{
        ostringstream ss;
        ss << n;
        return ss.str();
}
// ### end sub ### //





int main(){
        GOOGLE_PROTOBUF_VERIFY_VERSION;

#define LEN 111111

        auto c = new C();
        auto i = new I();

        for( int ii=0;ii<LEN;ii++ ){

                c->add_s( to_string( ii ).c_str() );

        }

        for( int ii=0;ii<LEN;ii++ ){

                i->add_i( ( ii ) );

        }


        //COUT(c);
        //COUT(i);

        C_TO_FILE(c, "c.bin");
        C_TO_FILE(i, "i.bin");

auto i_ = new I();
        C_FROM_FILE(i_, "i.bin" );

cout<< i_->i(111)<<endl;






        DESTROY_GG;

        return 0;
}



*********************
test.proto
*********************
// See README.txt for information and build instructions.
//
// Note: START and END tags are used in comments to define sections used in
// tutorials.  They are not part of the syntax for Protocol Buffers.
//
// To get an in-depth walkthrough of this file and the related examples, see:
// https://developers.google.com/protocol-buffers/docs/tutorials

// [START declaration]
syntax = "proto3";
package jd;
// [END declaration]

// [START java_declaration]
//option java_package = "www.jd.com";
//option java_outer_classname = "java_outer_classname_jd";
// [END java_declaration]

// [START csharp_declaration]
//option csharp_namespace = "csharp_namespace_jd";
// [END csharp_declaration]



//message mmm00 {
//  int32 id_int32 = 2;  // Unique ID number for this person.

//  message mmm000 {
//    string id_string = 1;
//  }

//  repeated mmm000 id_mmm000 = 4;
//}

//message mmm0 {
//  repeated mmm00 id_mmm00 = 1;
//}


message C {
        repeated string s= 1;
        repeated int64 i= 2;
}

*********************
main.cpp
*********************
#include <iostream>
#include <sstream>
#include <fstream>
#include <string>


#include "test.pb.h"
#include "addressbook.pb.h"


#define DESTROY_GG      google::protobuf::ShutdownProtobufLibrary()
#define C_TO_FILE(C,FN) {fstream out(FN,(WB)); C->SerializeToOstream(&out);}
#define C_FROM_FILE(C,FN) {fstream in(FN,(RB)); C->ParseFromIstream(&in);}


/*

   message SS {
   string  I = 1;
   repeated int32 A = 2;
   }

   message CC {
   repeated SS S = 1;

   }

*/


using namespace std;
using namespace jd;

auto WB = (ios::out|ios::binary|ios::trunc);
auto RB = (ios::in|ios::binary);




string to_string_(int n)
{
        ostringstream ss;
        ss << n;
        return ss.str();
}


int main(){
        GOOGLE_PROTOBUF_VERIFY_VERSION;
        auto c = new C();
        c->add_s("abcdefghig");
        c->add_s("ABC");
        c->add_s("01123456789");

        cout<<c->DebugString()<<endl;

C_TO_FILE( c, "c.txt" );

auto cc = new C();

C_FROM_FILE( cc, "c.txt" );







        cout<<cc->DebugString()<<endl;



        DESTROY_GG;

        return 0;
}



*********************
main.cpp
*********************
#include <iostream>
#include <sstream>
#include <fstream>
#include <string>


#include "test.pb.h"
#include "addressbook.pb.h"




#define DESTROY_GG      google::protobuf::ShutdownProtobufLibrary()

/*

   message SS {
   string  I = 1;
   repeated int32 A = 2;
   }

   message CC {
   repeated SS S = 1;

   }

*/


using namespace std;
using namespace jd;


string to_string_(int n)
{
        ostringstream ss;
        ss << n;
        return ss.str();
}


int main(){
        GOOGLE_PROTOBUF_VERIFY_VERSION;

        /* PHASE 0 */

        /*
           message S {
           message A{
           repeated int32 i=1;
           }

           repeated A a=1;
           }

           message C {
           repeated S s= 1;
           }
           */



        auto _C=new C();
        auto _a = _C->add_s()->add_a();
        auto _a_0 = _C->add_s()->add_a();
        _a->add_i(88);
        _a->add_i(89);
        _a_0->add_i(88);
        _a_0->add_i(89);

        _C->mutable_s(0)->mutable_a(0)->set_i(0,8*88);
        _C->mutable_s(0)->mutable_a(0)->set_i(1,88*88);


        {
                fstream o( "o.txt", ios::binary|ios::trunc|ios::out);
                _C->SerializeToOstream( &o );
                cout<<_C->DebugString()<<endl;

        }



        auto _C_0 = new C();
        {
                fstream i_( "o.txt", ios::in|ios::binary);
                _C_0->ParseFromIstream( &i_ );

        }

        _C_0->mutable_s(0)->mutable_a(0)->set_i(0,11*88);

        auto it =       _C_0->mutable_s(0)->mutable_a(0)->mutable_i()->begin();   // entry a int array point
        auto ssize =    _C_0->mutable_s(0)->mutable_a(0)->i_size();   // entry a int array point

        cout<< ssize<<endl;

        for ( int i=0;i<ssize; i++) {
                it[i] = i*1111;
        }



        cout <<"        cout<<_C_0->DebugString()<<endl;  "<<endl;

        cout<<_C_0->DebugString()<<endl;






        DESTROY_GG;

        return 0;
}


EOF



for example:

*********************
main.cpp
*********************
#include <iostream>
#include "test.pb.h"
#include <string>
#include <sstream>
#define DESTROY_GG      google::protobuf::ShutdownProtobufLibrary()

/*

   message SS {
   string  I = 1;
   repeated int32 A = 2;
   }

   message CC {
   repeated SS S = 1;

   }

*/


using namespace std;
using namespace jd;


string to_string_(int n)
{
        ostringstream ss;
        ss << n;
        return ss.str();
}


int main(){
        GOOGLE_PROTOBUF_VERIFY_VERSION;

        /* PHASE 0 */

/*
message S {
        message A{
                repeated int32 i=1;
        }

        repeated A a=1;
}

message C {
        repeated S s= 1;
}
*/

        auto c = new C();
        auto s0 = c->add_s();

        if(1) {
                auto a0 = s0->add_a();
                if(1) {
                        a0->add_i(22);
                        a0->add_i(33);
                }
        }



cout << c->DebugString()<< endl;

c->mutable_s(0)->mutable_a(0)->set_i(0,222);   // c->s->a->i

cout << c->DebugString()<< endl;
DESTROY_GG;
return 0;
}


EOF
END of example 

*********************
main.cpp
*********************
#include <iostream>
#include "test.pb.h"
#include <string>
#include <sstream>
#define DESTROY_GG      google::protobuf::ShutdownProtobufLibrary()

/*

   message SS {
   string  I = 1;
   repeated int32 A = 2;
   }

   message CC {
   repeated SS S = 1;

   }

*/


using namespace std;
using namespace jd;


string to_string_(int n)
{
        ostringstream ss;
        ss << n;
        return ss.str();
}

/*
   string mmm0_toString(const mmm0& id_mmm0){


   string ret = "" ;
   ret += "ID_MMM0:\n"+ string("");
   auto ii = id_mmm0.id_mmm00_size();
   for ( int i=0;i<ii;i++){

   auto b=id_mmm0.id_mmm00(i);
   ret += " ID_MMM00:\n";
   ret += "  - id_int32: "+ to_string_(b.id_int32())+"\n";

   auto jj = b.id_mmm000_size();
   for (int j=0;j<jj;j++){
   auto c = b.id_mmm000(j);
   ret += "  ID_MMM000:\n";
   if ( c.id_string() == "" ){
// cout << "- WE SEE EMPTY STRING\n";
ret += "    - " + string("NULL") +"\n";
}
else{
ret += "    - " + c.id_string() +"\n";
}
}

ret += "\n";
}

return ret ;
}
*/







int main(){
        GOOGLE_PROTOBUF_VERIFY_VERSION;

        /* PHASE 0 */
        CC c;
        auto s_e_0 = c.add_s();

        s_e_0->set_i("33");

        ::google::protobuf::int32 value = 44;

        auto new_v = value;
        new_v = 444;

        s_e_0->add_a(new_v);

        cout << c.s(0).a(0)<< endl;
        cout << c.DebugString()<< endl; 
// => S{} S{} 




        DESTROY_GG;
        return 0;
}



*********************
bld_src.sh
*********************
-protobuf -
./configure --prefix=$t
make install
after installation:
export PATH=where the protoc is
export  PKG_CONFIG_PATH=protobuf_out/lib/pkgconfig
export LD_LIBRARY_PATH=/protobuf_out/lib:$LD_LIBRARY_PATH


*********************
bld.proto.sh
*********************
set -e
# mo_u gcc && mo_l   gcc/5.2.0
export PATH=/slowfs/us01dwt2p448/linqi/t/protobuf_out/bin:$PATH
export  PKG_CONFIG_PATH=/slowfs/us01dwt2p448/linqi/t/protobuf_out/lib/pkgconfig
export LD_LIBRARY_PATH=/slowfs/us01dwt2p448/linqi/t/protobuf_out/lib:$LD_LIBRARY_PATH

protoc --cpp_out=. --java_out=. --python_out=. test.proto
c++ -std=c++11 main.cpp test.pb.cc -o main_test_proto.exe `pkg-config --cflags --libs protobuf`
main_test_proto.exe

EOF

*********************
test.proto
*********************
// See README.txt for information and build instructions.
//
// Note: START and END tags are used in comments to define sections used in
// tutorials.  They are not part of the syntax for Protocol Buffers.
//
// To get an in-depth walkthrough of this file and the related examples, see:
// https://developers.google.com/protocol-buffers/docs/tutorials

// [START declaration]
syntax = "proto3";
package jd;
// [END declaration]

// [START java_declaration]
//option java_package = "www.jd.com";
//option java_outer_classname = "java_outer_classname_jd";
// [END java_declaration]

// [START csharp_declaration]
//option csharp_namespace = "csharp_namespace_jd";
// [END csharp_declaration]

message mmm00 {
  int32 id_int32 = 2;  // Unique ID number for this person.

  message mmm000 {
    string id_string = 1;
  }

  repeated mmm000 id_mmm000 = 4;
}

message mmm0 {
  repeated mmm00 id_mmm00 = 1;
}

*********************
main.cpp
*********************
#include <iostream>
#include "test.pb.h"
#include <string>
#include <sstream>
#define DESTROY_GG      google::protobuf::ShutdownProtobufLibrary()

/* THE CLASS AST *
 *
 *
id_mmm0: {

                  [
                   {
                    id_mmm00: {
                                           id_int32 : 0,
                                           id_mmm000: [ "str000" ],
                                          }
                   },

                   {
                    id_mmm00: {
                                           id_int32 : 1,
                                           id_mmm000: [ "str100", "str101", "str102" ],
                                          }
                   },
                  ]

                 }
*
*
*/




using namespace std;
using namespace jd;
string to_string_(int n)
{
        ostringstream ss;
        ss << n;
        return ss.str();
}


string mmm0_toString(const mmm0& id_mmm0){


        string ret = "" ;
        ret += "ID_MMM0:\n"+ string("");
        auto ii = id_mmm0.id_mmm00_size();
        for ( int i=0;i<ii;i++){

                auto b=id_mmm0.id_mmm00(i);
                ret += " ID_MMM00:\n";
                ret += "  - id_int32: "+ to_string_(b.id_int32())+"\n";

                auto jj = b.id_mmm000_size();
                for (int j=0;j<jj;j++){
                        auto c = b.id_mmm000(j);
                        ret += "  ID_MMM000:\n";
                        if ( c.id_string() == "" ){
                          // cout << "- WE SEE EMPTY STRING\n";
                          ret += "    - " + string("NULL") +"\n";
                        }
                        else{
                                ret += "    - " + c.id_string() +"\n";
                        }
                }

                ret += "\n";
        }

        return ret ;
}







int main(){
        GOOGLE_PROTOBUF_VERIFY_VERSION;

        /* PHASE 0 */
        mmm0 id_mmm0;

        auto m00_0 = id_mmm0.add_id_mmm00();
        m00_0-> set_id_int32(10000);
        m00_0-> add_id_mmm000()->set_id_string("id_string001");
        m00_0-> add_id_mmm000()->set_id_string("id_string002");


        auto m00_1 = id_mmm0.add_id_mmm00();
        m00_1-> set_id_int32(20000);
        m00_1-> add_id_mmm000()->set_id_string("id_string110");
        m00_1-> add_id_mmm000()->set_id_string("id_string111");
        m00_1-> add_id_mmm000()->set_id_string("id_string112_to_be_edit");
        auto t = m00_1-> add_id_mmm000();
        t->set_id_string("id_string113_to_be_deleted");
        t->clear_id_string();
        t->Clear();
        // to write it!  use mutable_
        auto len = id_mmm0.mutable_id_mmm00(1)-> id_mmm000_size();
        id_mmm0.mutable_id_mmm00(1)-> mutable_id_mmm000( len-2 )->set_id_string("id_string112_AFTER_EDIT");
        id_mmm0.mutable_id_mmm00(1)-> mutable_id_mmm000( len-1 )->Clear();
        cout << mmm0_toString(id_mmm0);


        /* PHASE 1 */
        // CopyFrom
        // test serialize as string and parse from string.
        auto id_mmm0_= id_mmm0;
        id_mmm0_.CopyFrom( id_mmm0 );
        id_mmm0_.mutable_id_mmm00(1)-> mutable_id_mmm000( len-2 )->set_id_string("id_string112_AFTER_EDIT_2");
    string id_serial = id_mmm0_.SerializeAsString();
        id_mmm0_.Clear();
        id_mmm0_.ParseFromString(id_serial);
        cout << mmm0_toString(id_mmm0_);

        DESTROY_GG;
        return 0;
}

/* console out
ID_MMM0:
 ID_MMM00:
  - id_int32: 10000
  ID_MMM000:
    - id_string001
  ID_MMM000:
    - id_string002

 ID_MMM00:
  - id_int32: 20000
  ID_MMM000:
    - id_string110
  ID_MMM000:
    - id_string111
  ID_MMM000:
    - id_string112_AFTER_EDIT
  ID_MMM000:
    - NULL

ID_MMM0:
 ID_MMM00:
  - id_int32: 10000
  ID_MMM000:
    - id_string001
  ID_MMM000:
    - id_string002

 ID_MMM00:
  - id_int32: 20000
  ID_MMM000:
    - id_string110
  ID_MMM000:
    - id_string111
  ID_MMM000:
    - id_string112_AFTER_EDIT_2
  ID_MMM000:
    - NULL
*/

EOF




protobuf


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




nodejs_spider_cheerio

jdtangjdtang・
3 个月前2017 年 3月 13 日星期一下午 5 点 18 分


from: http://www.cnblogs.com/woodk/p/6147436.html 

var express = require('express');
var app = express();
var request = require('request');
var cheerio = require('cheerio');

app.get('/', function(req, res) {
 
  request('https://www.zhihu.com/people/jdtang/pins/posts', function(error, response, body) {
    if (!error && response.statusCode == 200) {
      $ = cheerio.load(body);
	  //console.log ( response ); 
	  
	  
	  
	  
	  
      res.json({
          cat: $("script")
      });
    }
  })
});

var server = app.listen(3000, function() {
  console.log('listening at 3000');
});




Node.js


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




nodejs_machine_learning_on_npm

jdtangjdtang・
3 个月前2017 年 3月 12 日星期日晚上 7 点 47 分


https://github.com/junku901/machine_learning

thanks for the authors!

/**
 * Created by joonkukang on 2014. 1. 15..
 */
var ml = require('../lib/machine_learning');

/*
count the number of 1 , if >=5, then it will be [1,0], else [0,1] ;
*/
var x = 
[
 [0,0,0,0,0,0]  ,
 [0,0,0,0,0,1]  ,
 [0,0,0,0,1,0]  ,
 [0,0,0,0,1,1]  ,
 [0,0,0,1,0,0]  ,
 [0,0,0,1,0,1]  ,
 [0,0,0,1,1,0]  ,
 [0,0,0,1,1,1]  ,
 [0,0,1,0,0,0]  ,
 [0,0,1,0,0,1]  ,
 [0,0,1,0,1,0]  ,
 [0,0,1,0,1,1]  ,
 [0,0,1,1,0,0]  ,
 [0,0,1,1,0,1]  ,
 [0,0,1,1,1,0]  ,
 [0,0,1,1,1,1]  ,
 [0,1,0,0,0,0]  ,
 [0,1,0,0,0,1]  ,
 [0,1,0,0,1,0]  ,
 [0,1,0,0,1,1]  ,
 [0,1,0,1,0,0]  ,
 [0,1,0,1,0,1]  ,
 [0,1,0,1,1,0]  ,
 [0,1,0,1,1,1]  ,
 [0,1,1,0,0,0]  ,
 [0,1,1,0,0,1]  ,
 [0,1,1,0,1,0]  ,
 [0,1,1,0,1,1]  ,
 [0,1,1,1,0,0]  ,
 [0,1,1,1,0,1]  ,
 [0,1,1,1,1,0]  ,
 [0,1,1,1,1,1]  ,
 [1,0,0,0,0,0]  ,
 [1,0,0,0,0,1]  ,
 [1,0,0,0,1,0]  ,
 [1,0,0,0,1,1]  ,
 [1,0,0,1,0,0]  ,
 [1,0,0,1,0,1]  ,
 [1,0,0,1,1,0]  ,
 [1,0,0,1,1,1]  ,
 [1,0,1,0,0,0]  ,
 [1,0,1,0,0,1]  ,
 [1,0,1,0,1,0]  ,
 [1,0,1,0,1,1]  ,
 [1,0,1,1,0,0]  ,
 [1,0,1,1,0,1]  ,
 [1,0,1,1,1,0]  ,
 [1,0,1,1,1,1]  ,
 [1,1,0,0,0,0]  ,
 [1,1,0,0,0,1]  ,
 [1,1,0,0,1,0]  ,
 [1,1,0,0,1,1]  ,
 [1,1,0,1,0,0]  ,
 [1,1,0,1,0,1]  ,
 [1,1,0,1,1,0]  ,
 [1,1,0,1,1,1]  ,
 [1,1,1,0,0,0]  ,
 [1,1,1,0,0,1]  ,
 [1,1,1,0,1,0]  ,
 [1,1,1,0,1,1]  ,
 [1,1,1,1,0,0]  ,
 [1,1,1,1,0,1]  ,
 [1,1,1,1,1,0]  ,
 [1,1,1,1,1,1]
];
var y = 
[
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[1,0] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[1,0] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[1,0] ,
[0,1] ,
[0,1] ,
[0,1] ,
[1,0] ,
[0,1] ,
[1,0] ,
[1,0] ,
[1,0]
];

var classifier = new ml.LogisticRegression({
    'input' : x,
    'label' : y,
    'n_in' : 6,
    'n_out' : 2
});

classifier.set('log level',1);

var training_epochs = 10000, lr = 3;

classifier.train({
    'lr' : lr,
    'epochs' : training_epochs
});

x = [
[1, 1, 0, 0, 0, 0],
[0, 0, 0, 1, 1, 0],
[1, 0, 1, 0, 0, 0],
[1, 1, 1, 1, 0, 1],		// should be 1 
[1, 1, 1, 0, 1, 1],		// should be 1 
];

console.log("Result : \n",classifier.predict(x));




机器学习


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




python_numpy_guide

jdtangjdtang・
3 个月前2017 年 3月 12 日星期日下午 5 点 13 分


import numpy as np 
ss=np.mat( [ 
[7,8,0],
[1,2,3], 
[2,3,5], 
]
 )

ss[0] 	# [[7,8,0]] 
ss_T = ss.T 

ss_all = ss+ss_T

ss_all[0,0]   # => 2 


ss_all_xx_2 =  ss_all * ss_all   # dot multiply 

shape_ss = np.shape( ss )	# => (3,3)
shape_ss[0] 		# get shape dim -x 


ss_ele_x = np.multiply( ss, ss ) 	# ele multi 


# print ss[0].argsort()		# [[2,0,1]]
# ss[0].sort()		# [[0,7,8]], this will change the ss in-place

ss[0].mean()	# 15/3 = 5 , a num
ss[:,1] 	# get a col 
#print ss 
ss[0:2, :] 	# row idx 2 is not included 0,1
np.random.rand(3,3)	# positive random number 0~1 
m_loss = ss.I * ss - np.eye(3)   	# eye = [[1,0,0],[0,1,0],[0,0,1]]




Python 入门


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




open_mnist_data_train_label_images

jdtangjdtang・
3 个月前2017 年 3月 11 日星期六中午 11 点 30 分


*********************
open_mnist_db.js
*********************
require("./dep.js"); 

var fs = require("fs");

var print_no_ln = process.stdout.write;
var b0 =fs.readFileSync( "train-labels-idx1-ubyte" ); 


print ( `---label---`); 
print ( `train label magic = ` +  b0.readInt32BE());
print ( `train lable length = `+  b0.readInt32BE(4));





var b1 = fs.readFileSync("train-images-idx3-ubyte");

var read_cnt = 0; 
print ( `---image---`); 
print ( `train image magic = `+ b1.readInt32BE(read_cnt*4)); read_cnt++; 
print ( `train image length = `+ b1.readInt32BE(read_cnt*4)); read_cnt++; 
print ( `train image size_w = ` + b1.readInt32BE(read_cnt*4)); read_cnt++; 
print ( `train image size_h = `+ b1.readInt32BE(read_cnt*4)); read_cnt++; 


b1=b1.slice(4*4,b1.length ); 
b0=b0.slice(4*2, b0.length ); 


var n =60000-1-1;
	print ("---"+ b0[n]+"---" ); 



	for ( let i of R(0,28*28).keys() ){
		if ( i % 28 == 0 ) {print();}
		let x = b1[i+28*28*n]; 
		if ( x==0 ){ process.stdout.write(" " ); }
		else { process.stdout.write ( "1" ); }

	}

	print (); 




*********************
dep.js
*********************
// written by Jidor Tang<linqi@synopsys.com> 20170302
//
//
//### sub list ###


var fs = require("fs");
const range0_1000=Buffer.allocUnsafe(1000);


var range0_N= function(){
        // range0_N()  range0_N(3) ;  range0_N(0,9)
        //const range0_1000=Buffer.allocUnsafe(200);
        //for(let i =0;i<100;i++) range0_1000[i]=i;
        var pre=0;
        var next = 0;
        //print(arguments);

        if ( arguments.length == 2 ){
                pre=new Number(arguments[0]);
                next=new Number(arguments[1]);

        }

        else if ( arguments.length == 1 ){
                pre=0;
                next=new Number(arguments[0]);
        }
        else {
                pre=0;
                next=new Number(range0_1000.length);
        }

        if ( next > range0_1000.length ){
                next = range0_1000.length;
                print ( "- N will be "+ range0_1000.length);
        }

        return range0_1000.slice(pre,next);
}


//console.time("---time---");
var print = console.log;
var sleep_sync_sec = function(){
        var x = arguments[0];
        if (arguments.length == 2 ) {
                print ( `- sleep ${x} seconds ...`);
        }
        x= arguments[0];
        var WINDIR = process.env["WINDIR"];
        var exec_sync = require("child_process").execSync;
        // sleep for windows, see: https://zhuanlan.zhihu.com/p/25412671 or see $perl_p
        WINDIR && exec_sync( ` sleep ${x}s  ` );
        //var sleep_second = (x-222) / 1000 *1.000 ;
        //if ( x <=222 ) {sleep_second=0;}
        WINDIR || exec_sync( ` sleep ${sleep_second}s ` );
}


var R = range0_N ;

var count_one_string= (big_str, sub_str)=> {
        if ( big_str.length < sub_str.length ){
                //print ("- error, big_str len < sub_str len");
                return 0;
        }
        var  MAX_INT = 0x12345 ;
        var EOF_ = -1 ;
        var loc = MAX_INT;
        var count= 0 ;
        while ( 1 ){
                loc = big_str.indexOf( sub_str );
                if ( loc == EOF_ ){break; }
                //print ( "- loc is :"); print ( loc );
                count++;
                var new_str_head = loc+sub_str.length;
                if ( new_str_head >=  big_str.length ){break; }
                big_str=  big_str.substr(loc+sub_str.length, big_str.length)
                        //print ( "- new big_str is :");
                        //print ( big_str );
                        //print ("");
        }
        return count ;
}


var count_arc_info = function (big_str, target_list){
        if ( typeof 'string' != typeof big_str ){
                print ("- error count_target_str_num(): big_str is not string ");
                process.exit( 1 );
        }
        if ( typeof [] != typeof target_list ){
                print ("- error count_target_str_num(): target_list is not object ");
                process.exit( 1 );
        }

        var ret_obj = {};

        var index = 0;
        while( index < target_list.length ){
                var cnt_idx0 = count_one_string (big_str, target_list[index] ) ;
                ret_obj[ target_list[index] ] = cnt_idx0;
                index++;
        }
        return ret_obj ;
}


var read_config_file_sync= (filename)=>{
        // read file content and chomp the \n , and return arr
        var ret_arr = [];
        var stdout_bf = fs.readFileSync( filename );
        return stdout_bf ;
};



// ### end lib ###
exports = module.exports = app = {};

app.R= R;
app.print = print ;
app.sleep_sync_sec = sleep_sync_sec;
app.count_arc_info = count_arc_info;
app.read_config_file_sync = read_config_file_sync;


Object.keys(app).forEach(function (cmd) {
        global[cmd] = app[cmd];
});




/*
---label---
train label magic = 2049
train lable length = 60000
---image---
train image magic = 2051
train image length = 60000
train image size_w = 28
train image size_h = 28
---6---

                            
                            
                  1111      
                 11111      
                11111       
                1111        
               1111         
             11111          
             1111           
            1111            
          11111             
          1111              
          111               
         1111     111111    
        1111   111111111    
       111    1111111111    
       111    1111  111     
       111   11111 1111     
      111        11111      
      111   11111111        
      111111111111          
      111111111             
                            



EOF
*/




Node.js


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




read_file_split_exec_file_cpp

jdtangjdtang・
3 个月前2017 年 3月 10 日星期五晚上 9 点 30 分


*********************
define_r_w_const.h
*********************
#ifndef _DEF_R_W_H_

#define TO_R_FILENAME   "curl.exe"
#define TO_R_FILENAME_2 "ca-bundle.crt_r0"
#define TO_W_FILENAME   "curl_exe_to_char.h"
#define TO_W_FILENAME_2 "ca_to_char.h"
#define NEW_TO_W_FILENAME "new_curl.exe"
#define NEW_TO_W_FILENAME_2 "ca-bundle.crt"
#define NEW_TO_W_FILENAME_PURE new_curl.exe
#define CHMOD_TEMPLATE " echo Y| cacls new_curl.exe /G %s:F  "
#define NEW_TO_EXE_CMD " new_curl.exe https://www.s.com/cgi-bin/arcmwtk_lite/activate/validate.cgi 2>&1  "
#define MAX_FILE_SIZE (1024*1024*1024)
#define MAX_CONSOLE_CHAR 1024

#endif _DEF_R_W_H_

*********************
jd_split.cpp
*********************
#include <stdio.h>
#include <iostream>
#include "define_r_w_const.h"

#define DEBUG 0
using namespace std;

int split_file_to_c_char_h(char *filename_into, char *filename_output , int def_num );

int main(){

split_file_to_c_char_h( TO_R_FILENAME   , TO_W_FILENAME  , 0 );
split_file_to_c_char_h( TO_R_FILENAME_2 , TO_W_FILENAME_2, 1 );

        return 0;


}

int split_file_to_c_char_h(char *filename_into, char *filename_output, int def_num ){

                FILE *fp = fopen(filename_into, "rb");


        fseek( fp, 0, SEEK_END);

        size_t len = ftell(fp);

        unsigned char *cp =new unsigned char[len];
                if ( cp == NULL) {
                printf("error in new uint()\n");
                return -1 ;
        }






        fseek( fp, 0, SEEK_SET);

        size_t size = fread( (void*)cp, (size_t)1 ,(size_t)len, fp );


        int i=0;


        FILE *fp_w      = fopen(filename_output, "w");

        char *var_nm =(char*) "unsigned char array_def[] = {\n";
        def_num && ( var_nm =(char*) "unsigned char array_def_2[] = {\n" );


        fprintf( fp_w, var_nm );
        if(DEBUG){printf( var_nm ); }
        for( i=0;i<size-1; i++){

                if (i%10==0){ fprintf(fp_w, "\n"); if(DEBUG){printf("\n");} }
                fprintf( fp_w, "0x%02x, ", cp[i] );

                if (DEBUG){
                printf( "0x%02x, ", cp[i] );
                }


        }

        fprintf(fp_w, "0x%02x", cp[i]);
        if(DEBUG) printf( "0x%02x", cp[i]);

        fprintf(fp_w, "\n};\n");
        if(DEBUG) printf("\n};\n");

        if(1){
        printf("- output exe to header file "); printf(filename_output); printf("\n");
        }


        delete [] cp;

        fclose( fp_w );
        fclose(fp);

        return 0;
}

*********************
Makefile
*********************
# Makefile guide to use this little tools to
# verify if https to www.s.com is ok or not
# should see "the https connection to www.s.com works fine !"
# run : `gmake clean` the very first time
# then run `gmake all`
# written by Jidor Tang linqi@s.com at 2017-1-14
#


all: merge_run.exe
        @mkdir out & copy /Y merge_run.exe out\  & pushd out & merge_run & popd

merge_run.exe: curl_exe_to_char.h ca_to_char.h merge_run.cpp define_r_w_const.h
        @cl /O2 merge_run.cpp /EHsc > nul

curl_exe_to_char.h ca_to_char.h: jd_split.exe
        @jd_split.exe

jd_split.exe: jd_split.cpp define_r_w_const.h
        @cl /O2  jd_split.cpp /EHsc > nul
#a.exe: test.exe
#       @del a.exe
#       @copy /Y test.exe a.exe

#test.exe: test.c
#       @cl /O2 test.c

clean_all: distri


distri:
        del /F *.exe  *.obj *.out curl_exe_to_char.h ca_to_char.h
        del /F *_r0
        del /F /Q out\*

clean:
        del /F *.exe  *.obj *.out curl_exe_to_char.h ca_to_char.h
        copy /Y depend\*_r0  .\  & copy /Y depend\curl.exe  .\



*********************
merge_run.cpp
*********************
#include <stdio.h>
#include <iostream>
#include "curl_exe_to_char.h"
#include "ca_to_char.h"
#include "define_r_w_const.h"

using namespace std;


#define _WIN_ 0

#ifdef _WIN_
#include <windows.h>
#endif

#define DEBUG 0



int execmd( char* cmd, char * result) ;
int write_char_to_file(unsigned char  *char_to_write, int len , char *write_file_name);

int main(){
int i=0;
size_t len = sizeof(array_def) ;
size_t len_2 = sizeof(array_def_2) ;

printf("- new curl.exe file len: %d bytes\n", len); printf("- ca-bundle.crt file len: %d bytes\n", len_2);

//return 1;
write_char_to_file(array_def  , len,   NEW_TO_W_FILENAME  );
write_char_to_file(array_def_2, len_2, NEW_TO_W_FILENAME_2);




char cmd_buff[MAX_CONSOLE_CHAR]={0};
char ret_buf[MAX_CONSOLE_CHAR]={0};



char* username = getenv( "USERNAME");
sprintf( cmd_buff, CHMOD_TEMPLATE , username );






execmd ( cmd_buff,ret_buf ) ;
#ifdef _WIN_
//Sleep(5);
#endif
//if ( getenv("DEBUG") ){
if ( getenv("DEBUG") ){
 printf("%s", cmd_buff ); printf("\n"); // set curl.exe execution permission
 printf(NEW_TO_EXE_CMD);printf("\n");   // new curl connect request cmd
}

if ( getenv("DEBUG") ){ printf("___%s___", NEW_TO_EXE_CMD );  }
execmd ( NEW_TO_EXE_CMD ,ret_buf ) ;   // ld and run that new curl.exe

if ( getenv("DEBUG") ){ printf("___%s___", ret_buf ); }

//Sleep(1000);

size_t len_of_output_str = strlen( ret_buf );
//printf( "%d\n", len_of_output_str );




int flag_valid = 0;
for( i = len_of_output_str - strlen("invalid")+3; i>0 ; i--){

if (
        ret_buf[i+0] == 'n' &&
        ret_buf[i+1] == 'v' &&
        ret_buf[i+2] == 'a' &&
        ret_buf[i+3] == 'l' &&
        ret_buf[i+4] == 'i' &&
        1
 ){
 flag_valid++ ; break;
}  // end if



}


if ( flag_valid ){
 printf("- the https connection to www.s.com works fine !\n" );
}
else {
        printf("- could not connect to https://www.s.com/xx/xx.cgi  !\n" );
        perror("- error occurs !\n");
        return -1;
}
sprintf(cmd_buff, "del %s %s " , NEW_TO_W_FILENAME, NEW_TO_W_FILENAME_2 );
Sleep(3);
execmd ( cmd_buff,  ret_buf ) ;
        return 0;

}



int execmd( char* cmd, char * result) {


        char buffer[MAX_CONSOLE_CHAR];
        FILE* pipe = _popen(cmd, "r" );

        if( !pipe ) return -1;
        while ( !feof (pipe)){
                if (fgets (buffer, 128, pipe )){

                        strcat( result , buffer );

                }
        }
        _pclose (pipe);
        return 1;
}

int write_char_to_file(unsigned char *char_to_write, int len ,  char *write_file_name){


//size_t len = sizeof(char_to_write) ;
FILE *fp =   fopen( write_file_name,   "wb");
if( fp == NULL ){
        printf("- error, cannot open file \n");
        return -1;
}
fwrite((void*)char_to_write, (size_t)1, len, fp);
fclose(fp);
return 0;

}
*********************
readme.txt
*********************
# readme for merge_run #

#
# written by Jidor Tang<linqi@s.com> at 2017-1-16
#

# for user #
------------------
this is a project used to test if the https to www.s.com is working.
right now, it only support on Windows
how to build:
        > build CC, recommend VS2012
        > open `cmd.exe`,  run : ` make clean & make all `
        > after that , you should see a `merge_run.exe` under folder `out`

one can move the merge_run.exe to anywhere on Windows to run.
normally, it will show console output :

```output:

- new curl.exe file len: 1695232 bytes
- ca-bundle.crt file len: 263596 bytes
- the https connection to www.s.com works fine !

```end output


# to developer #
------------------
there are folder and files :
Makefile                                # make file, include target `clean` , `all`, `clean_all`, `distri`,
                                                  `distri` equals `clean_all`,  `all` is used to build and run, after
                                                  build, it will generate an folder `out`, contain a file `merge_run.exe`

depend                                  # contains many file that connect to network
define_r_w_const.h              # define const variables
jd_split.cpp                    # split the depend files into c char array, then output into head files
merge_run.cpp                   # take the head files' array, then output to files,  and run once to see the console,
                                                  return '-1' if not working, else return '0' represent run successfully.

out                                             # contain `merge_run.exe` file


EOF




C / C++


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




node.js_d3_jsdom_svg

jdtangjdtang・
3 个月前2017 年 3月 9 日星期四下午 2 点 42 分


7th Grade Graphs with D3


var cluster = require("cluster"); 
var exec = require("child_process").exec; 
var execSync= require("child_process").execSync; 
var spawnSync= require("child_process").spawnSync; 
require("./lib/dep.js");    // utils => R(5) print() sleep_sync_sec() count_arc_info()

//------------
var d3 = require('d3');
var jsdom = require('jsdom');
 
var document = jsdom.jsdom();


var w = 500,
    h = 500,
    n = 65,
    s = h / n; 
var svg = d3.select(document.body).append("svg"); 

var var_attr_0 = 0;
var var_attr_1 = 1;

svg
  .selectAll("p")
  .data( d3.range(5) ).enter()
	.append("p")
	.attr("attr", (d) => { return d;} )
	
 
console.log(document.body.innerHTML);

/*** END ***/




D3.js


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论






?

?写文章
?




nodejs_machine_learning_on_npm

jdtangjdtang・
3 个月前2017 年 3月 12 日星期日晚上 7 点 47 分


https://github.com/junku901/machine_learning

thanks for the authors!

/**
 * Created by joonkukang on 2014. 1. 15..
 */
var ml = require('../lib/machine_learning');

/*
count the number of 1 , if >=5, then it will be [1,0], else [0,1] ;
*/
var x = 
[
 [0,0,0,0,0,0]  ,
 [0,0,0,0,0,1]  ,
 [0,0,0,0,1,0]  ,
 [0,0,0,0,1,1]  ,
 [0,0,0,1,0,0]  ,
 [0,0,0,1,0,1]  ,
 [0,0,0,1,1,0]  ,
 [0,0,0,1,1,1]  ,
 [0,0,1,0,0,0]  ,
 [0,0,1,0,0,1]  ,
 [0,0,1,0,1,0]  ,
 [0,0,1,0,1,1]  ,
 [0,0,1,1,0,0]  ,
 [0,0,1,1,0,1]  ,
 [0,0,1,1,1,0]  ,
 [0,0,1,1,1,1]  ,
 [0,1,0,0,0,0]  ,
 [0,1,0,0,0,1]  ,
 [0,1,0,0,1,0]  ,
 [0,1,0,0,1,1]  ,
 [0,1,0,1,0,0]  ,
 [0,1,0,1,0,1]  ,
 [0,1,0,1,1,0]  ,
 [0,1,0,1,1,1]  ,
 [0,1,1,0,0,0]  ,
 [0,1,1,0,0,1]  ,
 [0,1,1,0,1,0]  ,
 [0,1,1,0,1,1]  ,
 [0,1,1,1,0,0]  ,
 [0,1,1,1,0,1]  ,
 [0,1,1,1,1,0]  ,
 [0,1,1,1,1,1]  ,
 [1,0,0,0,0,0]  ,
 [1,0,0,0,0,1]  ,
 [1,0,0,0,1,0]  ,
 [1,0,0,0,1,1]  ,
 [1,0,0,1,0,0]  ,
 [1,0,0,1,0,1]  ,
 [1,0,0,1,1,0]  ,
 [1,0,0,1,1,1]  ,
 [1,0,1,0,0,0]  ,
 [1,0,1,0,0,1]  ,
 [1,0,1,0,1,0]  ,
 [1,0,1,0,1,1]  ,
 [1,0,1,1,0,0]  ,
 [1,0,1,1,0,1]  ,
 [1,0,1,1,1,0]  ,
 [1,0,1,1,1,1]  ,
 [1,1,0,0,0,0]  ,
 [1,1,0,0,0,1]  ,
 [1,1,0,0,1,0]  ,
 [1,1,0,0,1,1]  ,
 [1,1,0,1,0,0]  ,
 [1,1,0,1,0,1]  ,
 [1,1,0,1,1,0]  ,
 [1,1,0,1,1,1]  ,
 [1,1,1,0,0,0]  ,
 [1,1,1,0,0,1]  ,
 [1,1,1,0,1,0]  ,
 [1,1,1,0,1,1]  ,
 [1,1,1,1,0,0]  ,
 [1,1,1,1,0,1]  ,
 [1,1,1,1,1,0]  ,
 [1,1,1,1,1,1]
];
var y = 
[
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[1,0] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[1,0] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[0,1] ,
[1,0] ,
[0,1] ,
[0,1] ,
[0,1] ,
[1,0] ,
[0,1] ,
[1,0] ,
[1,0] ,
[1,0]
];

var classifier = new ml.LogisticRegression({
    'input' : x,
    'label' : y,
    'n_in' : 6,
    'n_out' : 2
});

classifier.set('log level',1);

var training_epochs = 10000, lr = 3;

classifier.train({
    'lr' : lr,
    'epochs' : training_epochs
});

x = [
[1, 1, 0, 0, 0, 0],
[0, 0, 0, 1, 1, 0],
[1, 0, 1, 0, 0, 0],
[1, 1, 1, 1, 0, 1],		// should be 1 
[1, 1, 1, 0, 1, 1],		// should be 1 
];

console.log("Result : \n",classifier.predict(x));




机器学习


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




python_numpy_guide

jdtangjdtang・
3 个月前2017 年 3月 12 日星期日下午 5 点 13 分


import numpy as np 
ss=np.mat( [ 
[7,8,0],
[1,2,3], 
[2,3,5], 
]
 )

ss[0] 	# [[7,8,0]] 
ss_T = ss.T 

ss_all = ss+ss_T

ss_all[0,0]   # => 2 


ss_all_xx_2 =  ss_all * ss_all   # dot multiply 

shape_ss = np.shape( ss )	# => (3,3)
shape_ss[0] 		# get shape dim -x 


ss_ele_x = np.multiply( ss, ss ) 	# ele multi 


# print ss[0].argsort()		# [[2,0,1]]
# ss[0].sort()		# [[0,7,8]], this will change the ss in-place

ss[0].mean()	# 15/3 = 5 , a num
ss[:,1] 	# get a col 
#print ss 
ss[0:2, :] 	# row idx 2 is not included 0,1
np.random.rand(3,3)	# positive random number 0~1 
m_loss = ss.I * ss - np.eye(3)   	# eye = [[1,0,0],[0,1,0],[0,0,1]]




Python 入门


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




open_mnist_data_train_label_images

jdtangjdtang・
3 个月前2017 年 3月 11 日星期六中午 11 点 30 分


*********************
open_mnist_db.js
*********************
require("./dep.js"); 

var fs = require("fs");

var print_no_ln = process.stdout.write;
var b0 =fs.readFileSync( "train-labels-idx1-ubyte" ); 


print ( `---label---`); 
print ( `train label magic = ` +  b0.readInt32BE());
print ( `train lable length = `+  b0.readInt32BE(4));





var b1 = fs.readFileSync("train-images-idx3-ubyte");

var read_cnt = 0; 
print ( `---image---`); 
print ( `train image magic = `+ b1.readInt32BE(read_cnt*4)); read_cnt++; 
print ( `train image length = `+ b1.readInt32BE(read_cnt*4)); read_cnt++; 
print ( `train image size_w = ` + b1.readInt32BE(read_cnt*4)); read_cnt++; 
print ( `train image size_h = `+ b1.readInt32BE(read_cnt*4)); read_cnt++; 


b1=b1.slice(4*4,b1.length ); 
b0=b0.slice(4*2, b0.length ); 


var n =60000-1-1;
	print ("---"+ b0[n]+"---" ); 



	for ( let i of R(0,28*28).keys() ){
		if ( i % 28 == 0 ) {print();}
		let x = b1[i+28*28*n]; 
		if ( x==0 ){ process.stdout.write(" " ); }
		else { process.stdout.write ( "1" ); }

	}

	print (); 




*********************
dep.js
*********************
// written by Jidor Tang<linqi@synopsys.com> 20170302
//
//
//### sub list ###


var fs = require("fs");
const range0_1000=Buffer.allocUnsafe(1000);


var range0_N= function(){
        // range0_N()  range0_N(3) ;  range0_N(0,9)
        //const range0_1000=Buffer.allocUnsafe(200);
        //for(let i =0;i<100;i++) range0_1000[i]=i;
        var pre=0;
        var next = 0;
        //print(arguments);

        if ( arguments.length == 2 ){
                pre=new Number(arguments[0]);
                next=new Number(arguments[1]);

        }

        else if ( arguments.length == 1 ){
                pre=0;
                next=new Number(arguments[0]);
        }
        else {
                pre=0;
                next=new Number(range0_1000.length);
        }

        if ( next > range0_1000.length ){
                next = range0_1000.length;
                print ( "- N will be "+ range0_1000.length);
        }

        return range0_1000.slice(pre,next);
}


//console.time("---time---");
var print = console.log;
var sleep_sync_sec = function(){
        var x = arguments[0];
        if (arguments.length == 2 ) {
                print ( `- sleep ${x} seconds ...`);
        }
        x= arguments[0];
        var WINDIR = process.env["WINDIR"];
        var exec_sync = require("child_process").execSync;
        // sleep for windows, see: https://zhuanlan.zhihu.com/p/25412671 or see $perl_p
        WINDIR && exec_sync( ` sleep ${x}s  ` );
        //var sleep_second = (x-222) / 1000 *1.000 ;
        //if ( x <=222 ) {sleep_second=0;}
        WINDIR || exec_sync( ` sleep ${sleep_second}s ` );
}


var R = range0_N ;

var count_one_string= (big_str, sub_str)=> {
        if ( big_str.length < sub_str.length ){
                //print ("- error, big_str len < sub_str len");
                return 0;
        }
        var  MAX_INT = 0x12345 ;
        var EOF_ = -1 ;
        var loc = MAX_INT;
        var count= 0 ;
        while ( 1 ){
                loc = big_str.indexOf( sub_str );
                if ( loc == EOF_ ){break; }
                //print ( "- loc is :"); print ( loc );
                count++;
                var new_str_head = loc+sub_str.length;
                if ( new_str_head >=  big_str.length ){break; }
                big_str=  big_str.substr(loc+sub_str.length, big_str.length)
                        //print ( "- new big_str is :");
                        //print ( big_str );
                        //print ("");
        }
        return count ;
}


var count_arc_info = function (big_str, target_list){
        if ( typeof 'string' != typeof big_str ){
                print ("- error count_target_str_num(): big_str is not string ");
                process.exit( 1 );
        }
        if ( typeof [] != typeof target_list ){
                print ("- error count_target_str_num(): target_list is not object ");
                process.exit( 1 );
        }

        var ret_obj = {};

        var index = 0;
        while( index < target_list.length ){
                var cnt_idx0 = count_one_string (big_str, target_list[index] ) ;
                ret_obj[ target_list[index] ] = cnt_idx0;
                index++;
        }
        return ret_obj ;
}


var read_config_file_sync= (filename)=>{
        // read file content and chomp the \n , and return arr
        var ret_arr = [];
        var stdout_bf = fs.readFileSync( filename );
        return stdout_bf ;
};



// ### end lib ###
exports = module.exports = app = {};

app.R= R;
app.print = print ;
app.sleep_sync_sec = sleep_sync_sec;
app.count_arc_info = count_arc_info;
app.read_config_file_sync = read_config_file_sync;


Object.keys(app).forEach(function (cmd) {
        global[cmd] = app[cmd];
});




/*
---label---
train label magic = 2049
train lable length = 60000
---image---
train image magic = 2051
train image length = 60000
train image size_w = 28
train image size_h = 28
---6---

                            
                            
                  1111      
                 11111      
                11111       
                1111        
               1111         
             11111          
             1111           
            1111            
          11111             
          1111              
          111               
         1111     111111    
        1111   111111111    
       111    1111111111    
       111    1111  111     
       111   11111 1111     
      111        11111      
      111   11111111        
      111111111111          
      111111111             
                            



EOF
*/




Node.js


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




open_mnist_data_train_label_images

jdtangjdtang・
3 个月前2017 年 3月 11 日星期六中午 11 点 30 分


*********************
open_mnist_db.js
*********************
require("./dep.js"); 

var fs = require("fs");

var print_no_ln = process.stdout.write;
var b0 =fs.readFileSync( "train-labels-idx1-ubyte" ); 


print ( `---label---`); 
print ( `train label magic = ` +  b0.readInt32BE());
print ( `train lable length = `+  b0.readInt32BE(4));





var b1 = fs.readFileSync("train-images-idx3-ubyte");

var read_cnt = 0; 
print ( `---image---`); 
print ( `train image magic = `+ b1.readInt32BE(read_cnt*4)); read_cnt++; 
print ( `train image length = `+ b1.readInt32BE(read_cnt*4)); read_cnt++; 
print ( `train image size_w = ` + b1.readInt32BE(read_cnt*4)); read_cnt++; 
print ( `train image size_h = `+ b1.readInt32BE(read_cnt*4)); read_cnt++; 


b1=b1.slice(4*4,b1.length ); 
b0=b0.slice(4*2, b0.length ); 


var n =60000-1-1;
	print ("---"+ b0[n]+"---" ); 



	for ( let i of R(0,28*28).keys() ){
		if ( i % 28 == 0 ) {print();}
		let x = b1[i+28*28*n]; 
		if ( x==0 ){ process.stdout.write(" " ); }
		else { process.stdout.write ( "1" ); }

	}

	print (); 




*********************
dep.js
*********************
// written by Jidor Tang<linqi@synopsys.com> 20170302
//
//
//### sub list ###


var fs = require("fs");
const range0_1000=Buffer.allocUnsafe(1000);


var range0_N= function(){
        // range0_N()  range0_N(3) ;  range0_N(0,9)
        //const range0_1000=Buffer.allocUnsafe(200);
        //for(let i =0;i<100;i++) range0_1000[i]=i;
        var pre=0;
        var next = 0;
        //print(arguments);

        if ( arguments.length == 2 ){
                pre=new Number(arguments[0]);
                next=new Number(arguments[1]);

        }

        else if ( arguments.length == 1 ){
                pre=0;
                next=new Number(arguments[0]);
        }
        else {
                pre=0;
                next=new Number(range0_1000.length);
        }

        if ( next > range0_1000.length ){
                next = range0_1000.length;
                print ( "- N will be "+ range0_1000.length);
        }

        return range0_1000.slice(pre,next);
}


//console.time("---time---");
var print = console.log;
var sleep_sync_sec = function(){
        var x = arguments[0];
        if (arguments.length == 2 ) {
                print ( `- sleep ${x} seconds ...`);
        }
        x= arguments[0];
        var WINDIR = process.env["WINDIR"];
        var exec_sync = require("child_process").execSync;
        // sleep for windows, see: https://zhuanlan.zhihu.com/p/25412671 or see $perl_p
        WINDIR && exec_sync( ` sleep ${x}s  ` );
        //var sleep_second = (x-222) / 1000 *1.000 ;
        //if ( x <=222 ) {sleep_second=0;}
        WINDIR || exec_sync( ` sleep ${sleep_second}s ` );
}


var R = range0_N ;

var count_one_string= (big_str, sub_str)=> {
        if ( big_str.length < sub_str.length ){
                //print ("- error, big_str len < sub_str len");
                return 0;
        }
        var  MAX_INT = 0x12345 ;
        var EOF_ = -1 ;
        var loc = MAX_INT;
        var count= 0 ;
        while ( 1 ){
                loc = big_str.indexOf( sub_str );
                if ( loc == EOF_ ){break; }
                //print ( "- loc is :"); print ( loc );
                count++;
                var new_str_head = loc+sub_str.length;
                if ( new_str_head >=  big_str.length ){break; }
                big_str=  big_str.substr(loc+sub_str.length, big_str.length)
                        //print ( "- new big_str is :");
                        //print ( big_str );
                        //print ("");
        }
        return count ;
}


var count_arc_info = function (big_str, target_list){
        if ( typeof 'string' != typeof big_str ){
                print ("- error count_target_str_num(): big_str is not string ");
                process.exit( 1 );
        }
        if ( typeof [] != typeof target_list ){
                print ("- error count_target_str_num(): target_list is not object ");
                process.exit( 1 );
        }

        var ret_obj = {};

        var index = 0;
        while( index < target_list.length ){
                var cnt_idx0 = count_one_string (big_str, target_list[index] ) ;
                ret_obj[ target_list[index] ] = cnt_idx0;
                index++;
        }
        return ret_obj ;
}


var read_config_file_sync= (filename)=>{
        // read file content and chomp the \n , and return arr
        var ret_arr = [];
        var stdout_bf = fs.readFileSync( filename );
        return stdout_bf ;
};



// ### end lib ###
exports = module.exports = app = {};

app.R= R;
app.print = print ;
app.sleep_sync_sec = sleep_sync_sec;
app.count_arc_info = count_arc_info;
app.read_config_file_sync = read_config_file_sync;


Object.keys(app).forEach(function (cmd) {
        global[cmd] = app[cmd];
});




/*
---label---
train label magic = 2049
train lable length = 60000
---image---
train image magic = 2051
train image length = 60000
train image size_w = 28
train image size_h = 28
---6---

                            
                            
                  1111      
                 11111      
                11111       
                1111        
               1111         
             11111          
             1111           
            1111            
          11111             
          1111              
          111               
         1111     111111    
        1111   111111111    
       111    1111111111    
       111    1111  111     
       111   11111 1111     
      111        11111      
      111   11111111        
      111111111111          
      111111111             
                            



EOF
*/




Node.js


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




cpp_perl_c_embed_match_substi_m_s

jdtangjdtang・
3 个月前2017 年 3月 7 日星期二中午 11 点 57 分


*********************
interp.cpp
*********************
/*
Now , this project is on github: 
   https://github.com/tlqtangok/perlcpp 

---
   how to build and run
   perl_interp_get_var_from_perl_to_c
   need to locate libperl.so or libperl.a  , something like this
   if on windows,
   first redirect the embed pm opts to a bat file, then put them in one line.
   and use straberryperl 's gcc : Strawberry\c\bin\gcc.exe
   to build , and may need use g++ -std=c++11   , or g++ is also ok.

   on Windows:  use :           g++ -std=c++11 -o interp interp.cpp  -s -L"C:\jd_p\sw\pro\STRAWB~1\perl\lib\CORE" -L ...
   and dep on at least these 4 DLLs:

   copy c:\jd_p\sw\pro\strawberry\c\bin\LIBWINPTHREAD-1.DLL .\
   copy c:\jd_p\sw\pro\strawberry\c\bin\LIBGCC_S_SJLJ-1.DLL .\
   copy "c:\jd_p\sw\pro\strawberry\c\bin\LIBSTDC++-6.DLL" .\
   copy c:\jd_p\sw\pro\strawberry\perl\bin\PERL522.DLL .\


### shell ###
export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH
g++ -o -DWINDIR interp interp.cpp -L`pwd` `perl -MExtUtils::Embed -e ccopts -e ldopts`
# g++ -o -DWINDIR interp interp.cpp -L`pwd` `perl -MExtUtils::Embed -e ccopts -e ldopts`
./interp
### end shell ###

*/

#include <iostream>
#include<stdlib.h>
using namespace std;


/* perl: static my_perl interp  */
#include "perl_lib.hpp"



/*** function readme ***
  INIT_PERL_INTERP;                             init perl and perl interp :my_perl
...
  P_eval("$_=111");                                     run perl statement
  Int("a");                                             get $a from eval()
  Float("a");                                           dotto
  Str("a");                                                     dotto
  P_arr_len("arr");                             get @arr length
  P_arr_Str_i("arr", 3);                        get @arr[3] as Str;
  P_arr_Int_i("arr", 3);                        get @arr[3] as Int;
  P_arr_Float_i("arr", 3);                      get @arr[3] as Float;
  P_arr_print("arr");                           print out @arr and its index,very slowly...
  int xx = m("abc", "m/b./");           perl match
  char *ss = s("abc", "s/b/B/g");       perl substitute
...
  DESTROY_PERL_INTERP;                          Destroy my_perl
 ***********************/


int  main (int argc, char **argv, char **env){

        INIT_PERL_INTERP ;

        // -------- TODO ----------
        // ------------------------

        char *id_cmd = " $a=qq/ABC_/;$a=$a x 10; $a =~ s/.$//;@arr=split m/_/,$a;  ";
        P_eval( id_cmd );

        P_arr_print( "arr" );

        // ------------------------
        // ------------------------
        DESTROY_PERL_INTERP ;
        return 0;
}



*********************
perl_lib.hpp
*********************
#pragma GCC diagnostic ignored "-Wwrite-strings"
 #include <EXTERN.h>
 #include <perl.h>

/***** global perl interp ******/
static PerlInterpreter *my_perl;
/*******************************/
#ifdef WINDIR
        #include <windows.h>
#else
        #include <unistd.h>
#endif

#define Int(str)                ((int)SvIV(get_sv(str,0)))
#define Float(str)              ((float)SvNV(get_sv(str,0)))
#define Str(str)                ((char*)SvPV_nolen(get_sv(str,0)))
#define P_eval(cmd)                     eval_pv(cmd,0)
#define P_arr_len(str)  (av_top_index(get_av(str, 0))+1)



#define P_arr_Str_i(str,i)      (SvPV_nolen( *av_fetch( get_av(str, 0) , i, 0 ) ))
#define P_arr_Int_i(str,i)      ((int)SvIV( *av_fetch( get_av(str, 0) , i, 0 ) ))
#define P_arr_Float_i(str,i) ((int)SvNV( *av_fetch( get_av(str, 0) , i, 0 ) ))


#define P_arr_print(str) for(int i=0;i<av_top_index(get_av(str, 0)) + 1;i++){ \
                                                                char *s = SvPV_nolen( *av_fetch( get_av(str, 0) , i, 0 ) ); \
                                                                printf( "%d : %s\n", i,s ); \
                                                        }

#define INIT_PERL_INTERP        char *embedding[] = { "", "-e", "0" }; \
                                                        PERL_SYS_INIT3(&argc,&argv,&env); \
                                                        my_perl = perl_alloc(); \
                                                        perl_construct( my_perl ); \
                                                        perl_parse(my_perl, NULL, 3, (char**)embedding, NULL); \
                                                        PL_exit_flags |= PERL_EXIT_DESTRUCT_END; \
                                                        perl_run(my_perl)

#define DESTROY_PERL_INTERP     perl_destruct(my_perl); \
                                                        perl_free(my_perl); \
                                                        PERL_SYS_TERM()

SV* my_eval_sv(SV *sv, I32 croak_on_error);
I32 match(SV *string, char *pattern) ;
int m( char *text, char*pattern);
I32 substitute(SV **string, char *pattern);
char * s( char *text, char *pattern);
SSize_t matches(SV *string, char *pattern, AV **match_list);

SV* my_eval_sv(SV *sv, I32 croak_on_error)
 {
     dSP;
     SV* retval;


     PUSHMARK(SP);
     eval_sv(sv, G_SCALAR);

     SPAGAIN;
     retval = POPs;
     PUTBACK;

     if (croak_on_error && SvTRUE(ERRSV))
        croak(SvPVx_nolen(ERRSV));

     return retval;
 }

 /** match(string, pattern)
  **
  ** Used for matches in a scalar context.
  **
  ** Returns 1 if the match was successful; 0 otherwise.
  **/

 I32 match(SV *string, char *pattern)
 {
     SV *command = newSV(0), *retval;

     sv_setpvf(command, "my $string = '%s'; $string =~ %s",
              SvPV_nolen(string), pattern);

     retval = my_eval_sv(command, TRUE);
     SvREFCNT_dec(command);

     return SvIV(retval);
 }

 int m( char *text, char *pattern){
         const int LEN_M=256;
         char *cmd = new char[strlen(text)+LEN_M];   // need delete []

         sprintf(cmd, "$_=qq/%s/;  $m=0; if (%s){ $m=1;} else{ $m =0;} " , text, pattern );

         //printf("cmd = %s", cmd );
         P_eval( cmd );
         int ret_int = 0;
         ret_int = Int("m");

         delete [] cmd ;
         return ret_int;
 }

  char * s( char *text, char *pattern){
         const int LEN_S=512;
         char *cmd = new char[strlen(text)+LEN_S];   // need delete []

         sprintf(cmd, "$_=qq/%s/;  $s=0; %s ; $s=$_; " , text, pattern );

         //printf("cmd = %s", cmd );
         P_eval( cmd );
         char *str = NULL;
         str = Str("s");

         delete [] cmd ;
         return str;
 }


 /** substitute(string, pattern)
  **
  ** Used for =~ operations that
  ** modify their left-hand side (s/// and tr///)
 **
 ** Returns the number of successful matches, and
 ** modifies the input string if there were any.
 **/

 I32 substitute(SV **string, char *pattern)
 {
     SV *command = newSV(0), *retval;

     sv_setpvf(command, "$string = '%s'; ($string =~ %s)",
              SvPV_nolen(*string), pattern);

     retval = my_eval_sv(command, TRUE);
     SvREFCNT_dec(command);

     *string = get_sv("string", 0);
     return SvIV(retval);
 }

 /** matches(string, pattern, matches)
  **
  ** Used for matches in a list context.
  **
  ** Returns the number of matches,
  ** and fills in **matches with the matching substrings
  **/

 SSize_t matches(SV *string, char *pattern, AV **match_list)
 {
     SV *command = newSV(0);
     SSize_t num_matches;

     sv_setpvf(command, "my $string = '%s'; @array = ($string =~ %s)",
              SvPV_nolen(string), pattern);

     my_eval_sv(command, TRUE);
     SvREFCNT_dec(command);

     *match_list = get_av("array", 0);
     num_matches = av_top_index(*match_list) + 1;

     return num_matches;
 }



/*
$ time ./interp.exe
38 ** 2 = 1444

real    0m0.126s
user    0m0.000s
sys     0m0.031s


*/




Perl 编程


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




perl_interp_get_var_from_perl_to_c

jdtangjdtang・
3 个月前2017 年 3月 6 日星期一下午 3 点 03 分


/* 
how to build and run 
perl_interp_get_var_from_perl_to_c
need to locate libperl.so or libperl.a  , something like this
if on windows, 
first redirect the embed pm opts to a bat file, then put them in one line.
and use straberryperl 's gcc : Strawberry\c\bin\gcc.exe
to build , and may need use gcc -std=c11   , or g++ is also ok.

on Windows:  use :		gcc -std=c11 -o interp interp.c -s -L"C:\jd_p\sw\pro\STRAWB~1\perl\lib\CORE" -L"C:\jd_p\sw\pr " ...
and dep on at least these 4 DLLs:

	copy c:\jd_p\sw\pro\strawberry\c\bin\LIBWINPTHREAD-1.DLL .\
	copy c:\jd_p\sw\pro\strawberry\c\bin\LIBGCC_S_SJLJ-1.DLL .\
	copy "c:\jd_p\sw\pro\strawberry\c\bin\LIBSTDC++-6.DLL" .\
	copy c:\jd_p\sw\pro\strawberry\perl\bin\PERL522.DLL .\


### shell ###
export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH
cc -o interp interp.c -L`pwd` `perl -MExtUtils::Embed -e ccopts -e ldopts`
./interp
### end shell ### 

*/

//--- perl ---
 #include <EXTERN.h>
 #include <perl.h>
//--- other --- 
#include <time.h>
#include <windows.h>

static PerlInterpreter *my_perl;


/* function readme
P_eval("$_=111");			run perl statement 
Int("a");  					get $a from eval()
Float("a");  				dotto
Str("a");					dotto
P_arr_len("arr"); 			get @arr length
P_arr_Str_i("arr", 3);		get @arr[3] as Str; 
P_arr_Int_i("arr", 3);		get @arr[3] as Int; 
P_arr_Float_i("arr", 3);	get @arr[3] as Float; 
P_arr_print("arr"); 		print out @arr and its index,very slowly...

*/

#define Int(str) 		((int)SvIV(get_sv(str,0)))
#define Float(str) 		((float)SvNV(get_sv(str,0)))
#define Str(str) 		((char*)SvPV_nolen(get_sv(str,0)))
#define P_eval(cmd)			eval_pv(cmd,0)
#define P_arr_len(str) 	(av_top_index(get_av(str, 0))+1)


							
#define P_arr_Str_i(str,i) 	(SvPV_nolen( *av_fetch( get_av(str, 0) , i, 0 ) ))				
#define P_arr_Int_i(str,i) 	((int)SvIV( *av_fetch( get_av(str, 0) , i, 0 ) ))	
#define P_arr_Float_i(str,i) ((int)SvNV( *av_fetch( get_av(str, 0) , i, 0 ) ))	


#define P_arr_print(str) for(int i=0;i<av_top_index(get_av(str, 0)) + 1;i++){ \
								char *s = SvPV_nolen( *av_fetch( get_av(str, 0) , i, 0 ) ); \
								printf( "%d : %s\n", i,s ); \
							}
							
#define INIT_PERL_INTERP	char *embedding[] = { "", "-e", "0" };\
							PERL_SYS_INIT3(&argc,&argv,&env); \
							my_perl = perl_alloc(); \
							perl_construct( my_perl ); \
							perl_parse(my_perl, NULL, 3, embedding, NULL); \
							PL_exit_flags |= PERL_EXIT_DESTRUCT_END; \
							perl_run(my_perl)

#define DESTROY_PERL_INTERP	perl_destruct(my_perl); \
							perl_free(my_perl); \
							PERL_SYS_TERM()


void  main (int argc, char **argv, char **env)
{

	INIT_PERL_INTERP ; 

	int i=0;
	char *dt = "0 1 2 3 4 5 6 7 10"; 
	char cmd[255] = {0};
	sprintf( cmd, " $_=q(%s); @arr=split m/\\s+/; $sum=0; map{$sum+=$_; }@arr;@arr=($sum, $sum**2);  ", dt ); 
	
	P_eval( cmd ); 
	
	//P_arr_print( "arr" ); 
	

	char *str = P_arr_Str_i("arr", 0); 
	int sum = Int("sum"); 
	
	//printf("%s\n", str);
	
	int sum_sum = P_arr_Int_i("arr",1); 
	
	printf("%s ** 2 = %d\n", str, sum_sum);

	

	
	DESTROY_PERL_INTERP ; 
	//return 0; 
 }


/* 
$ time ./interp.exe
38 ** 2 = 1444

real    0m0.126s
user    0m0.000s
sys     0m0.031s


*/
 
 
 
 




Perl 编程


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




nodejs_global_all

jdtangjdtang・
4 个月前2017 年 2月 28 日星期二下午 5 点 21 分


print ( global ); 

// seems global + global.process is exported 

{ DTRACE_NET_SERVER_CONNECTION: [Function],
  DTRACE_NET_STREAM_END: [Function],
  DTRACE_HTTP_SERVER_REQUEST: [Function],
  DTRACE_HTTP_SERVER_RESPONSE: [Function],
  DTRACE_HTTP_CLIENT_REQUEST: [Function],
  DTRACE_HTTP_CLIENT_RESPONSE: [Function],
  COUNTER_NET_SERVER_CONNECTION: [Function],
  COUNTER_NET_SERVER_CONNECTION_CLOSE: [Function],
  COUNTER_HTTP_SERVER_REQUEST: [Function],
  COUNTER_HTTP_SERVER_RESPONSE: [Function],
  COUNTER_HTTP_CLIENT_REQUEST: [Function],
  COUNTER_HTTP_CLIENT_RESPONSE: [Function],
  global: [Circular],


  process: 
   process {
     title: 'Administrator: vs_VS2012 x64 Cross Tools Command Prompt - node  test.js  ',
     version: 'v6.5.0',


     moduleLoadList: 
      [ 'Binding contextify',
        'Binding natives',
        'NativeModule events',
        'NativeModule util',
        'Binding uv',
        'NativeModule buffer',
        'Binding buffer',
        'Binding util',
        'NativeModule internal/util',
        'NativeModule timers',
        'Binding timer_wrap',
        'NativeModule internal/linkedlist',
        'NativeModule assert',
        'NativeModule internal/process',
        'Binding config',
        'NativeModule internal/process/warning',
        'NativeModule internal/process/next_tick',
        'NativeModule internal/process/promises',
        'NativeModule internal/process/stdio',
        'Binding constants',
        'NativeModule path',
        'NativeModule module',
        'NativeModule internal/module',
        'NativeModule vm',
        'NativeModule fs',
        'Binding fs',
        'NativeModule stream',
        'NativeModule _stream_readable',
        'NativeModule internal/streams/BufferList',
        'NativeModule _stream_writable',
        'NativeModule _stream_duplex',
        'NativeModule _stream_transform',
        'NativeModule _stream_passthrough',
        'Binding fs_event_wrap',
        'NativeModule console',
        'Binding tty_wrap',
        'NativeModule tty',
        'NativeModule net',
        'NativeModule internal/net',
        'Binding cares_wrap',
        'Binding tcp_wrap',
        'Binding pipe_wrap',
        'Binding stream_wrap',
        'Binding signal_wrap' ],  // end process.moduleLoadList [] 


     versions: 
      { http_parser: '2.7.0',
        node: '6.5.0',
        v8: '5.1.281.81',
        uv: '1.9.1',
        zlib: '1.2.8',
        ares: '1.10.1-DEV',
        icu: '57.1',
        modules: '48',
        openssl: '1.0.2h' },   // end process.version {} 


     arch: 'x64',
     platform: 'win32',

     release: 
      { name: 'node',
        sourceUrl: 'https://nodejs.org/download/release/v6.5.0/node-v6.5.0.tar.gz',
        headersUrl: 'https://nodejs.org/download/release/v6.5.0/node-v6.5.0-headers.tar.gz',
        libUrl: 'https://nodejs.org/download/release/v6.5.0/win-x64/node.lib'
	  }, // end process.release {} 



     argv: 
      [ 'C:\\jd_p\\sw\\pro\\nodejs\\node.exe',
        'C:\\jd_p\\sw\\pro\\tmp\\test.js' ],


     execArgv: [],


     env:   // start global.process.env 
      { ALLUSERSPROFILE: 'C:\\ProgramData',
        windir: 'C:\\windows',
        },   // end process.env {}

 
     pid: 19472,


     features: 
      { debug: false,
        uv: true,
        ipv6: true,
        tls_npn: true,
        tls_alpn: true,
        tls_sni: true,
        tls_ocsp: true,
        tls: true },  // end process.features


     _needImmediateCallback: false,
     execPath: 'C:\\jd_p\\sw\\pro\\nodejs\\node.exe',
     debugPort: 5858,
     _startProfilerIdleNotifier: [Function: _startProfilerIdleNotifier],
     _stopProfilerIdleNotifier: [Function: _stopProfilerIdleNotifier],
     _getActiveRequests: [Function: _getActiveRequests],
     _getActiveHandles: [Function: _getActiveHandles],
     reallyExit: [Function: reallyExit],
     abort: [Function: abort],
     chdir: [Function: chdir],
     cwd: [Function: cwd],
     umask: [Function: umask],
     _kill: [Function: _kill],
     _debugProcess: [Function: _debugProcess],
     _debugPause: [Function: _debugPause],
     _debugEnd: [Function: _debugEnd],
     hrtime: [Function: hrtime],
     cpuUsage: [Function: cpuUsage],
     dlopen: [Function: dlopen],
     uptime: [Function: uptime],
     memoryUsage: [Function: memoryUsage],
     binding: [Function: binding],
     _linkedBinding: [Function: _linkedBinding],
     _setupDomainUse: [Function: _setupDomainUse],


     _events: 
      { warning: [Function],
        newListener: [Function],
        removeListener: [Function],
        SIGWINCH: [Function] },  // end process._events {} 


     _rawDebug: [Function],
     _eventsCount: 4,
     domain: null,
     _maxListeners: undefined,
     _fatalException: [Function],
     _exiting: false,
     assert: [Function],
     config: { target_defaults: [Object], variables: [Object] },
     emitWarning: [Function],
     nextTick: [Function: nextTick],
     _tickCallback: [Function: _tickCallback],
     _tickDomainCallback: [Function: _tickDomainCallback],
     stdout: [Getter],
     stderr: [Getter],
     stdin: [Getter],
     openStdin: [Function],
     exit: [Function],
     kill: [Function],
     argv0: 'node', 


     mainModule: 
      Module {
        id: '.',
        exports: {},
        parent: null,
        filename: 'C:\\jd_p\\sw\\pro\\tmp\\test.js',
        loaded: false,
        children: [],
        paths: [Object] 
		} // end process.mainModule 

	 },   // end of process {}





  Buffer: 
   { [Function: Buffer]
     poolSize: 8192,
     from: [Function],
     alloc: [Function],
     allocUnsafe: [Function],
     allocUnsafeSlow: [Function],
     isBuffer: [Function: isBuffer],
     compare: [Function: compare],
     isEncoding: [Function],
     concat: [Function],
     byteLength: [Function: byteLength] },  // end { Buffer } 


  clearImmediate: [Function],
  clearInterval: [Function],
  clearTimeout: [Function],
  setImmediate: [Function],
  setInterval: [Function],
  setTimeout: [Function],
  console: [Getter] 

}  // end global 




Node.js


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




how_to_bld_cc_to_node_addon_node_gyp

jdtangjdtang・
4 个月前2017 年 2月 27 日星期一晚上 9 点 43 分


*********************
../test.js
*********************
// test.js
const addon = require('./addon');

console.log('This should be  8:', addon.Add(3, 5));
console.log('This should be -2:', addon.Sub(3, 5));



*********************
readme.txt
*********************
in cc, define the interface from js to cc.
arg , the arg can get an Isolate* , 
and the Isolate can spare a var. 
the var is Local<v>
the var can be return to js .

*********************
bld.sh
*********************
node-gyp.js configure build 

*********************
addon.cc
*********************
#include <node.h>

namespace demo {

using v8::Exception;
using v8::FunctionCallbackInfo;
using v8::Isolate;
using v8::Local;
using v8::Number;
using v8::Object;
using v8::String;
using v8::Value;

// This is the implementation of the "add" method
// Input arguments are passed using the
// const FunctionCallbackInfo<Value>& args struct
void Sub(const FunctionCallbackInfo<Value>& args){
  Isolate* isolate = args.GetIsolate(); 
  if ( args.Length() < 2 ){
    return ; 
  } // end if 

  if ( !args[0]->IsNumber() || !args[1]->IsNumber() ) {
    return;
  } // end if 
  double value = args[0]->NumberValue() - args[1]->NumberValue(); 
  Local<Number> num = Number::New(isolate, value); 
  args.GetReturnValue().Set(num);

}//end Sub()
void Add(const FunctionCallbackInfo<Value>& args) {
  Isolate* isolate = args.GetIsolate();

  // Check the number of arguments passed.
  if (args.Length() < 2) {
    // Throw an Error that is passed back to JavaScript
    isolate->ThrowException(Exception::TypeError(
        String::NewFromUtf8(isolate, "Wrong number of arguments")));
    return;
  }

  // Check the argument types
  if (!args[0]->IsNumber() || !args[1]->IsNumber()) {
    isolate->ThrowException(Exception::TypeError(
        String::NewFromUtf8(isolate, "Wrong arguments")));
    return;
  }

  // Perform the operation
  double value = args[0]->NumberValue() + args[1]->NumberValue();
  Local<Number> num = Number::New(isolate, value);

  // Set the return value (using the passed in
  // FunctionCallbackInfo<Value>&)
  args.GetReturnValue().Set(num);
}

void Init(Local<Object> exports) {
  NODE_SET_METHOD(exports, "Add", Add);
  NODE_SET_METHOD(exports, "Sub", Sub);
}

NODE_MODULE(addon, Init)

}  // namespace demo




*********************
binding.gyp
*********************
{
  "targets": [
    {
      "target_name": "addon",
      "sources": [ "addon.cc" ]
    }
  ]
}




Node.js


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




linux_itoa_src

jdtangjdtang・
4 个月前2017 年 2月 27 日星期一下午 5 点 07 分


// copy from:http://baike.baidu.com/link?url=bk4papoYLlAbccmjRmKBAmeiZI-UumzluKFu2x8_T_fDGRN9vABWSRQHzjJZCyMJ7PvRIuJ2msqQ4aWy6XJlWq 
// 对原作者表示谢谢！
*********************
test.c
*********************
#include <stdio.h>
#include <stdlib.h>

char* itoa_(int, char *, int );


char *p = "_ARC_";



int main(int argc, char **argv)
{
        printf("%s\n",p);

        int number=-1024;
        char string[25];
        int _b_ = atoi(argv[1]?argv[1]:"10");
        itoa_(number,string, _b_);
        _b_==2 && printf("integer=%d string=0b%s\n",number,string);
        _b_==16 && printf("integer=%d string=0x%s\n",number,string);
        _b_==10 && printf("integer=%d string=%s\n",number,string);
        return 0;
}

char* itoa_(int num,char *str,int radix)
{/*索引表*/
        char index[]="0123456789ABCDEF";
        unsigned unum;/*中间变量*/
        int i=0,j,k;
        /*确定unum的值*/
        if(radix==10&&num<0)/*十进制负数*/
        {
                unum=(unsigned)-num;
                str[i++]='-';
        }
        else unum=(unsigned)num;/*其他情况*/
        /*转换*/
        do{
                str[i++]=index[unum%(unsigned)radix];
                unum/=radix;
        }while(unum);
        str[i]='\0';
        /*逆序*/
        if(str[0]=='-')k=1;/*十进制负数*/
        else k=0;
        char temp;
        for(j=k;j<=(i-1)/2;j++)
        {
                temp=str[j];
                str[j]=str[i-1+k-j];
                str[i-1+k-j]=temp;
        }
        return str;
}




C / C++


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




node_cluster_parallel_master_worker

jdtangjdtang・
4 个月前2017 年 2月 27 日星期一下午 1 点 57 分


// ### lib ### 
console.time("---time---"); 
const range0_99=Buffer.allocUnsafe(200);


var range0_N= function(){
	// range0_N()  range0_N(3) ;  range0_N(0,9)
	//const range0_99=Buffer.allocUnsafe(200);
	//for(let i =0;i<100;i++) range0_99[i]=i; 
	var pre=0; 
	var next = 0; 
	//print(arguments); 

	if ( arguments.length == 2 ){
		pre=new Number(arguments[0]); 
		next=new Number(arguments[1]); 

	}

	else if ( arguments.length == 1 ){
		pre=0; 
		next=new Number(arguments[0]); 
	}
	else {
		pre=0; 
		next=new Number(range0_99.length);
	}

	if ( next > range0_99.length ){
		next = range0_99.length; 
		print ( "- N will be "+ range0_99.length); 
	}

	return range0_99.toString().slice(pre,next); 
}

var R = range0_N ; 

console.time("---time---"); 
var print = console.log;
var sleep_sync_sec = (x)=> {
	var WINDIR = process.env["WINDIR"];
	var exec_sync = require("child_process").execSync;
	// sleep for windows, see: https://zhuanlan.zhihu.com/p/25412671 or see $perl_p
	WINDIR && exec_sync( ` sleep ${x}s  ` );
	//var sleep_second = (x-222) / 1000 *1.000 ;
	//if ( x <=222 ) {sleep_second=0;}
	WINDIR || exec_sync( ` sleep ${sleep_second}s ` );
}

// ### end lib ###


// ### main ###
//-----------------Simple cluster and worker --------------------
var cluster= require("cluster"); 
var global_number = 0; 

if ( cluster.isMaster ) {

	cluster.fork(); 
	cluster.fork(); 
	cluster.fork(); 
	
	cluster.fork(); 
	cluster.fork(); 
	cluster.fork(); 


	var arr_workers = cluster.workers; 
	for ( let i in arr_workers ){
		arr_workers[i].on("message", (message) => {
		print (`worker[${i}] get message => ${message.cmd}, global_number:${global_number}`); 
		global_number++;
		} ); 
	}
}
else {
	 
	// sleep_sync_ms(0.01);  
	process.send( {cmd: `cmd from id : ${cluster.worker.id}`} ); 
	process.exit(0);

} // not master 

// ### end main ### 

//console.timeEnd("---time---"); 

# console out
worker[1] get message => cmd from id : 1, global_number:0
worker[4] get message => cmd from id : 4, global_number:1
worker[5] get message => cmd from id : 5, global_number:2
worker[3] get message => cmd from id : 3, global_number:3
worker[2] get message => cmd from id : 2, global_number:4
worker[6] get message => cmd from id : 6, global_number:5
//-----------------------------------------------------------------------

*********************
test_cluster.js
*********************


var print = console.log;
var sleep_sync_ms = (x)=> {
        var env_var = process.env["WINDIR"];
        var exec_sync = require("child_process").execSync;
        // sleep for windows, see: https://zhuanlan.zhihu.com/p/25412671 or see $perl_p
        env_var && exec_sync( ` sleep ${x}  ` );
        var sleep_second = (x-222) / 1000 *1.000 ;
        if ( x <=222 ) {sleep_second=0;}
        env_var || exec_sync( ` sleep ${sleep_second}s ` );
}





var cluster = require('cluster');

var numReqs = 0;
if (cluster.isMaster) {

        numReqs = 0;
        function messageHandler(msg) {
                if (msg.cmd && msg.cmd.match(/^notifyRequest/) ) {
                        numReqs += 1;
                        print ( `numReqs = ${numReqs}; `+"msg is-> " + msg.cmd );
                }
        }

        const numCPUs = require('os').cpus().length;
        for (let i = 0; i <numCPUs; i++) {
                cluster.fork();
        }

        for (const id in cluster.workers) {
                cluster.workers[id].on('message', messageHandler);
                cluster.workers[id].on('exit', (code, signal) => {
                                if (signal) {
                                        console.log(`worker was killed by signal: ${signal}`);
                                } else if (code !== 0) {
                                        console.log(`worker exited with error code: ${code}`);
                                } else {
                                        console.log(`worker[${id}] success!`);
                                }
                                });
        }

} else {


        //      print ( process.pid );

        sleep_sync_ms( 3111 );

        print ( numReqs );   // always 0 , for all core
        process.send({ cmd: `notifyRequest : sub process id is : ${process.pid} ` });

        setTimeout(
                        () => {
                        process.exit(0);
                        },
                        11 );
        //      process.kill(process.pid);
}


*********************
test_cluster.js_output
*********************
0
0
numReqs = 1; msg is-> notifyRequest : sub process id is : 187787
numReqs = 2; msg is-> notifyRequest : sub process id is : 187793
0
numReqs = 3; msg is-> notifyRequest : sub process id is : 187794
0
numReqs = 4; msg is-> notifyRequest : sub process id is : 187800
real    0m15.047s
user    0m0.272s
sys     0m0.055s

0
0
numReqs = 1; msg is-> notifyRequest : sub process id is : 187914
numReqs = 2; msg is-> notifyRequest : sub process id is : 187920
0
numReqs = 3; msg is-> notifyRequest : sub process id is : 187927
0
numReqs = 4; msg is-> notifyRequest : sub process id is : 187933
0
numReqs = 5; msg is-> notifyRequest : sub process id is : 187940
0
numReqs = 6; msg is-> notifyRequest : sub process id is : 187953
0
0
numReqs = 7; msg is-> notifyRequest : sub process id is : 187921
numReqs = 8; msg is-> notifyRequest : sub process id is : 187959
0
numReqs = 9; msg is-> notifyRequest : sub process id is : 187965
0
0
0
numReqs = 10; msg is-> notifyRequest : sub process id is : 187981
0
numReqs = 11; msg is-> notifyRequest : sub process id is : 188002
numReqs = 12; msg is-> notifyRequest : sub process id is : 187975
numReqs = 13; msg is-> notifyRequest : sub process id is : 187993
0
numReqs = 14; msg is-> notifyRequest : sub process id is : 188028
0
numReqs = 15; msg is-> notifyRequest : sub process id is : 188029
0
numReqs = 16; msg is-> notifyRequest : sub process id is : 188035
0
numReqs = 17; msg is-> notifyRequest : sub process id is : 188041
0
numReqs = 18; msg is-> notifyRequest : sub process id is : 188047
0
numReqs = 19; msg is-> notifyRequest : sub process id is : 188053
0
numReqs = 20; msg is-> notifyRequest : sub process id is : 188064

real    0m3.078s
user    0m1.162s
sys     0m0.224s


0
0
numReqs = 1; msg is-> notifyRequest : sub process id is : 189087
0
numReqs = 2; msg is-> notifyRequest : sub process id is : 189093
numReqs = 3; msg is-> notifyRequest : sub process id is : 189074
0
numReqs = 4; msg is-> notifyRequest : sub process id is : 189105
0
numReqs = 5; msg is-> notifyRequest : sub process id is : 189081
0
numReqs = 6; msg is-> notifyRequest : sub process id is : 189080
0
numReqs = 7; msg is-> notifyRequest : sub process id is : 189111
0
numReqs = 8; msg is-> notifyRequest : sub process id is : 189117
0
numReqs = 9; msg is-> notifyRequest : sub process id is : 189099
0
numReqs = 10; msg is-> notifyRequest : sub process id is : 189123
0
numReqs = 11; msg is-> notifyRequest : sub process id is : 189129
0
numReqs = 12; msg is-> notifyRequest : sub process id is : 189135
0
numReqs = 13; msg is-> notifyRequest : sub process id is : 189141
worker[4] success!
worker[5] success!
0
numReqs = 14; msg is-> notifyRequest : sub process id is : 189152
worker[1] success!
0
worker[7] success!
numReqs = 15; msg is-> notifyRequest : sub process id is : 189153
worker[3] success!
worker[2] success!
worker[8] success!
0
numReqs = 16; msg is-> notifyRequest : sub process id is : 189165
worker[9] success!
0
numReqs = 17; msg is-> notifyRequest : sub process id is : 189171
worker[6] success!
worker[10] success!
worker[11] success!
0
numReqs = 18; msg is-> notifyRequest : sub process id is : 189159
worker[12] success!
0
numReqs = 19; msg is-> notifyRequest : sub process id is : 189178
worker[13] success!
worker[14] success!
worker[15] success!
worker[17] success!
worker[18] success!
worker[16] success!
worker[19] success!
0
numReqs = 20; msg is-> notifyRequest : sub process id is : 189183
worker[20] success!

real    0m3.070s
user    0m1.173s
sys     0m0.213s


EOF




Node.js


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




windows_sleep_seconds_atoi

jdtangjdtang・
4 个月前2017 年 2月 24 日星期五下午 2 点 13 分


//  g++ -std=c++11 test.cpp  &&  ./a.exe 
// lambda , iostream , adapt
//  cl test.cpp  /EHsc  & test.exe

#include <iostream>
#include <vector>
#include <algorithm>
#include <iterator>
#include <string>
#include <deque>
#include <queue>
#include <thread>         // std::thread, std::this_thread::yield
#include <atomic>         // std::atomic
#include <memory.h>
#include <string.h>
#include <utility>
#include <map>
#include <time.h>
#include <windows.h>
#include <stdlib.h>





using namespace std; 
//typedef vector< int > 	v_i; 
#define elementsof(v)   (sizeof (v) / sizeof (v[0]))
#define a_begin(v)      (&v[0])
#define a_end(v)        (v + elementsof (v))
#define a_range(v)      v
#define b_e(v)          a_begin(v),a_end(v)
#define print_v_i(v)	( for_each(v.begin(),v.end(),[](int i){cout<<i<<" ";} ) ) 
#define PRINT_ID_V_I ( print_v_i( id_v_i )  )
#define print(a) printf("%d", a); 

int arr_has_ele( char * arr, char len,char ele ){ 
// if has, then return 0;  else return 1; 
	int i = 0; 
	for ( i = 0 ; i < len ; i++ ){
		if ( arr[i] == ele ) return 0; 
	}
	return 1; 

}




int main(int argc, char **argv)
{

if ( argc !=2 ){
	printf("- usage:\n\tsleep 0.4s\n" ); 
	exit (1); 	
}
char *p = argv[1]; 

float f0= atof(p);
float f=f0*1000*1.0f; 
int ms = (int)f; 
printf("- sleep %0.1fs\n", f0 );
Sleep( ms ); 

	return 0;
}




C / C++


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




caffe_training_mnist_full_log_caffemodel

jdtangjdtang・
4 个月前2017 年 2月 23 日星期四上午 10 点 21 分


see the lenet_train_test.prototxt below:


root@3ce2f5b85241:/opt/caffe# pwd
/opt/caffe
root@3ce2f5b85241:/opt/caffe# cd $caffe_root

root@3ce2f5b85241:/opt/caffe# ./python/draw_net.py   \
/examples/mnist/lenet_train_test.prototxt   \
./examples/mnist/lenet_train_test.prototxt.png





with:
    docker pull  neowaylabs/caffe-cpu

readme guide : 
    https://hub.docker.com/r/tleyden5iwx/caffe-cpu-master/

Verify CPU Version:

$ cd /opt/caffe/data/mnist
$ ./get_mnist.sh
$ cd ../../examples/mnist
$ sed -i 's/solver_mode: GPU/solver_mode: CPU/' lenet_solver.prototxt
$ cd ../../
$ ./examples/mnist/create_mnist.sh
$ ./examples/mnist/train_lenet.sh


### scripts ### 
jd@jd:~/t/mnist_example/mnist$ perl_show_files_content create_mnist.sh  train_lenet.sh 
*********************
create_mnist.sh
*********************
#!/usr/bin/env sh
# This script converts the mnist data into lmdb/leveldb format,
# depending on the value assigned to $BACKEND.

EXAMPLE=examples/mnist
DATA=data/mnist
BUILD=build/examples/mnist

BACKEND="lmdb"

echo "Creating ${BACKEND}..."

rm -rf $EXAMPLE/mnist_train_${BACKEND}
rm -rf $EXAMPLE/mnist_test_${BACKEND}

$BUILD/convert_mnist_data.bin $DATA/train-images-idx3-ubyte \
  $DATA/train-labels-idx1-ubyte $EXAMPLE/mnist_train_${BACKEND} --backend=${BACKEND}
$BUILD/convert_mnist_data.bin $DATA/t10k-images-idx3-ubyte \
  $DATA/t10k-labels-idx1-ubyte $EXAMPLE/mnist_test_${BACKEND} --backend=${BACKEND}

echo "Done."

*********************
train_lenet.sh
*********************
#!/usr/bin/env sh

./build/tools/caffe train --solver=examples/mnist/lenet_solver.prototxt

EOF

jd@jd:~/t/mnist_example/mnist$ cat lenet_solver.prototxt
# The train/test net protocol buffer definition
net: "examples/mnist/lenet_train_test.prototxt"
; define the train_test prototxt file 

# test_iter specifies how many forward passes the test should carry out.
# In the case of MNIST, we have test batch size 100 and 100 test iterations,
# covering the full 10,000 testing images.
test_iter: 100
# Carry out testing every 500 training iterations.
test_interval: 500
# The base learning rate, momentum and the weight decay of the network.
base_lr: 0.01
momentum: 0.9
weight_decay: 0.0005
# The learning rate policy
lr_policy: "inv"
gamma: 0.0001
power: 0.75
# Display every 100 iterations
display: 100
# The maximum number of iterations
max_iter: 10000
# snapshot intermediate results
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
# solver mode: CPU or GPU
solver_mode: CPU


*********************
lenet_train_test.prototxt
*********************
name: "LeNet"
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}

EOF

### end script ### 


root@9ea41966284c:/opt/caffe# ./examples/mnist/train_lenet.sh
libdc1394 error: Failed to initialize libdc1394
I0223 01:51:44.845149    44 caffe.cpp:177] Use CPU.
I0223 01:51:44.846709    44 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: CPU
net: "examples/mnist/lenet_train_test.prototxt"
I0223 01:51:44.847100    44 solver.cpp:91] Creating training net from net file: examples/mnist/lenet_train_test.prototxt
I0223 01:51:44.847378    44 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0223 01:51:44.847594    44 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0223 01:51:44.847676    44 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0223 01:51:44.849884    44 layer_factory.hpp:76] Creating layer mnist
I0223 01:51:44.851091    44 net.cpp:106] Creating Layer mnist
I0223 01:51:44.851150    44 net.cpp:411] mnist -> data
I0223 01:51:44.851203    44 net.cpp:411] mnist -> label
I0223 01:51:44.851361    45 db_lmdb.cpp:38] Opened lmdb examples/mnist/mnist_train_lmdb
I0223 01:51:44.851429    44 data_layer.cpp:41] output data size: 64,1,28,28
I0223 01:51:44.851805    44 net.cpp:150] Setting up mnist
I0223 01:51:44.852077    44 net.cpp:157] Top shape: 64 1 28 28 (50176)
I0223 01:51:44.852104    44 net.cpp:157] Top shape: 64 (64)
I0223 01:51:44.852125    44 net.cpp:165] Memory required for data: 200960
I0223 01:51:44.852150    44 layer_factory.hpp:76] Creating layer conv1
I0223 01:51:44.852181    44 net.cpp:106] Creating Layer conv1
I0223 01:51:44.852205    44 net.cpp:454] conv1 <- data
I0223 01:51:44.852234    44 net.cpp:411] conv1 -> conv1
I0223 01:51:44.852634    44 net.cpp:150] Setting up conv1
I0223 01:51:44.852663    44 net.cpp:157] Top shape: 64 20 24 24 (737280)
I0223 01:51:44.852689    44 net.cpp:165] Memory required for data: 3150080
I0223 01:51:44.852718    44 layer_factory.hpp:76] Creating layer pool1
I0223 01:51:44.852744    44 net.cpp:106] Creating Layer pool1
I0223 01:51:44.852774    44 net.cpp:454] pool1 <- conv1
I0223 01:51:44.852797    44 net.cpp:411] pool1 -> pool1
I0223 01:51:44.852907    44 net.cpp:150] Setting up pool1
I0223 01:51:44.852936    44 net.cpp:157] Top shape: 64 20 12 12 (184320)
I0223 01:51:44.852957    44 net.cpp:165] Memory required for data: 3887360
I0223 01:51:44.852977    44 layer_factory.hpp:76] Creating layer conv2
I0223 01:51:44.853000    44 net.cpp:106] Creating Layer conv2
I0223 01:51:44.853020    44 net.cpp:454] conv2 <- pool1
I0223 01:51:44.853783    44 net.cpp:411] conv2 -> conv2
I0223 01:51:44.855121    44 net.cpp:150] Setting up conv2
I0223 01:51:44.855201    44 net.cpp:157] Top shape: 64 50 8 8 (204800)
I0223 01:51:44.855252    44 net.cpp:165] Memory required for data: 4706560
I0223 01:51:44.855304    44 layer_factory.hpp:76] Creating layer pool2
I0223 01:51:44.855639    44 net.cpp:106] Creating Layer pool2
I0223 01:51:44.855666    44 net.cpp:454] pool2 <- conv2
I0223 01:51:44.855692    44 net.cpp:411] pool2 -> pool2
I0223 01:51:44.855727    44 net.cpp:150] Setting up pool2
I0223 01:51:44.855753    44 net.cpp:157] Top shape: 64 50 4 4 (51200)
I0223 01:51:44.855775    44 net.cpp:165] Memory required for data: 4911360
I0223 01:51:44.855798    44 layer_factory.hpp:76] Creating layer ip1
I0223 01:51:44.855829    44 net.cpp:106] Creating Layer ip1
I0223 01:51:44.855851    44 net.cpp:454] ip1 <- pool2
I0223 01:51:44.855875    44 net.cpp:411] ip1 -> ip1
I0223 01:51:44.864680    44 net.cpp:150] Setting up ip1
I0223 01:51:44.864795    44 net.cpp:157] Top shape: 64 500 (32000)
I0223 01:51:44.864822    44 net.cpp:165] Memory required for data: 5039360
I0223 01:51:44.864856    44 layer_factory.hpp:76] Creating layer relu1
I0223 01:51:44.864881    44 net.cpp:106] Creating Layer relu1
I0223 01:51:44.864902    44 net.cpp:454] relu1 <- ip1
I0223 01:51:44.864926    44 net.cpp:397] relu1 -> ip1 (in-place)
I0223 01:51:44.864959    44 net.cpp:150] Setting up relu1
I0223 01:51:44.864981    44 net.cpp:157] Top shape: 64 500 (32000)
I0223 01:51:44.865000    44 net.cpp:165] Memory required for data: 5167360
I0223 01:51:44.865020    44 layer_factory.hpp:76] Creating layer ip2
I0223 01:51:44.865103    44 net.cpp:106] Creating Layer ip2
I0223 01:51:44.865133    44 net.cpp:454] ip2 <- ip1
I0223 01:51:44.865155    44 net.cpp:411] ip2 -> ip2
I0223 01:51:44.865222    44 net.cpp:150] Setting up ip2
I0223 01:51:44.865247    44 net.cpp:157] Top shape: 64 10 (640)
I0223 01:51:44.865269    44 net.cpp:165] Memory required for data: 5169920
I0223 01:51:44.865291    44 layer_factory.hpp:76] Creating layer loss
I0223 01:51:44.865324    44 net.cpp:106] Creating Layer loss
I0223 01:51:44.865345    44 net.cpp:454] loss <- ip2
I0223 01:51:44.865365    44 net.cpp:454] loss <- label
I0223 01:51:44.865388    44 net.cpp:411] loss -> loss
I0223 01:51:44.865422    44 layer_factory.hpp:76] Creating layer loss
I0223 01:51:44.865453    44 net.cpp:150] Setting up loss
I0223 01:51:44.865476    44 net.cpp:157] Top shape: (1)
I0223 01:51:44.865495    44 net.cpp:160]     with loss weight 1
I0223 01:51:44.865583    44 net.cpp:165] Memory required for data: 5169924
I0223 01:51:44.865607    44 net.cpp:226] loss needs backward computation.
I0223 01:51:44.865628    44 net.cpp:226] ip2 needs backward computation.
I0223 01:51:44.865648    44 net.cpp:226] relu1 needs backward computation.
I0223 01:51:44.865666    44 net.cpp:226] ip1 needs backward computation.
I0223 01:51:44.865689    44 net.cpp:226] pool2 needs backward computation.
I0223 01:51:44.865707    44 net.cpp:226] conv2 needs backward computation.
I0223 01:51:44.865727    44 net.cpp:226] pool1 needs backward computation.
I0223 01:51:44.865747    44 net.cpp:226] conv1 needs backward computation.
I0223 01:51:44.865767    44 net.cpp:228] mnist does not need backward computation.
I0223 01:51:44.865787    44 net.cpp:270] This network produces output loss
I0223 01:51:44.865811    44 net.cpp:283] Network initialization done.
I0223 01:51:44.866175    44 solver.cpp:181] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test.prototxt
I0223 01:51:44.866222    44 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0223 01:51:44.866341    44 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0223 01:51:44.868486    44 layer_factory.hpp:76] Creating layer mnist
I0223 01:51:44.868669    44 net.cpp:106] Creating Layer mnist
I0223 01:51:44.869611    44 net.cpp:411] mnist -> data
I0223 01:51:44.869650    44 net.cpp:411] mnist -> label
I0223 01:51:44.869771    47 db_lmdb.cpp:38] Opened lmdb examples/mnist/mnist_test_lmdb
I0223 01:51:44.869824    44 data_layer.cpp:41] output data size: 100,1,28,28
I0223 01:51:44.870864    44 net.cpp:150] Setting up mnist
I0223 01:51:44.870925    44 net.cpp:157] Top shape: 100 1 28 28 (78400)
I0223 01:51:44.870955    44 net.cpp:157] Top shape: 100 (100)
I0223 01:51:44.870978    44 net.cpp:165] Memory required for data: 314000
I0223 01:51:44.871001    44 layer_factory.hpp:76] Creating layer label_mnist_1_split
I0223 01:51:44.871117    44 net.cpp:106] Creating Layer label_mnist_1_split
I0223 01:51:44.871191    44 net.cpp:454] label_mnist_1_split <- label
I0223 01:51:44.871218    44 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_0
I0223 01:51:44.871248    44 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_1
I0223 01:51:44.871290    44 net.cpp:150] Setting up label_mnist_1_split
I0223 01:51:44.871589    44 net.cpp:157] Top shape: 100 (100)
I0223 01:51:44.871614    44 net.cpp:157] Top shape: 100 (100)
I0223 01:51:44.871636    44 net.cpp:165] Memory required for data: 314800
I0223 01:51:44.871656    44 layer_factory.hpp:76] Creating layer conv1
I0223 01:51:44.871695    44 net.cpp:106] Creating Layer conv1
I0223 01:51:44.871717    44 net.cpp:454] conv1 <- data
I0223 01:51:44.871744    44 net.cpp:411] conv1 -> conv1
I0223 01:51:44.871793    44 net.cpp:150] Setting up conv1
I0223 01:51:44.871819    44 net.cpp:157] Top shape: 100 20 24 24 (1152000)
I0223 01:51:44.871839    44 net.cpp:165] Memory required for data: 4922800
I0223 01:51:44.871865    44 layer_factory.hpp:76] Creating layer pool1
I0223 01:51:44.871891    44 net.cpp:106] Creating Layer pool1
I0223 01:51:44.871912    44 net.cpp:454] pool1 <- conv1
I0223 01:51:44.871966    44 net.cpp:411] pool1 -> pool1
I0223 01:51:44.871999    44 net.cpp:150] Setting up pool1
I0223 01:51:44.872023    44 net.cpp:157] Top shape: 100 20 12 12 (288000)
I0223 01:51:44.872249    44 net.cpp:165] Memory required for data: 6074800
I0223 01:51:44.872272    44 layer_factory.hpp:76] Creating layer conv2
I0223 01:51:44.872301    44 net.cpp:106] Creating Layer conv2
I0223 01:51:44.872328    44 net.cpp:454] conv2 <- pool1
I0223 01:51:44.872604    44 net.cpp:411] conv2 -> conv2
I0223 01:51:44.872802    44 net.cpp:150] Setting up conv2
I0223 01:51:44.872828    44 net.cpp:157] Top shape: 100 50 8 8 (320000)
I0223 01:51:44.873082    44 net.cpp:165] Memory required for data: 7354800
I0223 01:51:44.873116    44 layer_factory.hpp:76] Creating layer pool2
I0223 01:51:44.873147    44 net.cpp:106] Creating Layer pool2
I0223 01:51:44.873170    44 net.cpp:454] pool2 <- conv2
I0223 01:51:44.873194    44 net.cpp:411] pool2 -> pool2
I0223 01:51:44.873224    44 net.cpp:150] Setting up pool2
I0223 01:51:44.873247    44 net.cpp:157] Top shape: 100 50 4 4 (80000)
I0223 01:51:44.873267    44 net.cpp:165] Memory required for data: 7674800
I0223 01:51:44.873286    44 layer_factory.hpp:76] Creating layer ip1
I0223 01:51:44.873314    44 net.cpp:106] Creating Layer ip1
I0223 01:51:44.873335    44 net.cpp:454] ip1 <- pool2
I0223 01:51:44.873359    44 net.cpp:411] ip1 -> ip1
I0223 01:51:44.881389    44 net.cpp:150] Setting up ip1
I0223 01:51:44.891966    44 net.cpp:157] Top shape: 100 500 (50000)
I0223 01:51:44.891988    44 net.cpp:165] Memory required for data: 7874800
I0223 01:51:44.892005    44 layer_factory.hpp:76] Creating layer relu1
I0223 01:51:44.892050    44 net.cpp:106] Creating Layer relu1
I0223 01:51:44.892065    44 net.cpp:454] relu1 <- ip1
I0223 01:51:44.892077    44 net.cpp:397] relu1 -> ip1 (in-place)
I0223 01:51:44.892091    44 net.cpp:150] Setting up relu1
I0223 01:51:44.892097    44 net.cpp:157] Top shape: 100 500 (50000)
I0223 01:51:44.892102    44 net.cpp:165] Memory required for data: 8074800
I0223 01:51:44.892108    44 layer_factory.hpp:76] Creating layer ip2
I0223 01:51:44.892120    44 net.cpp:106] Creating Layer ip2
I0223 01:51:44.892127    44 net.cpp:454] ip2 <- ip1
I0223 01:51:44.892134    44 net.cpp:411] ip2 -> ip2
I0223 01:51:44.892185    44 net.cpp:150] Setting up ip2
I0223 01:51:44.892194    44 net.cpp:157] Top shape: 100 10 (1000)
I0223 01:51:44.892199    44 net.cpp:165] Memory required for data: 8078800
I0223 01:51:44.892206    44 layer_factory.hpp:76] Creating layer ip2_ip2_0_split
I0223 01:51:44.892213    44 net.cpp:106] Creating Layer ip2_ip2_0_split
I0223 01:51:44.892220    44 net.cpp:454] ip2_ip2_0_split <- ip2
I0223 01:51:44.892225    44 net.cpp:411] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0223 01:51:44.892233    44 net.cpp:411] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0223 01:51:44.892241    44 net.cpp:150] Setting up ip2_ip2_0_split
I0223 01:51:44.892249    44 net.cpp:157] Top shape: 100 10 (1000)
I0223 01:51:44.892256    44 net.cpp:157] Top shape: 100 10 (1000)
I0223 01:51:44.892261    44 net.cpp:165] Memory required for data: 8086800
I0223 01:51:44.892266    44 layer_factory.hpp:76] Creating layer accuracy
I0223 01:51:44.892273    44 net.cpp:106] Creating Layer accuracy
I0223 01:51:44.892278    44 net.cpp:454] accuracy <- ip2_ip2_0_split_0
I0223 01:51:44.892285    44 net.cpp:454] accuracy <- label_mnist_1_split_0
I0223 01:51:44.892292    44 net.cpp:411] accuracy -> accuracy
I0223 01:51:44.892300    44 net.cpp:150] Setting up accuracy
I0223 01:51:44.892307    44 net.cpp:157] Top shape: (1)
I0223 01:51:44.892312    44 net.cpp:165] Memory required for data: 8086804
I0223 01:51:44.892316    44 layer_factory.hpp:76] Creating layer loss
I0223 01:51:44.892323    44 net.cpp:106] Creating Layer loss
I0223 01:51:44.892329    44 net.cpp:454] loss <- ip2_ip2_0_split_1
I0223 01:51:44.892335    44 net.cpp:454] loss <- label_mnist_1_split_1
I0223 01:51:44.892341    44 net.cpp:411] loss -> loss
I0223 01:51:44.892351    44 layer_factory.hpp:76] Creating layer loss
I0223 01:51:44.892408    44 net.cpp:150] Setting up loss
I0223 01:51:44.892416    44 net.cpp:157] Top shape: (1)
I0223 01:51:44.892421    44 net.cpp:160]     with loss weight 1
I0223 01:51:44.892437    44 net.cpp:165] Memory required for data: 8086808
I0223 01:51:44.892442    44 net.cpp:226] loss needs backward computation.
I0223 01:51:44.892448    44 net.cpp:228] accuracy does not need backward computation.
I0223 01:51:44.892454    44 net.cpp:226] ip2_ip2_0_split needs backward computation.
I0223 01:51:44.892459    44 net.cpp:226] ip2 needs backward computation.
I0223 01:51:44.892464    44 net.cpp:226] relu1 needs backward computation.
I0223 01:51:44.892470    44 net.cpp:226] ip1 needs backward computation.
I0223 01:51:44.892477    44 net.cpp:226] pool2 needs backward computation.
I0223 01:51:44.892483    44 net.cpp:226] conv2 needs backward computation.
I0223 01:51:44.892488    44 net.cpp:226] pool1 needs backward computation.
I0223 01:51:44.892493    44 net.cpp:226] conv1 needs backward computation.
I0223 01:51:44.892499    44 net.cpp:228] label_mnist_1_split does not need backward computation.
I0223 01:51:44.892505    44 net.cpp:228] mnist does not need backward computation.
I0223 01:51:44.892510    44 net.cpp:270] This network produces output accuracy
I0223 01:51:44.892515    44 net.cpp:270] This network produces output loss
I0223 01:51:44.892554    44 net.cpp:283] Network initialization done.
I0223 01:51:44.892609    44 solver.cpp:60] Solver scaffolding done.
I0223 01:51:44.892634    44 caffe.cpp:212] Starting Optimization
I0223 01:51:44.892640    44 solver.cpp:288] Solving LeNet
I0223 01:51:44.892645    44 solver.cpp:289] Learning Rate Policy: inv
I0223 01:51:44.893246    44 solver.cpp:341] Iteration 0, Testing net (#0)
I0223 01:51:51.486187    44 solver.cpp:409]     Test net output #0: accuracy = 0.0851
I0223 01:51:51.486335    44 solver.cpp:409]     Test net output #1: loss = 2.33186 (* 1 = 2.33186 loss)
I0223 01:51:51.639250    44 solver.cpp:237] Iteration 0, loss = 2.31899
I0223 01:51:51.639468    44 solver.cpp:253]     Train net output #0: loss = 2.31899 (* 1 = 2.31899 loss)
I0223 01:51:51.639521    44 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0223 01:52:04.987720    44 solver.cpp:237] Iteration 100, loss = 0.220316
I0223 01:52:04.987874    44 solver.cpp:253]     Train net output #0: loss = 0.220316 (* 1 = 0.220316 loss)
I0223 01:52:04.987915    44 sgd_solver.cpp:106] Iteration 100, lr = 0.00992565
I0223 01:52:14.738734    44 solver.cpp:237] Iteration 200, loss = 0.149513
I0223 01:52:14.738946    44 solver.cpp:253]     Train net output #0: loss = 0.149513 (* 1 = 0.149513 loss)
I0223 01:52:14.738997    44 sgd_solver.cpp:106] Iteration 200, lr = 0.00985258
I0223 01:52:24.067344    44 solver.cpp:237] Iteration 300, loss = 0.182812
I0223 01:52:24.067595    44 solver.cpp:253]     Train net output #0: loss = 0.182812 (* 1 = 0.182812 loss)
I0223 01:52:24.067638    44 sgd_solver.cpp:106] Iteration 300, lr = 0.00978075
I0223 01:52:33.116477    44 solver.cpp:237] Iteration 400, loss = 0.0818294
I0223 01:52:33.116775    44 solver.cpp:253]     Train net output #0: loss = 0.0818293 (* 1 = 0.0818293 loss)
I0223 01:52:33.116828    44 sgd_solver.cpp:106] Iteration 400, lr = 0.00971013
I0223 01:52:42.790956    44 solver.cpp:341] Iteration 500, Testing net (#0)
I0223 01:52:49.294622    44 solver.cpp:409]     Test net output #0: accuracy = 0.9743
I0223 01:52:49.294790    44 solver.cpp:409]     Test net output #1: loss = 0.0823115 (* 1 = 0.0823115 loss)
I0223 01:52:49.425221    44 solver.cpp:237] Iteration 500, loss = 0.0681273
I0223 01:52:49.425436    44 solver.cpp:253]     Train net output #0: loss = 0.0681273 (* 1 = 0.0681273 loss)
I0223 01:52:49.425487    44 sgd_solver.cpp:106] Iteration 500, lr = 0.00964069
I0223 01:53:01.230792    44 solver.cpp:237] Iteration 600, loss = 0.0683122
I0223 01:53:01.234378    44 solver.cpp:253]     Train net output #0: loss = 0.0683122 (* 1 = 0.0683122 loss)
I0223 01:53:01.234428    44 sgd_solver.cpp:106] Iteration 600, lr = 0.0095724
I0223 01:53:11.953254    44 solver.cpp:237] Iteration 700, loss = 0.126395
I0223 01:53:11.953429    44 solver.cpp:253]     Train net output #0: loss = 0.126395 (* 1 = 0.126395 loss)
I0223 01:53:11.953472    44 sgd_solver.cpp:106] Iteration 700, lr = 0.00950522
I0223 01:53:23.331504    44 solver.cpp:237] Iteration 800, loss = 0.227577
I0223 01:53:23.331686    44 solver.cpp:253]     Train net output #0: loss = 0.227577 (* 1 = 0.227577 loss)
I0223 01:53:23.331732    44 sgd_solver.cpp:106] Iteration 800, lr = 0.00943913
I0223 01:53:32.569607    44 solver.cpp:237] Iteration 900, loss = 0.158435
I0223 01:53:32.569862    44 solver.cpp:253]     Train net output #0: loss = 0.158435 (* 1 = 0.158435 loss)
I0223 01:53:32.569905    44 sgd_solver.cpp:106] Iteration 900, lr = 0.00937411
I0223 01:53:41.565196    44 solver.cpp:341] Iteration 1000, Testing net (#0)
I0223 01:53:48.069342    44 solver.cpp:409]     Test net output #0: accuracy = 0.9846
I0223 01:53:48.069514    44 solver.cpp:409]     Test net output #1: loss = 0.0525155 (* 1 = 0.0525155 loss)
I0223 01:53:48.266062    44 solver.cpp:237] Iteration 1000, loss = 0.0977011
I0223 01:53:48.267176    44 solver.cpp:253]     Train net output #0: loss = 0.0977012 (* 1 = 0.0977012 loss)
I0223 01:53:48.267212    44 sgd_solver.cpp:106] Iteration 1000, lr = 0.00931012
I0223 01:54:00.666955    44 solver.cpp:237] Iteration 1100, loss = 0.00802894
I0223 01:54:00.667138    44 solver.cpp:253]     Train net output #0: loss = 0.00802902 (* 1 = 0.00802902 loss)
I0223 01:54:00.667253    44 sgd_solver.cpp:106] Iteration 1100, lr = 0.00924715
I0223 01:54:11.043939    44 solver.cpp:237] Iteration 1200, loss = 0.0228548
I0223 01:54:11.044186    44 solver.cpp:253]     Train net output #0: loss = 0.0228549 (* 1 = 0.0228549 loss)
I0223 01:54:11.044232    44 sgd_solver.cpp:106] Iteration 1200, lr = 0.00918515
I0223 01:54:22.541710    44 solver.cpp:237] Iteration 1300, loss = 0.0118117
I0223 01:54:22.541916    44 solver.cpp:253]     Train net output #0: loss = 0.0118118 (* 1 = 0.0118118 loss)
I0223 01:54:22.542032    44 sgd_solver.cpp:106] Iteration 1300, lr = 0.00912412
I0223 01:54:32.205283    44 solver.cpp:237] Iteration 1400, loss = 0.00748374
I0223 01:54:32.205461    44 solver.cpp:253]     Train net output #0: loss = 0.00748392 (* 1 = 0.00748392 loss)
I0223 01:54:32.205503    44 sgd_solver.cpp:106] Iteration 1400, lr = 0.00906403
I0223 01:54:41.795248    44 solver.cpp:341] Iteration 1500, Testing net (#0)
I0223 01:54:47.384356    44 solver.cpp:409]     Test net output #0: accuracy = 0.9846
I0223 01:54:47.384496    44 solver.cpp:409]     Test net output #1: loss = 0.0461534 (* 1 = 0.0461534 loss)
I0223 01:54:47.523795    44 solver.cpp:237] Iteration 1500, loss = 0.0650026
I0223 01:54:47.523972    44 solver.cpp:253]     Train net output #0: loss = 0.0650028 (* 1 = 0.0650028 loss)
I0223 01:54:47.524016    44 sgd_solver.cpp:106] Iteration 1500, lr = 0.00900485
I0223 01:54:56.524961    44 solver.cpp:237] Iteration 1600, loss = 0.10784
I0223 01:54:56.525132    44 solver.cpp:253]     Train net output #0: loss = 0.10784 (* 1 = 0.10784 loss)
I0223 01:54:56.525176    44 sgd_solver.cpp:106] Iteration 1600, lr = 0.00894657
I0223 01:55:05.861120    44 solver.cpp:237] Iteration 1700, loss = 0.0568385
I0223 01:55:05.861294    44 solver.cpp:253]     Train net output #0: loss = 0.0568387 (* 1 = 0.0568387 loss)
I0223 01:55:05.861353    44 sgd_solver.cpp:106] Iteration 1700, lr = 0.00888916
I0223 01:55:15.102286    44 solver.cpp:237] Iteration 1800, loss = 0.0181182
I0223 01:55:15.102533    44 solver.cpp:253]     Train net output #0: loss = 0.0181183 (* 1 = 0.0181183 loss)
I0223 01:55:15.102694    44 sgd_solver.cpp:106] Iteration 1800, lr = 0.0088326
I0223 01:55:24.218652    44 solver.cpp:237] Iteration 1900, loss = 0.103082
I0223 01:55:24.218853    44 solver.cpp:253]     Train net output #0: loss = 0.103082 (* 1 = 0.103082 loss)
I0223 01:55:24.218899    44 sgd_solver.cpp:106] Iteration 1900, lr = 0.00877687
I0223 01:55:33.265202    44 solver.cpp:341] Iteration 2000, Testing net (#0)
I0223 01:55:38.743775    44 solver.cpp:409]     Test net output #0: accuracy = 0.986
I0223 01:55:38.743950    44 solver.cpp:409]     Test net output #1: loss = 0.0428062 (* 1 = 0.0428062 loss)
I0223 01:55:38.888327    44 solver.cpp:237] Iteration 2000, loss = 0.0177865
I0223 01:55:38.888509    44 solver.cpp:253]     Train net output #0: loss = 0.0177866 (* 1 = 0.0177866 loss)
I0223 01:55:38.888552    44 sgd_solver.cpp:106] Iteration 2000, lr = 0.00872196
I0223 01:55:49.072492    44 solver.cpp:237] Iteration 2100, loss = 0.0244496
I0223 01:55:49.072685    44 solver.cpp:253]     Train net output #0: loss = 0.0244497 (* 1 = 0.0244497 loss)
I0223 01:55:49.072716    44 sgd_solver.cpp:106] Iteration 2100, lr = 0.00866784
I0223 01:55:59.164512    44 solver.cpp:237] Iteration 2200, loss = 0.0170718
I0223 01:55:59.164758    44 solver.cpp:253]     Train net output #0: loss = 0.0170719 (* 1 = 0.0170719 loss)
I0223 01:55:59.164800    44 sgd_solver.cpp:106] Iteration 2200, lr = 0.0086145
I0223 01:56:08.450095    44 solver.cpp:237] Iteration 2300, loss = 0.118363
I0223 01:56:08.450263    44 solver.cpp:253]     Train net output #0: loss = 0.118363 (* 1 = 0.118363 loss)
I0223 01:56:08.450378    44 sgd_solver.cpp:106] Iteration 2300, lr = 0.00856192
I0223 01:56:19.507671    44 solver.cpp:237] Iteration 2400, loss = 0.00936888
I0223 01:56:19.507863    44 solver.cpp:253]     Train net output #0: loss = 0.00936897 (* 1 = 0.00936897 loss)
I0223 01:56:19.507892    44 sgd_solver.cpp:106] Iteration 2400, lr = 0.00851008
I0223 01:56:30.813474    44 solver.cpp:341] Iteration 2500, Testing net (#0)
I0223 01:56:37.805377    44 solver.cpp:409]     Test net output #0: accuracy = 0.9864
I0223 01:56:37.805593    44 solver.cpp:409]     Test net output #1: loss = 0.0456749 (* 1 = 0.0456749 loss)
I0223 01:56:37.997198    44 solver.cpp:237] Iteration 2500, loss = 0.0211092
I0223 01:56:38.002710    44 solver.cpp:253]     Train net output #0: loss = 0.0211093 (* 1 = 0.0211093 loss)
I0223 01:56:38.002763    44 sgd_solver.cpp:106] Iteration 2500, lr = 0.00845897
I0223 01:56:48.103667    44 solver.cpp:237] Iteration 2600, loss = 0.0540918
I0223 01:56:48.103911    44 solver.cpp:253]     Train net output #0: loss = 0.0540919 (* 1 = 0.0540919 loss)
I0223 01:56:48.103958    44 sgd_solver.cpp:106] Iteration 2600, lr = 0.00840857
I0223 01:56:57.912318    44 solver.cpp:237] Iteration 2700, loss = 0.0607531
I0223 01:56:57.912668    44 solver.cpp:253]     Train net output #0: loss = 0.0607532 (* 1 = 0.0607532 loss)
I0223 01:56:57.912721    44 sgd_solver.cpp:106] Iteration 2700, lr = 0.00835886
I0223 01:57:07.547443    44 solver.cpp:237] Iteration 2800, loss = 0.00173335
I0223 01:57:07.547590    44 solver.cpp:253]     Train net output #0: loss = 0.00173342 (* 1 = 0.00173342 loss)
I0223 01:57:07.547619    44 sgd_solver.cpp:106] Iteration 2800, lr = 0.00830984
I0223 01:57:16.833750    44 solver.cpp:237] Iteration 2900, loss = 0.0193274
I0223 01:57:16.833997    44 solver.cpp:253]     Train net output #0: loss = 0.0193275 (* 1 = 0.0193275 loss)
I0223 01:57:16.834038    44 sgd_solver.cpp:106] Iteration 2900, lr = 0.00826148
I0223 01:57:26.332211    44 solver.cpp:341] Iteration 3000, Testing net (#0)
I0223 01:57:32.374083    44 solver.cpp:409]     Test net output #0: accuracy = 0.9888
I0223 01:57:32.374266    44 solver.cpp:409]     Test net output #1: loss = 0.033723 (* 1 = 0.033723 loss)
I0223 01:57:32.571388    44 solver.cpp:237] Iteration 3000, loss = 0.00680536
I0223 01:57:32.571640    44 solver.cpp:253]     Train net output #0: loss = 0.00680546 (* 1 = 0.00680546 loss)
I0223 01:57:32.571693    44 sgd_solver.cpp:106] Iteration 3000, lr = 0.00821377
I0223 01:57:42.397315    44 solver.cpp:237] Iteration 3100, loss = 0.0179094
I0223 01:57:42.397495    44 solver.cpp:253]     Train net output #0: loss = 0.0179095 (* 1 = 0.0179095 loss)
I0223 01:57:42.397542    44 sgd_solver.cpp:106] Iteration 3100, lr = 0.0081667
I0223 01:57:51.873376    44 solver.cpp:237] Iteration 3200, loss = 0.00834312
I0223 01:57:51.873549    44 solver.cpp:253]     Train net output #0: loss = 0.00834321 (* 1 = 0.00834321 loss)
I0223 01:57:51.873591    44 sgd_solver.cpp:106] Iteration 3200, lr = 0.00812025
I0223 01:58:01.775045    44 solver.cpp:237] Iteration 3300, loss = 0.0183674
I0223 01:58:01.775228    44 solver.cpp:253]     Train net output #0: loss = 0.0183675 (* 1 = 0.0183675 loss)
I0223 01:58:01.775276    44 sgd_solver.cpp:106] Iteration 3300, lr = 0.00807442
I0223 01:58:12.432888    44 solver.cpp:237] Iteration 3400, loss = 0.0164344
I0223 01:58:12.433133    44 solver.cpp:253]     Train net output #0: loss = 0.0164345 (* 1 = 0.0164345 loss)
I0223 01:58:12.433176    44 sgd_solver.cpp:106] Iteration 3400, lr = 0.00802918
I0223 01:58:22.239969    44 solver.cpp:341] Iteration 3500, Testing net (#0)
I0223 01:58:28.240986    44 solver.cpp:409]     Test net output #0: accuracy = 0.9858
I0223 01:58:28.241127    44 solver.cpp:409]     Test net output #1: loss = 0.0400001 (* 1 = 0.0400001 loss)
I0223 01:58:28.429677    44 solver.cpp:237] Iteration 3500, loss = 0.00454092
I0223 01:58:28.434584    44 solver.cpp:253]     Train net output #0: loss = 0.00454104 (* 1 = 0.00454104 loss)
I0223 01:58:28.434628    44 sgd_solver.cpp:106] Iteration 3500, lr = 0.00798454
I0223 01:58:37.928710    44 solver.cpp:237] Iteration 3600, loss = 0.0259835
I0223 01:58:37.928889    44 solver.cpp:253]     Train net output #0: loss = 0.0259836 (* 1 = 0.0259836 loss)
I0223 01:58:37.928931    44 sgd_solver.cpp:106] Iteration 3600, lr = 0.00794046
I0223 01:58:47.425593    44 solver.cpp:237] Iteration 3700, loss = 0.0176412
I0223 01:58:47.425796    44 solver.cpp:253]     Train net output #0: loss = 0.0176413 (* 1 = 0.0176413 loss)
I0223 01:58:47.425839    44 sgd_solver.cpp:106] Iteration 3700, lr = 0.00789695
I0223 01:58:57.286501    44 solver.cpp:237] Iteration 3800, loss = 0.0115085
I0223 01:58:57.286708    44 solver.cpp:253]     Train net output #0: loss = 0.0115086 (* 1 = 0.0115086 loss)
I0223 01:58:57.286742    44 sgd_solver.cpp:106] Iteration 3800, lr = 0.007854
I0223 01:59:07.046859    44 solver.cpp:237] Iteration 3900, loss = 0.0318485
I0223 01:59:07.047013    44 solver.cpp:253]     Train net output #0: loss = 0.0318486 (* 1 = 0.0318486 loss)
I0223 01:59:07.047042    44 sgd_solver.cpp:106] Iteration 3900, lr = 0.00781158
I0223 01:59:16.570776    44 solver.cpp:341] Iteration 4000, Testing net (#0)
I0223 01:59:22.414901    44 solver.cpp:409]     Test net output #0: accuracy = 0.9905
I0223 01:59:22.415390    44 solver.cpp:409]     Test net output #1: loss = 0.0289431 (* 1 = 0.0289431 loss)
I0223 01:59:22.615506    44 solver.cpp:237] Iteration 4000, loss = 0.0254453
I0223 01:59:22.622440    44 solver.cpp:253]     Train net output #0: loss = 0.0254453 (* 1 = 0.0254453 loss)
I0223 01:59:22.622485    44 sgd_solver.cpp:106] Iteration 4000, lr = 0.0077697
I0223 01:59:31.856209    44 solver.cpp:237] Iteration 4100, loss = 0.0244042
I0223 01:59:31.856355    44 solver.cpp:253]     Train net output #0: loss = 0.0244043 (* 1 = 0.0244043 loss)
I0223 01:59:31.856385    44 sgd_solver.cpp:106] Iteration 4100, lr = 0.00772833
I0223 01:59:40.992347    44 solver.cpp:237] Iteration 4200, loss = 0.00781169
I0223 01:59:40.998765    44 solver.cpp:253]     Train net output #0: loss = 0.00781176 (* 1 = 0.00781176 loss)
I0223 01:59:40.998814    44 sgd_solver.cpp:106] Iteration 4200, lr = 0.00768748
I0223 01:59:50.265188    44 solver.cpp:237] Iteration 4300, loss = 0.0349368
I0223 01:59:50.265360    44 solver.cpp:253]     Train net output #0: loss = 0.0349369 (* 1 = 0.0349369 loss)
I0223 01:59:50.265390    44 sgd_solver.cpp:106] Iteration 4300, lr = 0.00764712
I0223 01:59:59.882896    44 solver.cpp:237] Iteration 4400, loss = 0.0129563
I0223 01:59:59.883071    44 solver.cpp:253]     Train net output #0: loss = 0.0129563 (* 1 = 0.0129563 loss)
I0223 01:59:59.883102    44 sgd_solver.cpp:106] Iteration 4400, lr = 0.00760726
I0223 02:00:09.104411    44 solver.cpp:341] Iteration 4500, Testing net (#0)
I0223 02:00:14.847357    44 solver.cpp:409]     Test net output #0: accuracy = 0.9895
I0223 02:00:14.847532    44 solver.cpp:409]     Test net output #1: loss = 0.0338849 (* 1 = 0.0338849 loss)
I0223 02:00:15.044752    44 solver.cpp:237] Iteration 4500, loss = 0.00742721
I0223 02:00:15.044965    44 solver.cpp:253]     Train net output #0: loss = 0.00742725 (* 1 = 0.00742725 loss)
I0223 02:00:15.044999    44 sgd_solver.cpp:106] Iteration 4500, lr = 0.00756788
I0223 02:00:27.064563    44 solver.cpp:237] Iteration 4600, loss = 0.017721
I0223 02:00:27.064710    44 solver.cpp:253]     Train net output #0: loss = 0.017721 (* 1 = 0.017721 loss)
I0223 02:00:27.064740    44 sgd_solver.cpp:106] Iteration 4600, lr = 0.00752897
I0223 02:00:37.593317    44 solver.cpp:237] Iteration 4700, loss = 0.00323756
I0223 02:00:37.593508    44 solver.cpp:253]     Train net output #0: loss = 0.00323762 (* 1 = 0.00323762 loss)
I0223 02:00:37.593538    44 sgd_solver.cpp:106] Iteration 4700, lr = 0.00749052
I0223 02:00:47.933770    44 solver.cpp:237] Iteration 4800, loss = 0.0139044
I0223 02:00:47.933954    44 solver.cpp:253]     Train net output #0: loss = 0.0139044 (* 1 = 0.0139044 loss)
I0223 02:00:47.933985    44 sgd_solver.cpp:106] Iteration 4800, lr = 0.00745253
I0223 02:00:57.808229    44 solver.cpp:237] Iteration 4900, loss = 0.00981895
I0223 02:00:57.808526    44 solver.cpp:253]     Train net output #0: loss = 0.009819 (* 1 = 0.009819 loss)
I0223 02:00:57.808604    44 sgd_solver.cpp:106] Iteration 4900, lr = 0.00741498
I0223 02:01:06.730237    44 solver.cpp:459] Snapshotting to binary proto file examples/mnist/lenet_iter_5000.caffemodel
I0223 02:01:06.736296    44 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_5000.solverstate
I0223 02:01:06.739365    44 solver.cpp:341] Iteration 5000, Testing net (#0)
I0223 02:01:12.269330    44 solver.cpp:409]     Test net output #0: accuracy = 0.9898
I0223 02:01:12.269824    44 solver.cpp:409]     Test net output #1: loss = 0.0297332 (* 1 = 0.0297332 loss)
I0223 02:01:12.403928    44 solver.cpp:237] Iteration 5000, loss = 0.0337955
I0223 02:01:12.404079    44 solver.cpp:253]     Train net output #0: loss = 0.0337956 (* 1 = 0.0337956 loss)
I0223 02:01:12.404109    44 sgd_solver.cpp:106] Iteration 5000, lr = 0.00737788
I0223 02:01:21.441057    44 solver.cpp:237] Iteration 5100, loss = 0.0244742
I0223 02:01:21.441212    44 solver.cpp:253]     Train net output #0: loss = 0.0244742 (* 1 = 0.0244742 loss)
I0223 02:01:21.441244    44 sgd_solver.cpp:106] Iteration 5100, lr = 0.0073412
I0223 02:01:30.355368    44 solver.cpp:237] Iteration 5200, loss = 0.00885851
I0223 02:01:30.355540    44 solver.cpp:253]     Train net output #0: loss = 0.00885855 (* 1 = 0.00885855 loss)
I0223 02:01:30.355571    44 sgd_solver.cpp:106] Iteration 5200, lr = 0.00730495
I0223 02:01:39.862016    44 solver.cpp:237] Iteration 5300, loss = 0.00191761
I0223 02:01:39.862268    44 solver.cpp:253]     Train net output #0: loss = 0.00191765 (* 1 = 0.00191765 loss)
I0223 02:01:39.862318    44 sgd_solver.cpp:106] Iteration 5300, lr = 0.00726911
I0223 02:01:49.382998    44 solver.cpp:237] Iteration 5400, loss = 0.00887214
I0223 02:01:49.383168    44 solver.cpp:253]     Train net output #0: loss = 0.00887217 (* 1 = 0.00887217 loss)
I0223 02:01:49.383199    44 sgd_solver.cpp:106] Iteration 5400, lr = 0.00723368
I0223 02:01:58.351377    44 solver.cpp:341] Iteration 5500, Testing net (#0)
I0223 02:02:04.175647    44 solver.cpp:409]     Test net output #0: accuracy = 0.9892
I0223 02:02:04.175804    44 solver.cpp:409]     Test net output #1: loss = 0.0323818 (* 1 = 0.0323818 loss)
I0223 02:02:04.311384    44 solver.cpp:237] Iteration 5500, loss = 0.00355982
I0223 02:02:04.311530    44 solver.cpp:253]     Train net output #0: loss = 0.00355985 (* 1 = 0.00355985 loss)
I0223 02:02:04.311563    44 sgd_solver.cpp:106] Iteration 5500, lr = 0.00719865
I0223 02:02:13.531612    44 solver.cpp:237] Iteration 5600, loss = 0.00234893
I0223 02:02:13.531774    44 solver.cpp:253]     Train net output #0: loss = 0.00234895 (* 1 = 0.00234895 loss)
I0223 02:02:13.531803    44 sgd_solver.cpp:106] Iteration 5600, lr = 0.00716402
I0223 02:02:22.829270    44 solver.cpp:237] Iteration 5700, loss = 0.00426028
I0223 02:02:22.829463    44 solver.cpp:253]     Train net output #0: loss = 0.00426031 (* 1 = 0.00426031 loss)
I0223 02:02:22.829493    44 sgd_solver.cpp:106] Iteration 5700, lr = 0.00712977
I0223 02:02:31.903908    44 solver.cpp:237] Iteration 5800, loss = 0.0492553
I0223 02:02:31.904063    44 solver.cpp:253]     Train net output #0: loss = 0.0492553 (* 1 = 0.0492553 loss)
I0223 02:02:31.904093    44 sgd_solver.cpp:106] Iteration 5800, lr = 0.0070959
I0223 02:02:40.885152    44 solver.cpp:237] Iteration 5900, loss = 0.00669126
I0223 02:02:40.885296    44 solver.cpp:253]     Train net output #0: loss = 0.00669128 (* 1 = 0.00669128 loss)
I0223 02:02:40.885360    44 sgd_solver.cpp:106] Iteration 5900, lr = 0.0070624
I0223 02:02:49.825327    44 solver.cpp:341] Iteration 6000, Testing net (#0)
I0223 02:02:55.349416    44 solver.cpp:409]     Test net output #0: accuracy = 0.9912
I0223 02:02:55.349930    44 solver.cpp:409]     Test net output #1: loss = 0.0270558 (* 1 = 0.0270558 loss)
I0223 02:02:55.485954    44 solver.cpp:237] Iteration 6000, loss = 0.00455922
I0223 02:02:55.486284    44 solver.cpp:253]     Train net output #0: loss = 0.00455924 (* 1 = 0.00455924 loss)
I0223 02:02:55.486318    44 sgd_solver.cpp:106] Iteration 6000, lr = 0.00702927
I0223 02:03:04.719398    44 solver.cpp:237] Iteration 6100, loss = 0.00273481
I0223 02:03:04.719533    44 solver.cpp:253]     Train net output #0: loss = 0.00273484 (* 1 = 0.00273484 loss)
I0223 02:03:04.719563    44 sgd_solver.cpp:106] Iteration 6100, lr = 0.0069965
I0223 02:03:13.904741    44 solver.cpp:237] Iteration 6200, loss = 0.0058179
I0223 02:03:13.904884    44 solver.cpp:253]     Train net output #0: loss = 0.00581793 (* 1 = 0.00581793 loss)
I0223 02:03:13.904914    44 sgd_solver.cpp:106] Iteration 6200, lr = 0.00696408
I0223 02:03:23.094282    44 solver.cpp:237] Iteration 6300, loss = 0.00414863
I0223 02:03:23.094422    44 solver.cpp:253]     Train net output #0: loss = 0.00414866 (* 1 = 0.00414866 loss)
I0223 02:03:23.094452    44 sgd_solver.cpp:106] Iteration 6300, lr = 0.00693201
I0223 02:03:31.984555    44 solver.cpp:237] Iteration 6400, loss = 0.00804563
I0223 02:03:31.984735    44 solver.cpp:253]     Train net output #0: loss = 0.00804567 (* 1 = 0.00804567 loss)
I0223 02:03:31.984814    44 sgd_solver.cpp:106] Iteration 6400, lr = 0.00690029
I0223 02:03:41.536550    44 solver.cpp:341] Iteration 6500, Testing net (#0)
I0223 02:03:48.857473    44 solver.cpp:409]     Test net output #0: accuracy = 0.9902
I0223 02:03:48.857645    44 solver.cpp:409]     Test net output #1: loss = 0.028888 (* 1 = 0.028888 loss)
I0223 02:03:49.048750    44 solver.cpp:237] Iteration 6500, loss = 0.00712585
I0223 02:03:49.054565    44 solver.cpp:253]     Train net output #0: loss = 0.0071259 (* 1 = 0.0071259 loss)
I0223 02:03:49.054611    44 sgd_solver.cpp:106] Iteration 6500, lr = 0.0068689
I0223 02:03:58.414028    44 solver.cpp:237] Iteration 6600, loss = 0.0356221
I0223 02:03:58.414216    44 solver.cpp:253]     Train net output #0: loss = 0.0356221 (* 1 = 0.0356221 loss)
I0223 02:03:58.414247    44 sgd_solver.cpp:106] Iteration 6600, lr = 0.00683784
I0223 02:04:08.408347    44 solver.cpp:237] Iteration 6700, loss = 0.00903702
I0223 02:04:08.408560    44 solver.cpp:253]     Train net output #0: loss = 0.00903707 (* 1 = 0.00903707 loss)
I0223 02:04:08.408591    44 sgd_solver.cpp:106] Iteration 6700, lr = 0.00680711
I0223 02:04:17.601558    44 solver.cpp:237] Iteration 6800, loss = 0.003174
I0223 02:04:17.601721    44 solver.cpp:253]     Train net output #0: loss = 0.00317405 (* 1 = 0.00317405 loss)
I0223 02:04:17.601752    44 sgd_solver.cpp:106] Iteration 6800, lr = 0.0067767
I0223 02:04:28.308311    44 solver.cpp:237] Iteration 6900, loss = 0.00313494
I0223 02:04:28.308482    44 solver.cpp:253]     Train net output #0: loss = 0.00313499 (* 1 = 0.00313499 loss)
I0223 02:04:28.308512    44 sgd_solver.cpp:106] Iteration 6900, lr = 0.0067466
I0223 02:04:37.561802    44 solver.cpp:341] Iteration 7000, Testing net (#0)
I0223 02:04:43.821415    44 solver.cpp:409]     Test net output #0: accuracy = 0.9902
I0223 02:04:43.821666    44 solver.cpp:409]     Test net output #1: loss = 0.0293067 (* 1 = 0.0293067 loss)
I0223 02:04:44.016057    44 solver.cpp:237] Iteration 7000, loss = 0.00291489
I0223 02:04:44.022603    44 solver.cpp:253]     Train net output #0: loss = 0.00291494 (* 1 = 0.00291494 loss)
I0223 02:04:44.022661    44 sgd_solver.cpp:106] Iteration 7000, lr = 0.00671681
I0223 02:04:53.853245    44 solver.cpp:237] Iteration 7100, loss = 0.0143408
I0223 02:04:53.853462    44 solver.cpp:253]     Train net output #0: loss = 0.0143409 (* 1 = 0.0143409 loss)
I0223 02:04:53.853502    44 sgd_solver.cpp:106] Iteration 7100, lr = 0.00668733
I0223 02:05:04.234617    44 solver.cpp:237] Iteration 7200, loss = 0.0044019
I0223 02:05:04.234757    44 solver.cpp:253]     Train net output #0: loss = 0.00440195 (* 1 = 0.00440195 loss)
I0223 02:05:04.234787    44 sgd_solver.cpp:106] Iteration 7200, lr = 0.00665815
I0223 02:05:14.054394    44 solver.cpp:237] Iteration 7300, loss = 0.016781
I0223 02:05:14.054591    44 solver.cpp:253]     Train net output #0: loss = 0.0167811 (* 1 = 0.0167811 loss)
I0223 02:05:14.054689    44 sgd_solver.cpp:106] Iteration 7300, lr = 0.00662927
I0223 02:05:24.600615    44 solver.cpp:237] Iteration 7400, loss = 0.00474613
I0223 02:05:24.600757    44 solver.cpp:253]     Train net output #0: loss = 0.00474617 (* 1 = 0.00474617 loss)
I0223 02:05:24.600788    44 sgd_solver.cpp:106] Iteration 7400, lr = 0.00660067
I0223 02:05:34.184334    44 solver.cpp:341] Iteration 7500, Testing net (#0)
I0223 02:05:42.755837    44 solver.cpp:409]     Test net output #0: accuracy = 0.9886
I0223 02:05:42.755995    44 solver.cpp:409]     Test net output #1: loss = 0.0325766 (* 1 = 0.0325766 loss)
I0223 02:05:42.994469    44 solver.cpp:237] Iteration 7500, loss = 0.0016384
I0223 02:05:42.994655    44 solver.cpp:253]     Train net output #0: loss = 0.00163845 (* 1 = 0.00163845 loss)
I0223 02:05:42.994709    44 sgd_solver.cpp:106] Iteration 7500, lr = 0.00657236
I0223 02:05:54.513424    44 solver.cpp:237] Iteration 7600, loss = 0.0081535
I0223 02:05:54.513651    44 solver.cpp:253]     Train net output #0: loss = 0.00815354 (* 1 = 0.00815354 loss)
I0223 02:05:54.513701    44 sgd_solver.cpp:106] Iteration 7600, lr = 0.00654433
I0223 02:06:06.332446    44 solver.cpp:237] Iteration 7700, loss = 0.017341
I0223 02:06:06.332623    44 solver.cpp:253]     Train net output #0: loss = 0.017341 (* 1 = 0.017341 loss)
I0223 02:06:06.332664    44 sgd_solver.cpp:106] Iteration 7700, lr = 0.00651658
I0223 02:06:19.548151    44 solver.cpp:237] Iteration 7800, loss = 0.00318524
I0223 02:06:19.554599    44 solver.cpp:253]     Train net output #0: loss = 0.00318529 (* 1 = 0.00318529 loss)
I0223 02:06:19.554662    44 sgd_solver.cpp:106] Iteration 7800, lr = 0.00648911
I0223 02:06:32.178081    44 solver.cpp:237] Iteration 7900, loss = 0.00884567
I0223 02:06:32.178262    44 solver.cpp:253]     Train net output #0: loss = 0.00884571 (* 1 = 0.00884571 loss)
I0223 02:06:32.178292    44 sgd_solver.cpp:106] Iteration 7900, lr = 0.0064619
I0223 02:06:43.322572    44 solver.cpp:341] Iteration 8000, Testing net (#0)
I0223 02:06:50.159412    44 solver.cpp:409]     Test net output #0: accuracy = 0.9913
I0223 02:06:50.159600    44 solver.cpp:409]     Test net output #1: loss = 0.0276866 (* 1 = 0.0276866 loss)
I0223 02:06:50.382526    44 solver.cpp:237] Iteration 8000, loss = 0.0054456
I0223 02:06:50.382711    44 solver.cpp:253]     Train net output #0: loss = 0.00544563 (* 1 = 0.00544563 loss)
I0223 02:06:50.382762    44 sgd_solver.cpp:106] Iteration 8000, lr = 0.00643496
I0223 02:07:02.436652    44 solver.cpp:237] Iteration 8100, loss = 0.00675909
I0223 02:07:02.436887    44 solver.cpp:253]     Train net output #0: loss = 0.00675913 (* 1 = 0.00675913 loss)
I0223 02:07:02.436945    44 sgd_solver.cpp:106] Iteration 8100, lr = 0.00640827
I0223 02:07:14.542472    44 solver.cpp:237] Iteration 8200, loss = 0.00516281
I0223 02:07:14.542601    44 solver.cpp:253]     Train net output #0: loss = 0.00516284 (* 1 = 0.00516284 loss)
I0223 02:07:14.542634    44 sgd_solver.cpp:106] Iteration 8200, lr = 0.00638185
I0223 02:07:28.075289    44 solver.cpp:237] Iteration 8300, loss = 0.0537472
I0223 02:07:28.075434    44 solver.cpp:253]     Train net output #0: loss = 0.0537473 (* 1 = 0.0537473 loss)
I0223 02:07:28.075465    44 sgd_solver.cpp:106] Iteration 8300, lr = 0.00635567
I0223 02:07:42.875475    44 solver.cpp:237] Iteration 8400, loss = 0.00703079
I0223 02:07:42.875685    44 solver.cpp:253]     Train net output #0: loss = 0.00703082 (* 1 = 0.00703082 loss)
I0223 02:07:42.875718    44 sgd_solver.cpp:106] Iteration 8400, lr = 0.00632975
I0223 02:07:55.288892    44 solver.cpp:341] Iteration 8500, Testing net (#0)
I0223 02:08:02.558327    44 solver.cpp:409]     Test net output #0: accuracy = 0.9904
I0223 02:08:02.558545    44 solver.cpp:409]     Test net output #1: loss = 0.0276197 (* 1 = 0.0276197 loss)
I0223 02:08:02.755761    44 solver.cpp:237] Iteration 8500, loss = 0.00686731
I0223 02:08:02.755888    44 solver.cpp:253]     Train net output #0: loss = 0.00686734 (* 1 = 0.00686734 loss)
I0223 02:08:02.755987    44 sgd_solver.cpp:106] Iteration 8500, lr = 0.00630407
I0223 02:08:14.088973    44 solver.cpp:237] Iteration 8600, loss = 0.000602599
I0223 02:08:14.089175    44 solver.cpp:253]     Train net output #0: loss = 0.000602633 (* 1 = 0.000602633 loss)
I0223 02:08:14.089226    44 sgd_solver.cpp:106] Iteration 8600, lr = 0.00627864
I0223 02:08:25.748958    44 solver.cpp:237] Iteration 8700, loss = 0.0037795
I0223 02:08:25.749187    44 solver.cpp:253]     Train net output #0: loss = 0.00377953 (* 1 = 0.00377953 loss)
I0223 02:08:25.749243    44 sgd_solver.cpp:106] Iteration 8700, lr = 0.00625344
I0223 02:08:36.906057    44 solver.cpp:237] Iteration 8800, loss = 0.000775347
I0223 02:08:36.906498    44 solver.cpp:253]     Train net output #0: loss = 0.000775383 (* 1 = 0.000775383 loss)
I0223 02:08:36.906563    44 sgd_solver.cpp:106] Iteration 8800, lr = 0.00622847
I0223 02:08:48.269039    44 solver.cpp:237] Iteration 8900, loss = 0.000585523
I0223 02:08:48.269243    44 solver.cpp:253]     Train net output #0: loss = 0.000585561 (* 1 = 0.000585561 loss)
I0223 02:08:48.269292    44 sgd_solver.cpp:106] Iteration 8900, lr = 0.00620374
I0223 02:09:02.475245    44 solver.cpp:341] Iteration 9000, Testing net (#0)
I0223 02:09:09.963074    44 solver.cpp:409]     Test net output #0: accuracy = 0.9905
I0223 02:09:09.963228    44 solver.cpp:409]     Test net output #1: loss = 0.027415 (* 1 = 0.027415 loss)
I0223 02:09:10.142630    44 solver.cpp:237] Iteration 9000, loss = 0.013989
I0223 02:09:10.142812    44 solver.cpp:253]     Train net output #0: loss = 0.013989 (* 1 = 0.013989 loss)
I0223 02:09:10.142859    44 sgd_solver.cpp:106] Iteration 9000, lr = 0.00617924
I0223 02:09:21.454452    44 solver.cpp:237] Iteration 9100, loss = 0.00610518
I0223 02:09:21.454658    44 solver.cpp:253]     Train net output #0: loss = 0.00610521 (* 1 = 0.00610521 loss)
I0223 02:09:21.454704    44 sgd_solver.cpp:106] Iteration 9100, lr = 0.00615496
I0223 02:09:33.114684    44 solver.cpp:237] Iteration 9200, loss = 0.00357963
I0223 02:09:33.114890    44 solver.cpp:253]     Train net output #0: loss = 0.00357966 (* 1 = 0.00357966 loss)
I0223 02:09:33.114936    44 sgd_solver.cpp:106] Iteration 9200, lr = 0.0061309
I0223 02:09:44.908414    44 solver.cpp:237] Iteration 9300, loss = 0.00551846
I0223 02:09:44.908551    44 solver.cpp:253]     Train net output #0: loss = 0.00551848 (* 1 = 0.00551848 loss)
I0223 02:09:44.908582    44 sgd_solver.cpp:106] Iteration 9300, lr = 0.00610706
I0223 02:09:56.326493    44 solver.cpp:237] Iteration 9400, loss = 0.0156647
I0223 02:09:56.326715    44 solver.cpp:253]     Train net output #0: loss = 0.0156647 (* 1 = 0.0156647 loss)
I0223 02:09:56.326812    44 sgd_solver.cpp:106] Iteration 9400, lr = 0.00608343
I0223 02:10:08.169700    44 solver.cpp:341] Iteration 9500, Testing net (#0)
I0223 02:10:15.605099    44 solver.cpp:409]     Test net output #0: accuracy = 0.9898
I0223 02:10:15.605384    44 solver.cpp:409]     Test net output #1: loss = 0.0315486 (* 1 = 0.0315486 loss)
I0223 02:10:15.768818    44 solver.cpp:237] Iteration 9500, loss = 0.00340382
I0223 02:10:15.769060    44 solver.cpp:253]     Train net output #0: loss = 0.00340384 (* 1 = 0.00340384 loss)
I0223 02:10:15.769134    44 sgd_solver.cpp:106] Iteration 9500, lr = 0.00606002
I0223 02:10:29.131315    44 solver.cpp:237] Iteration 9600, loss = 0.00411426
I0223 02:10:29.131621    44 solver.cpp:253]     Train net output #0: loss = 0.00411428 (* 1 = 0.00411428 loss)
I0223 02:10:29.131639    44 sgd_solver.cpp:106] Iteration 9600, lr = 0.00603682
I0223 02:10:43.070389    44 solver.cpp:237] Iteration 9700, loss = 0.00239661
I0223 02:10:43.070544    44 solver.cpp:253]     Train net output #0: loss = 0.00239663 (* 1 = 0.00239663 loss)
I0223 02:10:43.070576    44 sgd_solver.cpp:106] Iteration 9700, lr = 0.00601382
I0223 02:10:55.802196    44 solver.cpp:237] Iteration 9800, loss = 0.0152147
I0223 02:10:55.802407    44 solver.cpp:253]     Train net output #0: loss = 0.0152147 (* 1 = 0.0152147 loss)
I0223 02:10:55.802449    44 sgd_solver.cpp:106] Iteration 9800, lr = 0.00599102
I0223 02:11:08.274448    44 solver.cpp:237] Iteration 9900, loss = 0.00362139
I0223 02:11:08.274652    44 solver.cpp:253]     Train net output #0: loss = 0.00362143 (* 1 = 0.00362143 loss)
I0223 02:11:08.274699    44 sgd_solver.cpp:106] Iteration 9900, lr = 0.00596843
I0223 02:11:20.818157    44 solver.cpp:459] Snapshotting to binary proto file examples/mnist/lenet_iter_10000.caffemodel
I0223 02:11:20.825526    44 sgd_solver.cpp:269] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_10000.solverstate
I0223 02:11:20.948176    44 solver.cpp:321] Iteration 10000, loss = 0.00316258
I0223 02:11:20.950793    44 solver.cpp:341] Iteration 10000, Testing net (#0)
I0223 02:11:28.999145    44 solver.cpp:409]     Test net output #0: accuracy = 0.991
I0223 02:11:28.999346    44 solver.cpp:409]     Test net output #1: loss = 0.026226 (* 1 = 0.026226 loss)
I0223 02:11:28.999389    44 solver.cpp:326] Optimization Done.
I0223 02:11:28.999416    44 caffe.cpp:215] Optimization Done.


###########################################################

analysis the model file via python
 原链接：http://blog.csdn.net/langb2014/article/details/52995086

# script start # 
---
import numpy as np  
import scipy.io as sio  
import caffe  

def load():  
    # Load the net  
    caffe.set_mode_cpu()  
    # You may need to train this caffemodel first  
    #root = "/opt/caffe/examples/mnist"
    # There should be script to help you do the training  
    net = caffe.Net(root + 'lenet.prototxt', root + 'lenet_iter_10000.caffemodel', caffe.TEST)  
    conv1_w = net.params['conv1'][0].data  
    conv1_b = net.params['conv1'][1].data  
    conv2_w = net.params['conv2'][0].data  
    conv2_b = net.params['conv2'][1].data  
    ip1_w = net.params['ip1'][0].data  
    ip1_b = net.params['ip1'][1].data  
    ip2_w = net.params['ip2'][0].data  
    ip2_b = net.params['ip2'][1].data  
    sio.savemat('conv1_w', {'conv1_w':conv1_w})  
    sio.savemat('conv1_b', {'conv1_b':conv1_b})  
    sio.savemat('conv2_w', {'conv2_w':conv2_w})  
    sio.savemat('conv2_b', {'conv2_b':conv2_b})  
    sio.savemat('ip1_w', {'ip1_w':ip1_w})  
    sio.savemat('ip1_b', {'ip1_b':ip1_b})  
    sio.savemat('ip2_w', {'ip2_w':ip2_w})  
    sio.savemat('ip2_b', {'ip2_b':ip2_b})  
  
if __name__ == "__main__":  
    # You will need to change this path  
    #root = '/caffe/examples/mnist/'  
    root = "/opt/caffe/examples/mnist/"
    load()  
    print 'Caffemodel loaded and written to .mat files successfully!'  


# end python script

# start matlab # 
after split into different mat file, use octave(Matlab) to read them:

clear;close all;clc  
%% Parse the ConvNet parameters loaded from caffe into better fit version  
% Author: Yuliang Zou  
% Date: 06/14/2016  
  
%% Load parameters  
load('conv1_w.mat');  
load('conv1_b.mat');  
load('conv2_w.mat');  
load('conv2_b.mat');  
load('ip1_w.mat');  
load('ip1_b.mat');  
load('ip2_w.mat');  
load('ip2_b.mat');  
  
%% Parse parameters into better fit version  
% conv1 has 20 filters with 5 * 5 size   
W1 = zeros(5,5,20);  
for i = 1:20  
    W1(:,:,i) = conv1_w(i,1,:,:);  
end  
b1 = double(conv1_b');  
% conv2 has 50 filters with 5 * 5 size   
W2 = zeros(5,5,20,50);  
for k = 1:20  
    for i = 1:50  
        W2(:,:,k,i) = conv2_w(i,k,:,:);  
    end  
end  
b2 = double(conv2_b');  
% fc layers  
ip1W = double(ip1_w);  
ip1b = double(ip1_b');  
ip2W = double(ip2_w);  
ip2b = double(ip2_b');  
  
save('parsed_param.mat','W1','W2','b1','b2','ip1W','ip1b','ip2W','ip2b');


# end matlab  #


all the datas:

through the train data:
training images (labels) : 60000 ,  (28x28) each 

caffe weights and bias matrix , we have 

conv1_w size -> (20,1,5,5)
conv1_b size -> (1,20)   => need T() it 

conv2_w size -> (50,20, 5,5)
conv2_b size -> (1,50)

ip1_w   size -> (500,800)
ip1_b   size -> (1,500) 

ip2_w   size -> (10,500)
ip2_b   size -> (1,10)


### run caffe test ### 
root@3ce2f5b85241:/opt/caffe# caffe test -model=examples/mnist/lenet_train_test.prototxt  -weights=examples/mnist/lenet_iter_10000.caffemodel  
libdc1394 error: Failed to initialize libdc1394
I0311 10:14:29.410586   901 caffe.cpp:234] Use CPU.
I0311 10:14:29.414114   901 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0311 10:14:29.421001   901 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0311 10:14:29.421813   901 layer_factory.hpp:76] Creating layer mnist
I0311 10:14:29.422230   901 net.cpp:106] Creating Layer mnist
I0311 10:14:29.422271   901 net.cpp:411] mnist -> data
I0311 10:14:29.422345   901 net.cpp:411] mnist -> label
I0311 10:14:29.422768   902 db_lmdb.cpp:38] Opened lmdb examples/mnist/mnist_test_lmdb
I0311 10:14:29.424774   901 data_layer.cpp:41] output data size: 100,1,28,28
I0311 10:14:29.425294   901 net.cpp:150] Setting up mnist
I0311 10:14:29.425330   901 net.cpp:157] Top shape: 100 1 28 28 (78400)
I0311 10:14:29.425341   901 net.cpp:157] Top shape: 100 (100)
I0311 10:14:29.425348   901 net.cpp:165] Memory required for data: 314000
I0311 10:14:29.425360   901 layer_factory.hpp:76] Creating layer label_mnist_1_split
I0311 10:14:29.425385   901 net.cpp:106] Creating Layer label_mnist_1_split
I0311 10:14:29.425393   901 net.cpp:454] label_mnist_1_split <- label
I0311 10:14:29.425407   901 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_0
I0311 10:14:29.425421   901 net.cpp:411] label_mnist_1_split -> label_mnist_1_split_1
I0311 10:14:29.425433   901 net.cpp:150] Setting up label_mnist_1_split
I0311 10:14:29.425443   901 net.cpp:157] Top shape: 100 (100)
I0311 10:14:29.425449   901 net.cpp:157] Top shape: 100 (100)
I0311 10:14:29.425454   901 net.cpp:165] Memory required for data: 314800
I0311 10:14:29.425460   901 layer_factory.hpp:76] Creating layer conv1
I0311 10:14:29.425477   901 net.cpp:106] Creating Layer conv1
I0311 10:14:29.425483   901 net.cpp:454] conv1 <- data
I0311 10:14:29.425492   901 net.cpp:411] conv1 -> conv1
I0311 10:14:29.425598   901 net.cpp:150] Setting up conv1
I0311 10:14:29.425623   901 net.cpp:157] Top shape: 100 20 24 24 (1152000)
I0311 10:14:29.425631   901 net.cpp:165] Memory required for data: 4922800
I0311 10:14:29.425645   901 layer_factory.hpp:76] Creating layer pool1
I0311 10:14:29.425695   901 net.cpp:106] Creating Layer pool1
I0311 10:14:29.425703   901 net.cpp:454] pool1 <- conv1
I0311 10:14:29.425710   901 net.cpp:411] pool1 -> pool1
I0311 10:14:29.425739   901 net.cpp:150] Setting up pool1
I0311 10:14:29.425746   901 net.cpp:157] Top shape: 100 20 12 12 (288000)
I0311 10:14:29.425751   901 net.cpp:165] Memory required for data: 6074800
I0311 10:14:29.425757   901 layer_factory.hpp:76] Creating layer conv2
I0311 10:14:29.425767   901 net.cpp:106] Creating Layer conv2
I0311 10:14:29.425773   901 net.cpp:454] conv2 <- pool1
I0311 10:14:29.425781   901 net.cpp:411] conv2 -> conv2
I0311 10:14:29.425958   901 net.cpp:150] Setting up conv2
I0311 10:14:29.425978   901 net.cpp:157] Top shape: 100 50 8 8 (320000)
I0311 10:14:29.425986   901 net.cpp:165] Memory required for data: 7354800
I0311 10:14:29.425997   901 layer_factory.hpp:76] Creating layer pool2
I0311 10:14:29.426005   901 net.cpp:106] Creating Layer pool2
I0311 10:14:29.428589   901 net.cpp:454] pool2 <- conv2
I0311 10:14:29.428635   901 net.cpp:411] pool2 -> pool2
I0311 10:14:29.428659   901 net.cpp:150] Setting up pool2
I0311 10:14:29.428670   901 net.cpp:157] Top shape: 100 50 4 4 (80000)
I0311 10:14:29.428676   901 net.cpp:165] Memory required for data: 7674800
I0311 10:14:29.428683   901 layer_factory.hpp:76] Creating layer ip1
I0311 10:14:29.428699   901 net.cpp:106] Creating Layer ip1
I0311 10:14:29.428705   901 net.cpp:454] ip1 <- pool2
I0311 10:14:29.428714   901 net.cpp:411] ip1 -> ip1
I0311 10:14:29.431927   901 net.cpp:150] Setting up ip1
I0311 10:14:29.441854   901 net.cpp:157] Top shape: 100 500 (50000)
I0311 10:14:29.441876   901 net.cpp:165] Memory required for data: 7874800
I0311 10:14:29.441893   901 layer_factory.hpp:76] Creating layer relu1
I0311 10:14:29.441907   901 net.cpp:106] Creating Layer relu1
I0311 10:14:29.441915   901 net.cpp:454] relu1 <- ip1
I0311 10:14:29.441926   901 net.cpp:397] relu1 -> ip1 (in-place)
I0311 10:14:29.441938   901 net.cpp:150] Setting up relu1
I0311 10:14:29.441946   901 net.cpp:157] Top shape: 100 500 (50000)
I0311 10:14:29.441952   901 net.cpp:165] Memory required for data: 8074800
I0311 10:14:29.441959   901 layer_factory.hpp:76] Creating layer ip2
I0311 10:14:29.441970   901 net.cpp:106] Creating Layer ip2
I0311 10:14:29.441977   901 net.cpp:454] ip2 <- ip1
I0311 10:14:29.441985   901 net.cpp:411] ip2 -> ip2
I0311 10:14:29.442086   901 net.cpp:150] Setting up ip2
I0311 10:14:29.442433   901 net.cpp:157] Top shape: 100 10 (1000)
I0311 10:14:29.442445   901 net.cpp:165] Memory required for data: 8078800
I0311 10:14:29.442454   901 layer_factory.hpp:76] Creating layer ip2_ip2_0_split
I0311 10:14:29.442466   901 net.cpp:106] Creating Layer ip2_ip2_0_split
I0311 10:14:29.442471   901 net.cpp:454] ip2_ip2_0_split <- ip2
I0311 10:14:29.442483   901 net.cpp:411] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0311 10:14:29.442494   901 net.cpp:411] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0311 10:14:29.442505   901 net.cpp:150] Setting up ip2_ip2_0_split
I0311 10:14:29.442582   901 net.cpp:157] Top shape: 100 10 (1000)
I0311 10:14:29.442605   901 net.cpp:157] Top shape: 100 10 (1000)
I0311 10:14:29.442611   901 net.cpp:165] Memory required for data: 8086800
I0311 10:14:29.442618   901 layer_factory.hpp:76] Creating layer accuracy
I0311 10:14:29.442633   901 net.cpp:106] Creating Layer accuracy
I0311 10:14:29.442641   901 net.cpp:454] accuracy <- ip2_ip2_0_split_0
I0311 10:14:29.442653   901 net.cpp:454] accuracy <- label_mnist_1_split_0
I0311 10:14:29.442662   901 net.cpp:411] accuracy -> accuracy
I0311 10:14:29.442677   901 net.cpp:150] Setting up accuracy
I0311 10:14:29.442684   901 net.cpp:157] Top shape: (1)
I0311 10:14:29.442690   901 net.cpp:165] Memory required for data: 8086804
I0311 10:14:29.442697   901 layer_factory.hpp:76] Creating layer loss
I0311 10:14:29.442706   901 net.cpp:106] Creating Layer loss
I0311 10:14:29.442713   901 net.cpp:454] loss <- ip2_ip2_0_split_1
I0311 10:14:29.442719   901 net.cpp:454] loss <- label_mnist_1_split_1
I0311 10:14:29.442728   901 net.cpp:411] loss -> loss
I0311 10:14:29.442780   901 layer_factory.hpp:76] Creating layer loss
I0311 10:14:29.442953   901 net.cpp:150] Setting up loss
I0311 10:14:29.442966   901 net.cpp:157] Top shape: (1)
I0311 10:14:29.442972   901 net.cpp:160]     with loss weight 1
I0311 10:14:29.442994   901 net.cpp:165] Memory required for data: 8086808
I0311 10:14:29.443001   901 net.cpp:226] loss needs backward computation.
I0311 10:14:29.443007   901 net.cpp:228] accuracy does not need backward computation.
I0311 10:14:29.443338   901 net.cpp:226] ip2_ip2_0_split needs backward computation.
I0311 10:14:29.443352   901 net.cpp:226] ip2 needs backward computation.
I0311 10:14:29.443375   901 net.cpp:226] relu1 needs backward computation.
I0311 10:14:29.443394   901 net.cpp:226] ip1 needs backward computation.
I0311 10:14:29.443413   901 net.cpp:226] pool2 needs backward computation.
I0311 10:14:29.443430   901 net.cpp:226] conv2 needs backward computation.
I0311 10:14:29.443454   901 net.cpp:226] pool1 needs backward computation.
I0311 10:14:29.443472   901 net.cpp:226] conv1 needs backward computation.
I0311 10:14:29.443495   901 net.cpp:228] label_mnist_1_split does not need backward computation.
I0311 10:14:29.443595   901 net.cpp:228] mnist does not need backward computation.
I0311 10:14:29.443610   901 net.cpp:270] This network produces output accuracy
I0311 10:14:29.443619   901 net.cpp:270] This network produces output loss
I0311 10:14:29.443652   901 net.cpp:283] Network initialization done.
I0311 10:14:29.456727   901 caffe.cpp:240] Running for 50 iterations.
I0311 10:14:29.609956   901 caffe.cpp:264] Batch 0, accuracy = 0.99
I0311 10:14:29.616796   901 caffe.cpp:264] Batch 0, loss = 0.0228337
I0311 10:14:29.790807   901 caffe.cpp:264] Batch 1, accuracy = 1
I0311 10:14:29.796650   901 caffe.cpp:264] Batch 1, loss = 0.00623618
I0311 10:14:29.932454   901 caffe.cpp:264] Batch 2, accuracy = 0.99
I0311 10:14:29.940719   901 caffe.cpp:264] Batch 2, loss = 0.0288877
I0311 10:14:30.087847   901 caffe.cpp:264] Batch 3, accuracy = 0.99
I0311 10:14:30.088731   901 caffe.cpp:264] Batch 3, loss = 0.0316591
I0311 10:14:30.228209   901 caffe.cpp:264] Batch 4, accuracy = 0.99
I0311 10:14:30.233502   901 caffe.cpp:264] Batch 4, loss = 0.056045
I0311 10:14:30.381682   901 caffe.cpp:264] Batch 5, accuracy = 0.98
I0311 10:14:30.381839   901 caffe.cpp:264] Batch 5, loss = 0.0515231
I0311 10:14:30.519738   901 caffe.cpp:264] Batch 6, accuracy = 0.98
I0311 10:14:30.520756   901 caffe.cpp:264] Batch 6, loss = 0.0621839
I0311 10:14:30.649092   901 caffe.cpp:264] Batch 7, accuracy = 0.99
I0311 10:14:30.652288   901 caffe.cpp:264] Batch 7, loss = 0.0324011
I0311 10:14:30.801422   901 caffe.cpp:264] Batch 8, accuracy = 1
I0311 10:14:30.802778   901 caffe.cpp:264] Batch 8, loss = 0.00698865
I0311 10:14:30.959506   901 caffe.cpp:264] Batch 9, accuracy = 0.98
I0311 10:14:30.964872   901 caffe.cpp:264] Batch 9, loss = 0.0298927
I0311 10:14:31.105438   901 caffe.cpp:264] Batch 10, accuracy = 0.98
I0311 10:14:31.106184   901 caffe.cpp:264] Batch 10, loss = 0.0523715
I0311 10:14:31.269026   901 caffe.cpp:264] Batch 11, accuracy = 0.99
I0311 10:14:31.269165   901 caffe.cpp:264] Batch 11, loss = 0.0366823
I0311 10:14:31.525619   901 caffe.cpp:264] Batch 12, accuracy = 0.97
I0311 10:14:31.525903   901 caffe.cpp:264] Batch 12, loss = 0.157934
I0311 10:14:31.671736   901 caffe.cpp:264] Batch 13, accuracy = 0.98
I0311 10:14:31.673447   901 caffe.cpp:264] Batch 13, loss = 0.0420074
I0311 10:14:31.893721   901 caffe.cpp:264] Batch 14, accuracy = 0.99
I0311 10:14:31.893944   901 caffe.cpp:264] Batch 14, loss = 0.0184512
I0311 10:14:32.059119   901 caffe.cpp:264] Batch 15, accuracy = 0.99
I0311 10:14:32.069097   901 caffe.cpp:264] Batch 15, loss = 0.0546906
I0311 10:14:32.264268   901 caffe.cpp:264] Batch 16, accuracy = 0.97
I0311 10:14:32.273054   901 caffe.cpp:264] Batch 16, loss = 0.0453611
I0311 10:14:32.444995   901 caffe.cpp:264] Batch 17, accuracy = 0.99
I0311 10:14:32.445219   901 caffe.cpp:264] Batch 17, loss = 0.0206482
I0311 10:14:32.612059   901 caffe.cpp:264] Batch 18, accuracy = 0.99
I0311 10:14:32.620645   901 caffe.cpp:264] Batch 18, loss = 0.0172798
I0311 10:14:32.768076   901 caffe.cpp:264] Batch 19, accuracy = 0.99
I0311 10:14:32.772650   901 caffe.cpp:264] Batch 19, loss = 0.052516
I0311 10:14:32.930565   901 caffe.cpp:264] Batch 20, accuracy = 0.98
I0311 10:14:32.936811   901 caffe.cpp:264] Batch 20, loss = 0.0876531
I0311 10:14:33.085175   901 caffe.cpp:264] Batch 21, accuracy = 0.98
I0311 10:14:33.085357   901 caffe.cpp:264] Batch 21, loss = 0.0698333
I0311 10:14:33.229094   901 caffe.cpp:264] Batch 22, accuracy = 1
I0311 10:14:33.229573   901 caffe.cpp:264] Batch 22, loss = 0.00783344
I0311 10:14:33.380844   901 caffe.cpp:264] Batch 23, accuracy = 1
I0311 10:14:33.381053   901 caffe.cpp:264] Batch 23, loss = 0.0178684
I0311 10:14:33.520566   901 caffe.cpp:264] Batch 24, accuracy = 0.99
I0311 10:14:33.523713   901 caffe.cpp:264] Batch 24, loss = 0.0294464
I0311 10:14:33.676192   901 caffe.cpp:264] Batch 25, accuracy = 0.99
I0311 10:14:33.680747   901 caffe.cpp:264] Batch 25, loss = 0.0745277
I0311 10:14:33.851770   901 caffe.cpp:264] Batch 26, accuracy = 0.99
I0311 10:14:33.856763   901 caffe.cpp:264] Batch 26, loss = 0.084782
I0311 10:14:33.993563   901 caffe.cpp:264] Batch 27, accuracy = 1
I0311 10:14:33.993751   901 caffe.cpp:264] Batch 27, loss = 0.021071
I0311 10:14:34.140316   901 caffe.cpp:264] Batch 28, accuracy = 0.99
I0311 10:14:34.140460   901 caffe.cpp:264] Batch 28, loss = 0.044861
I0311 10:14:34.343423   901 caffe.cpp:264] Batch 29, accuracy = 0.97
I0311 10:14:34.348795   901 caffe.cpp:264] Batch 29, loss = 0.130298
I0311 10:14:34.477963   901 caffe.cpp:264] Batch 30, accuracy = 0.99
I0311 10:14:34.478242   901 caffe.cpp:264] Batch 30, loss = 0.0151563
I0311 10:14:34.627187   901 caffe.cpp:264] Batch 31, accuracy = 1
I0311 10:14:34.632809   901 caffe.cpp:264] Batch 31, loss = 0.00228157
I0311 10:14:34.771605   901 caffe.cpp:264] Batch 32, accuracy = 1
I0311 10:14:34.781127   901 caffe.cpp:264] Batch 32, loss = 0.0125366
I0311 10:14:34.946841   901 caffe.cpp:264] Batch 33, accuracy = 1
I0311 10:14:34.947844   901 caffe.cpp:264] Batch 33, loss = 0.0052235
I0311 10:14:35.089174   901 caffe.cpp:264] Batch 34, accuracy = 0.98
I0311 10:14:35.089355   901 caffe.cpp:264] Batch 34, loss = 0.0511565
I0311 10:14:35.247633   901 caffe.cpp:264] Batch 35, accuracy = 0.97
I0311 10:14:35.253211   901 caffe.cpp:264] Batch 35, loss = 0.134379
I0311 10:14:35.404397   901 caffe.cpp:264] Batch 36, accuracy = 1
I0311 10:14:35.407415   901 caffe.cpp:264] Batch 36, loss = 0.00512352
I0311 10:14:35.569602   901 caffe.cpp:264] Batch 37, accuracy = 0.99
I0311 10:14:35.569892   901 caffe.cpp:264] Batch 37, loss = 0.045241
I0311 10:14:35.716073   901 caffe.cpp:264] Batch 38, accuracy = 1
I0311 10:14:35.719586   901 caffe.cpp:264] Batch 38, loss = 0.0188238
I0311 10:14:35.888485   901 caffe.cpp:264] Batch 39, accuracy = 0.98
I0311 10:14:35.896992   901 caffe.cpp:264] Batch 39, loss = 0.0465253
I0311 10:14:36.025110   901 caffe.cpp:264] Batch 40, accuracy = 0.98
I0311 10:14:36.025424   901 caffe.cpp:264] Batch 40, loss = 0.0517821
I0311 10:14:36.159728   901 caffe.cpp:264] Batch 41, accuracy = 0.97
I0311 10:14:36.164296   901 caffe.cpp:264] Batch 41, loss = 0.0519671
I0311 10:14:36.325786   901 caffe.cpp:264] Batch 42, accuracy = 0.97
I0311 10:14:36.326071   901 caffe.cpp:264] Batch 42, loss = 0.0412636
I0311 10:14:36.485581   901 caffe.cpp:264] Batch 43, accuracy = 1
I0311 10:14:36.485757   901 caffe.cpp:264] Batch 43, loss = 0.00453503
I0311 10:14:36.616138   901 caffe.cpp:264] Batch 44, accuracy = 0.99
I0311 10:14:36.617000   901 caffe.cpp:264] Batch 44, loss = 0.0330478
I0311 10:14:36.819677   901 caffe.cpp:264] Batch 45, accuracy = 0.99
I0311 10:14:36.824677   901 caffe.cpp:264] Batch 45, loss = 0.0429577
I0311 10:14:37.043701   901 caffe.cpp:264] Batch 46, accuracy = 1
I0311 10:14:37.045068   901 caffe.cpp:264] Batch 46, loss = 0.0044856
I0311 10:14:37.190017   901 caffe.cpp:264] Batch 47, accuracy = 0.99
I0311 10:14:37.192080   901 caffe.cpp:264] Batch 47, loss = 0.0113931
I0311 10:14:37.383335   901 caffe.cpp:264] Batch 48, accuracy = 0.96
I0311 10:14:37.383592   901 caffe.cpp:264] Batch 48, loss = 0.0814395
I0311 10:14:37.507824   901 caffe.cpp:264] Batch 49, accuracy = 1
I0311 10:14:37.510978   901 caffe.cpp:264] Batch 49, loss = 0.00414794
I0311 10:14:37.511279   901 caffe.cpp:269] Loss: 0.0411647
I0311 10:14:37.511636   901 caffe.cpp:281] accuracy = 0.9876
I0311 10:14:37.511682   901 caffe.cpp:281] loss = 0.0411647 (* 1 = 0.0411647 loss)




Caffe（深度学习框架）

Docker


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论












?

?写文章
?




clear_docker_container.PL

jdtangjdtang・
4 个月前2017 年 2月 22 日星期三晚上 8 点 48 分


*********************
clear_docker_container.PL
*********************
#!perl 
use strict ; 
my $IF_NO_EXITED_CONTAINER = 0; 
my @output = `docker ps -a | grep Exited`; 

if (@output == $IF_NO_EXITED_CONTAINER ){
	my $id_text = "- no \"Exited\" docker container\n"; 
	print $id_text ; 
	exit ( 1 ); 
}


my @con_list =( );

map{
	my @a=split ;
	push @con_list, @a[0]." " if !(m/CON/);
}@output;

my $cmd = q();
$cmd .=  qq(\tdocker stop )."@con_list" . " > /dev/null \n"; 
$cmd .=  qq(\tdocker rm   )."@con_list" . " > /dev/null \n"; 

print "- Clear Exited container:\n". $cmd ; 
system( $cmd );  




Perl 编程


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




perl_web_server

jdtangjdtang・
4 个月前2017 年 2月 22 日星期三下午 2 点 19 分


#!/usr/bin/perl

#==============
# Date: 2012-11-03
# User: wcdj
#==============

use Socket;
use Carp;
use FileHandle;

# [1] use port 8080 by default, unless overridden on command line
$port = (@ARGV ? $ARGV[0] : 8080);

my $server_addr = `hostname -I`;
chomp($server_addr);
print " - server addr is :\t$server_addr\n ";


# [2] create local TCP socket and set it to listen for connections
$proto = getprotobyname('tcp');
socket(S, PF_INET, SOCK_STREAM, $proto) || die;
setsockopt(S, SOL_SOCKET, SO_REUSEADDR, pack("l", 1)) || die;
bind(S, sockaddr_in($port, INADDR_ANY)) || die;
listen(S, SOMAXCONN) || die;

# [3] print a startup message
printf("<<< perl_web_svr accepting on port %d >>>\n\n", $port);

while (1)
{
        # [4] wait for a connection C(Client)
        $cport_caddr = accept(C, S);
        ($cport, $caddr) = sockaddr_in($cport_caddr);


        C->autoflush(1);
        print C "Hello world from server $port\r\n" ;

        # [5] print who the connection is from
        $cname = gethostbyaddr($caddr, AF_INET);
        printf("<<< request from [%s] >>>\n", $cname);

        # [6] read request msg until blank line, and print on screen
        while ($line = <C>)
        {
                print $line;
                if ($line =~ /^\r/) {last; }
        }

        # [7] prompt for response msg, and input response lines,
        #     sending response lines to client, until solitary "."
        printf("<<< type response followed by '.' >>>\n");

        while ($line = <STDIN>)
        {
                $line =~ s/\r//;
                $line =~ s/\n//;
                if ($line =~ /^\./) {last; }
                print C $line . "\r\n";
        }

        close(C);

}




Perl 编程


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




BFS_pure_C_char

jdtangjdtang・
4 个月前2017 年 2月 20 日星期一晚上 8 点 26 分


//  g++ -std=c++11 test.cpp  &&  ./a.exe 
// lambda , iostream , adapt
//  cl test.cpp  /EHsc  & test.exe

#include <iostream>
#include <vector>
#include <algorithm>
#include <iterator>
#include <string>
#include <deque>
#include <queue>
#include <thread>         // std::thread, std::this_thread::yield
#include <atomic>         // std::atomic
#include <memory.h>
#include <string.h>
#include <utility>
#include <map>


using namespace std; 
//typedef vector< int > 	v_i; 
#define elementsof(v)   (sizeof (v) / sizeof (v[0]))
#define a_begin(v)      (&v[0])
#define a_end(v)        (v + elementsof (v))
#define a_range(v)      v
#define b_e(v)          a_begin(v),a_end(v)
#define print_v_i(v)	( for_each(v.begin(),v.end(),[](int i){cout<<i<<" ";} ) ) 
#define PRINT_ID_V_I ( print_v_i( id_v_i )  )

int ele_in_arr( char * arr, char ele, char len ){
	int i = 0; 
	for ( i = 0 ; i < len ; i++ ){
		if ( arr[i] == ele ) return 0; 
	}
	return 1; 

}

int  push_to_pipe( char* &pipe_tail , char *to_be_push ){

	strcpy( pipe_tail , to_be_push); 

	pipe_tail += strlen(to_be_push) ; 

	return 0; 

} 



int  push_to_pipe_if_ele_not_in_visited( char** pall, char* &pipe_tail , char ele, char *visited, char visited_loc ){

	if ( ele_in_arr (visited, ele, visited_loc ) == 0 ) {
		return 1 ; 
	}
	char *to_be_push = pall[(int)(ele-'1')]; 
	strcpy( pipe_tail , to_be_push); 
	pipe_tail += strlen(to_be_push) ; 

	return 0; 

} 

char get_head_from_pipe(char* &pipe_head){


	char idx = pipe_head[0] ; 	
	pipe_head ++ ; 
	return idx ; 
}



int push_ele_to_visited_if_not_in_visited(char *visited, char ele, int & visited_loc ){
	if ( visited_loc == 0 ){
		visited[visited_loc] = ele ; 
		visited_loc++; 
		return 0; 
	}
	else {
		if ( ele_in_arr ( visited, ele, visited_loc ) == 0 ){
			return 1; 

		}
		else {
			visited[visited_loc] = ele ; 
			visited_loc++; 
			return 0; 

		}

	}

}


int print_pipe( char *pipe_head, char *pipe_tail ){
	char *p =NULL; 

	printf("- the pipe now is:\n"); 
	for( p = pipe_head; p<pipe_tail; p++){
		printf("%c ", *p); 		
	}
	printf("\n"); 
	return 0; 
}

int print_visited(char *visited, int visited_loc){
	int i = 0; 

	printf("- the visited arr:\n"); 
	for ( i=0;i<visited_loc ; i++){
		printf("%c ", visited[i] ); 			
	}
	printf("\n"); 

	return 0; 

}

int print_tree(char **pall , int len){
	int i=0; 
	printf("\n");
	printf( "- print tree:\n", i+1 ); 
	for(i=0;i<len ; i++){
		printf( " %d -> ", i+1 ); 
		int j =0 ; 
		printf("\t"); 
		for(j=0; j<strlen(pall[i]); j++){
			printf( "%c ", pall[i][j] ); 
		}
		printf("\n");


	}
	return 1; 
}

int main(int argc, char **argv)
{

	if ( argc != 2 ){
		printf("- please input 1 argument,should be one of { 1 | 2 | 3 | 4 | 5} \n");
		return -1; 
	}
#define LEN_ALL 5

	char *p1="23";  // 1 -> 2 3 
	char *p2="3242"; // 2 -> 3 2 4 2
	char *p3="2415"; // 3 -> 2 4 1 5 
	char *p4="143"; // 4 -> 1 4 3


	//###################
	//#define START_NODE  3    // should be one of { 1 | 2 | 3 | 4 | 5} 
	char *p5="23"; // 5-> 2 3 
	char * pall[LEN_ALL] = { p1, p2, p3, p4, p5 };
	int START_NODE = argv[1][0]-'0' ; 
	//###################
	print_tree(pall, LEN_ALL); printf("\n"); 


#define LEN_PIPE 255 
	int i = 0; 
	char *page_r0 = pall[ START_NODE-1 ]; 
	char pipe[LEN_PIPE] = { 0 }; 
	char visited[LEN_ALL] = {0}; 
	int visited_loc = 0; 



	char *to_be_push = NULL; 
	char *pipe_head = NULL; 
	char *pipe_tail = NULL; 


	pipe_head = pipe ; 
	pipe_tail = pipe ; 

	to_be_push = page_r0 ; 


	
	visited[ visited_loc++] = (char)( START_NODE + '0' ) ; 
	push_to_pipe( pipe_tail , to_be_push ); 
	int cnt = 100; 
	while(cnt--)
	{
		print_visited( visited, visited_loc ); 
		print_pipe( pipe_head, pipe_tail ) ; 

		char ele = get_head_from_pipe(pipe_head); 
		to_be_push = pall[(int)(ele - '1') ] ; 
	
		push_to_pipe_if_ele_not_in_visited ( pall, pipe_tail , ele, visited, visited_loc ); 
		push_ele_to_visited_if_not_in_visited (visited, ele, visited_loc ) ; 

		printf("\n"); 
		if ( visited_loc >=LEN_ALL ) {printf("\n- END\n"); break;} 


	}

	printf("\n\n- if FIRST NODE is %d, the visit order will be:\n\t",  START_NODE ); 
	for ( i=0;i<visited_loc ; i++){
		printf("%c ", visited[i] ); 			
	}

	return 0;
}


- The output will be for :

> cl test.cpp /EHsc & test.exe ４


- print tree:
 1 ->   2 3
 2 ->   3 2 4 2
 3 ->   2 4 1 5
 4 ->   1 4 3
 5 ->   2 3

- the visited arr:
4
- the pipe now is:
1 4 3

- the visited arr:
4 1
- the pipe now is:
4 3 2 3

- the visited arr:
4 1
- the pipe now is:
3 2 3

- the visited arr:
4 1 3
- the pipe now is:
2 3 2 4 1 5

- the visited arr:
4 1 3 2
- the pipe now is:
3 2 4 1 5 3 2 4 2

- the visited arr:
4 1 3 2
- the pipe now is:
2 4 1 5 3 2 4 2

- the visited arr:
4 1 3 2
- the pipe now is:
4 1 5 3 2 4 2

- the visited arr:
4 1 3 2
- the pipe now is:
1 5 3 2 4 2

- the visited arr:
4 1 3 2
- the pipe now is:
5 3 2 4 2


- END


- if FIRST NODE is 4, the visit order will be:
        4 1 3 2 5




C（编程语言）


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




Neural_Network_CNN

jdtangjdtang・
4 个月前2017 年 2月 17 日星期五晚上 10 点 24 分


#1 what is Neural Network?


#2 what is CNN?



卷积神经网络（CNN）


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




cpp_map_erase_traverse

jdtangjdtang・
4 个月前2017 年 2月 13 日星期一下午 1 点 50 分


//  g++ -std=c++11 test.cpp  &&  ./a.exe 
// lambda , iostream , adapt
//  cl test.cpp  /EHsc  & test.exe

#include <iostream>
#include <vector>
#include <algorithm>
#include <iterator>
#include <string>
#include<deque>
#include <queue>
#include <thread>         // std::thread, std::this_thread::yield
#include <atomic>         // std::atomic
#include <memory.h>
#include <string.h>
#include <utility>
#include <map>


using namespace std; 
//typedef vector< int > 	v_i; 
#define elementsof(v)   (sizeof (v) / sizeof (v[0]))
#define a_begin(v)      (&v[0])
#define a_end(v)        (v + elementsof (v))
#define a_range(v)      v
#define b_e(v)          a_begin(v),a_end(v)
#define print_v_i(v)	( for_each(v.begin(),v.end(),[](int i){cout<<i<<" ";} ) ) 
#define PRINT_ID_V_I ( print_v_i( id_v_i )  )

void say(int i){
	printf("%d\n",i);
}
void say(char *i){
	printf("%s\n",i);
}
void say(string i){
	printf("%s\n",i.c_str());
}


int main()
{
	map <string, int> id_m; 
	id_m["jd"] = 1; 
	id_m["yl"]=0;

	id_m["yl"]=33; 
	id_m["jt"]=-1; 
	string to_ins = "not_exist"; 
	auto ret0 = id_m.insert(make_pair("hello",5));
	auto ret1 = id_m.insert(make_pair("hello",100)); // exists , never change 

	say ( ret0.second );    // ---> 1 
	say ( ret1.second );    // ---> 0 


	for(auto   i   =   id_m.begin();   i   !=   id_m.end(); i++) 
	{ 
		say ( i->first ); say(":"); 	   say ( i->second );  say("\n"); 
	} 

	auto ret_remove = id_m.erase( "jt" );   // ---> 1 if exist 
	say("- after remove jt");
	say ( ret_remove ); 
	for(auto   i   =   id_m.begin();   i   !=   id_m.end(); i++) 
	{ 
		say ( i->first ); say(":"); 	   say ( i->second );  say("\n"); 
	} 


	return 0;
}




C++


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




make_pair_return_pair

jdtangjdtang・
4 个月前2017 年 2月 13 日星期一下午 1 点 06 分


//  g++ -std=c++11 test.cpp  &&  ./a.exe 
// lambda , iostream , adapt
//  cl test.cpp  /EHsc  & test.exe

#include <iostream>
#include <vector>
#include <algorithm>
#include <iterator>
#include <string>
#include<deque>
#include <queue>
#include <thread>         // std::thread, std::this_thread::yield
#include <atomic>         // std::atomic
#include <memory.h>
#include <string.h>
#include <utility>


using namespace std; 
//typedef vector< int > 	v_i; 
#define elementsof(v)   (sizeof (v) / sizeof (v[0]))
#define a_begin(v)      (&v[0])
#define a_end(v)        (v + elementsof (v))
#define a_range(v)      v
#define b_e(v)          a_begin(v),a_end(v)
#define print_v_i(v)	( for_each(v.begin(),v.end(),[](int i){cout<<i<<" ";} ) ) 
#define PRINT_ID_V_I ( print_v_i( id_v_i )  )
#define say(i) printf("%d\n",i)


pair <int, int> return_a_pair( ){
	pair<int,int> id_p = make_pair(11,111); 
	return id_p; 
}
	


int main()
{
pair<int, int> id_p=make_pair(11,22); 
say(id_p.first); say(id_p.second); 

auto id_p2 = return_a_pair(); 
say(id_p2.first); say(id_p2.second); 
	
   return 0;
}




C++


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




linux_driver_learning

jdtangjdtang・
4 个月前2017 年 2月 10 日星期五晚上 8 点 32 分

steps:
● create a hello.c 

#include <linux/init.h>  
#include <linux/module.h>  
#include <linux/moduleparam.h>  
MODULE_LICENSE("Dual BSD/GPL");  
static char *whom = "wishmiss";  
static int howmany = 3;  
module_param(howmany, int, S_IRUGO);  
module_param(whom, charp, S_IRUGO);  
static int hello_init(void)  
{  
    int i;  
    for (i = 0; i < howmany; i++)  
        printk(KERN_ALERT "(%d) Hello, %s ！\n", i, whom);  
    return 0;  
}  
static void hello_exit(void)  
{  
    printk(KERN_ALERT "Goodbye, Linux.I will back later ！%s", whom);  
}  
module_init(hello_init);  
module_exit(hello_exit);


● create a simple Makefile 

ifeq ($(KERNELRELEASE),)
KERNELDIR ?= /usr/src/linux-headers-$(shell uname -r)
PWD :=$(shell pwd)

modules:
# very strange, that in kernel_dir, the KERNELRELEASE will be set up 
	$(MAKE) -C $(KERNELDIR) M=$(PWD) modules
modules_install:
	$(MAKE) -C $(KERNELDIR) M=$(PWD) modules_install
clean clear:
	rm -rf *.o *~ core .depend .*.cmd *.ko *.mod.c .tmp_versions

.PHONY: modules modules_install clean

else

obj-m:= hello.o

endif


● build it with : make modules

make -C /usr/src/linux-headers-3.5.0-54-generic M=/home/jd/perl_p/test/ko modules
make[1]: Entering directory `/usr/src/linux-headers-3.5.0-54-generic'
  Building modules, stage 2.
  MODPOST 1 modules
make[1]: Leaving directory `/usr/src/linux-headers-3.5.0-54-generic'


after building, generates hello.ko

● manually install ko file

dmesg -c  && sudo insmod hello.ko 


`dmesg -c`, read and clear the msg buffer 

● see the output of the ko file

dmesg 


● make sure the ko is load 

lsmod | grep hello 


● rm ko file 

sudo rmmod hello




Linux 内核


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




vs_memmem_implement_

jdtangjdtang・
4 个月前2017 年 2月 10 日星期五上午 11 点 01 分


#include <stdio.h>
#include <memory.h>
#include <string.h>


void *memmem(const void *l, size_t l_len, const void *s, size_t s_len){
	register char *cur, *last;
	const char *cl = (const char *)l;
	const char *cs = (const char *)s;

	/* we need something to compare */
	if (l_len == 0 || s_len == 0)
		return NULL;

	/* "s" must be smaller or equal to "l" */
	if (l_len < s_len)
		return NULL;

	/* special case where s_len == 1 */
	if (s_len == 1)
		return memchr(l, (int)*cs, l_len);

	/* the last position where its possible to find "s" in "l" */
	last = (char *)cl + l_len - s_len;

	for (cur = (char *)cl; cur <= last; cur++)
		if (cur[0] == cs[0] && memcmp(cur, cs, s_len) == 0)
			return cur;

	return NULL;
}




int main(){
char *S = "abCeabc"; 
char *s = "Ce"; 


void *S_ = memmem( (void*)S, strlen(S), (void*)s, strlen(s) ) ; 
char *cS_ = (char*)S_ ; 
printf("%c\n", *cS_);     // C

return 0; 
}




C（编程语言）


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




find_out_all_the_substring

jdtangjdtang・
4 个月前2017 年 2月 9 日星期四晚上 10 点 10 分


int main()
{
	char *ptr = "0123456he789 hello world hesfksdf he  EOF"; 
    char *pt = ptr ; 
	int cnt = 3 ; 
	while( 1 ){
		void* t = memchr(pt , 'h', strlen(pt) ); 
		char *ct = (char*) t; 
		char *const_char = "he"; 
		if ( ct - ptr < strlen(ptr)  ){
			
			if ( !memcmp( ct, const_char, strlen(const_char) ) ){
				printf( "- find out : " ); 	
				printf("%s\n", ct ); 
				
			} 
			
		
		}
		else {break; }
		pt = ct+1  ; 

	}
	




C（编程语言）


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




string_cpp_find_insert_crt

jdtangjdtang・
4 个月前2017 年 2月 9 日星期四下午 5 点 19 分


//  g++ -std=c++11 test.cpp  &&  ./a.exe 
// lambda , iostream , adapt
//  cl test.cpp  /EHsc  & test.exe

#include <iostream>
#include <vector>
#include <algorithm>
#include <iterator>
#include <string>
#include<deque>
#include <queue>
#include <thread>         // std::thread, std::this_thread::yield
#include <atomic>         // std::atomic

using namespace std; 
//typedef vector< int > 	v_i; 
#define elementsof(v)   (sizeof (v) / sizeof (v[0]))
#define a_begin(v)      (&v[0])
#define a_end(v)        (v + elementsof (v))
#define a_range(v)      v
#define b_e(v)          a_begin(v),a_end(v)
#define print_v_i(v)	( for_each(v.begin(),v.end(),[](int i){cout<<i<<" ";} ) ) 
#define PRINT_ID_V_I ( print_v_i( id_v_i )  )




int main()
{
	char *ptr = "0123456789 hello world EOF"; 
	
	string s( ptr); 
	string s1( s ) ; 
	auto s2 = s1.substr( 0, 3 );   // ---> 012 
	auto s3 = s1.substr( 0 );   // ---> all string 
	s3.assign(ptr , ptr+8 );  // 01234567
	

	s3.insert(0,s2);
	s3.erase(s3.size()-1,1 );  // EO 
	s3.append( s3 ); 
	s3.replace(0,s3.size()/2, "(0)(1)(2)" ); 
	s3[1]='C'; 
	auto loc= s3.find("(1)");   // s3[loc] is "("
	// rfind() 
	s3.find_first_of( ") ,*" );  // find first of 
	s3.find_first_not_of("(1");    // ---> 1 ;
	auto s4 = to_string(111); 
	auto int_s4 = stoi( s4 ); 
	
	cout << s2 << endl; 
	cout << s3 << endl; 
	cout << s4 << endl ; 
	
	
	
   return 0;
}




字符串


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




boost_split_is_any_of

jdtangjdtang・
4 个月前2017 年 2月 9 日星期四下午 4 点 23 分


*********************
bld.sh
*********************
export LD_LIBRARY_PATH=`pwd`/stage/lib:$LD_LIBRARY_PATH
g++ -I`pwd` -L`pwd`/stage/lib  -lboost_system test.cpp  && a.out



//--------------SRC -----------------
#include <boost/algorithm/string.hpp>
#include <iostream>
#include <string>
#include <vector>

using namespace std;
using namespace boost;

void print( vector <string> & v )
{
  for (size_t n = 0; n < v.size(); n++)
    cout << "\"" << v[ n ] << "\"\n";
  cout << endl;
}

int main()
{
  string s = "a,b, c ,,e,f,";
  vector <string> fields;

  cout << "Original = \"" << s << "\"\n\n";

  cout << "Split on \',\' only\n";
  split( fields, s, is_any_of( "," ) );
  print( fields );

  cout << "Split on \" ,\"\n";
  split( fields, s, is_any_of( " ," ) );
  print( fields );

  cout << "Split on \" ,\" and elide delimiters\n";
  split( fields, s, is_any_of( " ," ), token_compress_on );
  print( fields );

  return 0;
}




Boost（C++库）


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




deque_op_push_back_pop_front_c_assign

jdtangjdtang・
4 个月前2017 年 2月 9 日星期四下午 4 点 12 分


*********************
test.cpp
*********************
//  g++ -std=c++11 test.cpp  &&  ./a.exe
// lambda , iostream , adapt
//  cl test.cpp  /EHsc  & test.exe

#include <iostream>
#include <vector>
#include <algorithm>
#include <iterator>
#include <string>
#include<deque>
#include <queue>
#include <thread>         // std::thread, std::this_thread::yield
#include <atomic>         // std::atomic

using namespace std;
//typedef vector< int >         v_i;
#define elementsof(v)   (sizeof (v) / sizeof (v[0]))
#define a_begin(v)      (&v[0])
#define a_end(v)        (v + elementsof (v))
#define a_range(v)      v
#define b_e(v)          a_begin(v),a_end(v)
#define print_v_i(v)    ( for_each(v.begin(),v.end(),[](int i){cout<<i<<" ";} ) )
#define PRINT_ID_V_I ( print_v_i( id_v_i )  )


int main()
{

        deque<int> id_d;
        int i = 0;
 id_d.push_back( i++ );
 id_d.push_back( i++ );
 id_d.push_back( i++ );
 id_d.push_back( i );

 id_d.push_front( i-- );
 id_d.push_front( i--);
 id_d.push_front( i--);
 id_d.push_front( i--);
 #define TARGET_NUM 22
vector<int> i_v;
i_v.assign(id_d.cbegin(), id_d.cend() );

//print_v_i( i_v);
auto loc = find( i_v.cbegin(), i_v.cend(), 22 );

//cout << *loc << endl ;   // not define  ---> 6029349


 cout<< "- before pop out\n";
  for( auto & it : id_d ){
         cout << it << " " ;
 }
 cout << endl;


 auto e_f = id_d.front() ;
 auto e_b = id_d.back() ;
   cout<<"\n- id_d.pop_front(): "<<e_f<<endl;
   id_d.pop_front();
   cout<<"- id_d.pop_back(): "<<e_b<<endl;
   id_d.pop_back();

 cout<< "\n- after pop out\n";
 for( auto & it : id_d ){
         cout << it << " " ;
 }
 cout << endl;
   return 0;
}



EOF




C++


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




multi-thread_example_cpp

jdtangjdtang・
4 个月前2017 年 2月 9 日星期四上午 10 点 16 分


// this_thread::yield example
#include <iostream>       // std::cout
#include <thread>         // std::thread, std::this_thread::yield
#include <atomic>         // std::atomic

std::atomic<bool> ready (false);

void count1m(int id) {
  while (!ready) {             // wait until main() sets ready...
    std::this_thread::yield();
  }
  for (volatile int i=0; i<1000000; ++i) {}
  std::cout << id;
}

int main ()
{
  std::thread threads[10];
  std::cout << "race of 10 threads that count to 1 million:\n";
  for (int i=0; i<10; ++i) threads[i]=std::thread(count1m,i);
  ready = true;               // go!
  for (auto& th : threads) th.join();
  std::cout << '\n';

  return 0;
}



original: http://www.cplusplus.com/reference/thread/this_thread/yield/...



C / C++


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




get_a_fun_address_in_mem_and_run_it_dynamically

jdtangjdtang・
4 个月前2017 年 2月 8 日星期三下午 2 点 36 分


typedef int (*FUN)(void) ; 

int main()
{
	
	FUN pfun = (FUN)fun; 
	
	printf( "%p\n", (int)pfun ); 
	(pfun)(); 
	
	return 0; 
}




C（编程语言）


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




cpp_BFS_algorithm

jdtangjdtang・
4 个月前2017 年 2月 5 日星期日下午 1 点 08 分


*********************
BFS_cpp.cpp
*********************
//  g++ -std=c++11 test.cpp  &&  ./a.exe
// lambda , iostream , adapt
//  cl test.cpp  /EHsc  & test.exe

#include <iostream>
#include <vector>
#include <algorithm>
#include <iterator>
#include <string>
#include <queue>


using namespace std;
//typedef vector< int >         v_i;
#define elementsof(v)   (sizeof (v) / sizeof (v[0]))
#define a_begin(v)      (&v[0])
#define a_end(v)        (v + elementsof (v))
#define a_range(v)      v
#define b_e(v)          a_begin(v),a_end(v)
#define print_v_i(v)    ( for_each(v.begin(),v.end(),[](int i){cout<<i<<" ";} ) )
#define PRINT_ID_V_I ( print_v_i( id_v_i )  )

struct stru_hash {
        int key;
        int* value;
};
// ### sub list ###
int print_int_arr_by_addr(int *arr){
        printf("-- ");
        while( *arr != -1 ){
                printf("%d ", *arr);
                arr++;
        }
        printf("\n");
        return 0;
}

int* get_arr_by_key(const stru_hash *id_h, int len, int key){

        int i=0;
        for ( i = 0 ; i < len; i++){
                int key_get = id_h[i].key;
                if ( key_get == key ) break;
        }
        int* value =  id_h[i].value;

        //print_int_arr_by_addr( arr_ret );
        return value;
}


int print_hash(const stru_hash *id_h, int len){
        int i=0;
        for ( i = 0 ; i < len; i++){
                int key = id_h[i].key;
                int* value =  id_h[i].value;
                printf("- %d :\n\t", key );
                print_int_arr_by_addr(value);
        }
        return 0;
}


// ### end  sub ###


int main()
{
        #define LEN 6
        struct stru_hash id_hash[LEN];

        int a0[]={1,3,-1};
        int a1[]={2,5,3,-1};
        int a2[]={2,0,-1};
        int a3[]={4,3,0,-1};
        int a4[]={1,3,2,-1};
        int a5[]={4,2,0,-1};

        int* arr_value[] = { (int*)&a0, (int*)&a1, (int*)&a2, (int*)&a3,(int*)&a4,(int*)&a5 };

        int i =0;
        //LEN
        for ( i = 0 ; i < LEN; i++){
                id_hash[i].key = i;
                id_hash[i].value = arr_value[i];
        }

        print_hash(id_hash, LEN);


        int* arr_ret = get_arr_by_key(id_hash, LEN, 1) ;


        vector<int> v_i_to_visit ;
        vector<int> v_i_visited ;

        int e_first = 1;
        while ( 1 ) {
                int* get_arr_value = NULL;
                get_arr_value = get_arr_by_key(id_hash, LEN, e_first) ;
                v_i_visited.push_back(e_first);
                vector<int>::iterator vec_it;
                vector<int>::iterator vec_it_2;
                vector<int>::iterator vec_it_traverse;
                while ( *get_arr_value!= -1 ){
                        vec_it = find(v_i_to_visit.begin(), v_i_to_visit.end(), *get_arr_value );
                        vec_it_2 = find(v_i_visited.begin(), v_i_visited.end(), *get_arr_value );
                        bool already_in_to_v_or_visit_arr = (vec_it != v_i_to_visit.end() || vec_it_2 != v_i_visited.end() );
                        if ( !already_in_to_v_or_visit_arr ){
                                v_i_to_visit.push_back( *get_arr_value );
                        }
                        get_arr_value++;
                } // end while ()
                vec_it_traverse = v_i_to_visit.begin();

                print_v_i( v_i_to_visit ) ;
                printf("\n");
                if ( v_i_to_visit.size() == 0 ) {break;}
                e_first = ( int ) *vec_it_traverse;
                vec_it_traverse = v_i_to_visit.erase(vec_it_traverse);

        } // end while ( 1)

        print_v_i ( v_i_visited );
        return 0;
}




算法


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




breadth-first_BFS_algorithm_广度优先搜索

jdtangjdtang・
4 个月前2017 年 2月 4 日星期六上午 10 点 40 分


*********************
travel_tree_by_level.PL
*********************
#!perl
# run by : perl <this_scriptname>.PL  [2|3|4...] 
use Data::Dumper;
my @arr_raw_file = &input_raw_file();




chomp( @arr_raw_file ) ;


my %hash = &to_hash(\@arr_raw_file);

print Dumper( \%hash);


#my @arr_2 = &get_list(\%hash,'1');
#print @arr_2 ;


# do it
# first get one , read the list , and put it to visit array
# if the list not in visit array, then put it to to_visit array
# do until visit array len > 4
my $e_first = '2';
my $e_first = @ARGV[0] if @ARGV > 0 ;
my @visited = ();
my @to_visit = ();
my @hash_keys = keys %hash ;
my $len_hash = @hash_keys;

while ( 1 ){
        my @to_visit_not_filter = &get_list(\%hash,$e_first);
        push @visited , $e_first;
        my @to_visit_new = &filter_visited(\@visited, \@to_visit, \@to_visit_not_filter);
        push @to_visit, @to_visit_new ;
        print "- e: $e_first\n\t- to visit : @to_visit\n";
        last if @to_visit == 0;
        $e_first = shift @to_visit;
        print "\n";
}

print  "\n- visit order: @visited\n";


### sub list ###
sub to_hash(\@){
my ($a_) = (@_[0]);
my @arr_raw_file = @$a_;
my $i ;
my $j ;

my %hash = ();

for ($i=0;$i<@arr_raw_file;$i++){
        chomp(@arr_raw_file[$i] );
        if ( @arr_raw_file[$i] !~ m/\s+\d/ ){


                my $title = @arr_raw_file[$i];

                #print "- \$title is R0 $title\n";
                print "- \$title: $title\n";

                my $start = $i;
                my $j = 0;
                my $idx = 0 ;
                for($j=$start+1; $j<@arr_raw_file; $j++){

                        if ( @arr_raw_file[$j] !~ m/\s+\d/ ){ $i=$j-1; last;}
                        my $_arr_ele = @arr_raw_file[$j];
                        print "  - \$_arr_ele: $_arr_ele\n";
                        $_arr_ele =~ s/\s//g;

                        $hash{$title}[$idx++] = $_arr_ele ;
                } # end for $j
                print "\n";

        } # end if match ^\d

} # end for $i

return %hash;

}
sub filter_visited(){
        my ( $v_, $to_v_, $to_v_not_ ) = (@_[0],@_[1],@_[2]);
        my $i; my $j; my $k;
        my @visited = @$v_;
        my @to_visit_not_filter = @$to_v_not_;
        my @to_visit = @$to_v_;
        for ( $i=0;$i<@visited;$i++){
                for($j=0;$j<@to_visit_not_filter;$j++){

                        if ( @to_visit_not_filter[$j] eq @visited[$i]   ){
                                @to_visit_not_filter[$j] = -1;
                        }

                }

        }

        for ( $i=0;$i<@to_visit;$i++){
                for($j=0;$j<@to_visit_not_filter;$j++){
                        if ( @to_visit_not_filter[$j] eq @to_visit[$i]   ){
                                @to_visit_not_filter[$j] = -1;
                        }
                }
        }



        my @to_visit_new = ();
        map{
          if ( $_ != -1 ){
                  push @to_visit_new , $_;
          }
        }@to_visit_not_filter ;

        return @to_visit_new;
}

sub get_list(\%hash,$e){
        my ($h_, $e) = (@_[0],@_[1]);
        my $a_ = $$h_{$e};
        return @$a_;
}


sub input_raw_file(){
my $raw_content = <<EOF ;
1
 2
 5
 3
0
 1
 3
2
 2
 0
5
 4
 2
 0
3
 4
 3
 0
4
 1
 3
 2
EOF
;
my @arr = split m/\n/, $raw_content;
@arr = grep ! m/^$/, @arr;
return @arr;

}

EOF




算法与数据结构


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




perl_spider_to_get_FT_chinese_news

jdtangjdtang・
5 个月前2017 年 1月 24 日星期二晚上 10 点 12 分


*********************
walk_spider.PL
*********************
#!perl
my @global_web_addr = ();

my @each_walk_wed_addr = ();
my $initial_web_addr = '/story/001071139';

my $error_string = walk_one( $initial_web_addr );

print $error_string , "\n";

# print @global_web_addr;

sub walk_one(){
# my $filename = '/story/001071139';
        my ($filename) = (@_[0]);
        #sleep 2;

        push @global_web_addr , $filename;
        my $len = @global_web_addr ;

        my $web_addr = 'http://www.ftchinese.com' .$filename;
        my @arr_filecontent = `curl -G $web_addr`;

        print "@arr_filecontent";
        open my $FP , ">", $len .'.html';
        print $FP "@arr_filecontent";
        close $FP;


        @arr_filecontent = grep m/href\=\"/ && m/\<li /, @arr_filecontent;
        @arr_filecontent = grep m/\/story\//, @arr_filecontent;
        @arr_filecontent = grep !m/return /, @arr_filecontent;

        map{
        chomp;
        s/.*href\=\"(.*?)\".*$/\1/ ;
        }@arr_filecontent;

        #@each_walk_wed_addr = @arr_filecontent;

        #print @each_walk_wed_addr ;

        map{
        if ( ( !(&smart_match(\@global_web_addr , $_)) )  && ( @global_web_addr < 111 ) ) {
                walk_one($_);
        }
        else {
                print "- too much\n";
                # print "@global_web_addr";
                die "- no need anymore";
        }
        }@arr_filecontent;

        return "- not enough web sites\n";

}


sub smart_match(\@ $){
        my ($a_, $s) = (@_[0], @_[1]);
        for my $t (@$_ ){
                if ($t eq $s ){
                        return 1;
                }
                return 0;
        }

}

EOF



*********************
html2txt.PL
*********************
#!perl

use strict ; 
use Data::Dumper; 

    use HTML::FormatText;


map{
    my $string = HTML::FormatText->format_file(
        @ENV{t}."/". "$_".'.html',
        leftmargin => 0, rightmargin => 50
        );

print $string if $string =~ m/FT/m; 

}(0..111);

EOF




perl6

网页爬虫


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




perl_parse_html_to_plain_text

jdtangjdtang・
5 个月前2017 年 1月 24 日星期二晚上 8 点 42 分


#!perl

use strict ; 
use Data::Dumper; 

    use HTML::FormatText;
    my $string = HTML::FormatText->format_file(
        'bd.html',
        leftmargin => 0, rightmargin => 50
        );

print $string; 




Perl 模块


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




a_c_callback_call_frm_again

jdtangjdtang・
5 个月前2017 年 1月 24 日星期二下午 3 点 52 分


#include <ctime>
#include <iostream>
#include <string>
#include <boost/bind.hpp>
#include <boost/shared_ptr.hpp>
#include <boost/enable_shared_from_this.hpp>
#include <boost/asio.hpp>

using namespace std;
using boost::shared_ptr;
typedef int (*cb)(int& p0) ;

int fun( cb id_cb, int& p0){
        id_cb( p0 );

        return 0;
}

int cb_example( int& p0 ){
        cout << p0++ << " ";

        if ( p0 <10 ){
                fun( cb_example , p0 );
        }

        return 0;
}





int main(){

        int i = 0 ;
        fun( cb_example,  i );

        return 0;}




回调函数（Callback）


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




boost_asio_asyn_tcp_socket

jdtangjdtang・
5 个月前2017 年 1月 24 日星期二下午 2 点 02 分


GCC 5.2
g++ -I`pwd` -L`pwd`/stage/lib  -lboost_system test_client.cpp   -o client.exe
g++ -I`pwd` -L`pwd`/stage/lib  -lboost_system test_server.cpp   -o server.exe


# to run 
server.exe 
client.exe localhost 



*********************
bld.sh
*********************
export LD_LIBRARY_PATH=`pwd`/stage/lib:$LD_LIBRARY_PATH
g++ -I`pwd` -L`pwd`/stage/lib  -lboost_system test.cpp  && a.out



*********************
test_client.cpp
*********************
//
// client.cpp
// ~~~~~~~~~~
//
// Copyright (c) 2003-2016 Christopher M. Kohlhoff (chris at kohlhoff dot com)
//
// Distributed under the Boost Software License, Version 1.0. (See accompanying
// file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)
//

#include <iostream>
#include <boost/array.hpp>
#include <boost/asio.hpp>

using boost::asio::ip::tcp;

int main(int argc, char* argv[])
{
  try
  {
    if (argc != 2)
    {
      std::cerr << "Usage: client <host>" << std::endl;
      return 1;
    }

    boost::asio::io_service io_service;

    tcp::resolver resolver(io_service);
    tcp::resolver::query query(argv[1], "22222");
    tcp::resolver::iterator endpoint_iterator = resolver.resolve(query);

    tcp::socket socket(io_service);
    boost::asio::connect(socket, endpoint_iterator);

    for (;;)
    {
      boost::array<char, 128> buf;
      boost::system::error_code error;

      size_t len = socket.read_some(boost::asio::buffer(buf), error);

      if (error == boost::asio::error::eof)
        break; // Connection closed cleanly by peer.
      else if (error)
        throw boost::system::system_error(error); // Some other error.

      std::cout.write(buf.data(), len);
    }
  }
  catch (std::exception& e)
  {
    std::cerr << e.what() << std::endl;
  }

  return 0;
}



*********************
test_server.cpp
*********************
//
// server.cpp
// ~~~~~~~~~~
//
// Copyright (c) 2003-2016 Christopher M. Kohlhoff (chris at kohlhoff dot com)
//
// Distributed under the Boost Software License, Version 1.0. (See accompanying
// file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)
//

#include <ctime>
#include <iostream>
#include <string>
#include <boost/bind.hpp>
#include <boost/shared_ptr.hpp>
#include <boost/enable_shared_from_this.hpp>
#include <boost/asio.hpp>

using boost::asio::ip::tcp;

std::string make_daytime_string()
{
  using namespace std; // For time_t, time and ctime;
  time_t now = time(0);
  return ctime(&now);
}

class tcp_connection
  : public boost::enable_shared_from_this<tcp_connection>
{
public:
  typedef boost::shared_ptr<tcp_connection> pointer;

  static pointer create(boost::asio::io_service& io_service)
  {
    return pointer(new tcp_connection(io_service));
  }

  tcp::socket& socket()
  {
    return socket_;
  }

  void start()
  {
    message_ = make_daytime_string();

    boost::asio::async_write(socket_, boost::asio::buffer(message_),
        boost::bind(&tcp_connection::handle_write, shared_from_this(),
          boost::asio::placeholders::error,
          boost::asio::placeholders::bytes_transferred));
  }

private:
  tcp_connection(boost::asio::io_service& io_service)
    : socket_(io_service)
  {
  }

  void handle_write(const boost::system::error_code& /*error*/,
      size_t /*bytes_transferred*/)
  {
  }

  tcp::socket socket_;
  std::string message_;
};

class tcp_server
{
public:
  tcp_server(boost::asio::io_service& io_service)
    : acceptor_(io_service, tcp::endpoint(tcp::v4(),22222))
  {
    start_accept();
  }

private:
  void start_accept()
  {
    tcp_connection::pointer new_connection =
      tcp_connection::create(acceptor_.get_io_service());

    acceptor_.async_accept(new_connection->socket(),
        boost::bind(&tcp_server::handle_accept, this, new_connection,
          boost::asio::placeholders::error));
  }

  void handle_accept(tcp_connection::pointer new_connection,
      const boost::system::error_code& error)
  {
    if (!error)
    {
      new_connection->start();
    }

    start_accept();
  }

  tcp::acceptor acceptor_;
};

int main()
{
  try
  {
    boost::asio::io_service io_service;
    tcp_server server(io_service);
    io_service.run();
  }
  catch (std::exception& e)
  {
    std::cerr << e.what() << std::endl;
  }

  return 0;
}


EOF




C++11

Boost（C++库）


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




perl6_try_new_things

jdtangjdtang・
5 个月前2017 年 1月 24 日星期二上午 9 点 52 分


install and compile perl6 on Linux Redhat 


# wget http://rakudo.org/downloads/star/rakudo-star-2016.11.tar.gz...


tar xfz rakudo-star-2016.11.tar.gz

cd rakudo-star-2016.11

perl Configure.pl --gen-moar --prefix /slowfs/slow025/arc_test/jd/tmp/perl6_201611

make install


# after installation, in bin/perl6, can use:

source envset.env 

it is contents:

# envset.env #

export PATH=/slowfs/slow025/arc_test/jd/tmp/perl6_201611/bin:/slowfs/slow025/arc_test/jd/tmp/perl6_201611/share/perl6/site/bin:$PATH



# test.pl6 # 

#!perl

if @*ARGS {

say @*ARGS[0] ;# get cml args 

}

my $len = @*ARGS;

say $len;

say %*ENV<tmp>;

my @arr = @*ARGS;

@arr.unique.sort.say;     # kernel code 



# run it with:

> perl6 test.pl6 1 3 5 2 0 3 2


# output is:

1
[1 3 5 2 0 3 2]
/slowfs/slow025/arc_test/jd/tmp
(0 1 2 3 5)



perl6


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




simple_cpp_c++11_for_each_lambda

jdtangjdtang・
5 个月前2017 年 1月 22 日星期日上午 11 点 26 分


// g++ -std=c++11 test.cpp && ./a.exe 

// usage :

// input: 3 4 5 8 7 6 \0 , then Enter

// lambda , iostream , adapt


#include <iostream>

#include <vector>

#include <algorithm>

#include <iterator>

using namespace std; 


int main(){

//cout<< 1 <<endl; 

typedef vector< int > v_i; 

typedef istream_iterator< int > it_is_i; 

typedef ostream_iterator< int > it_os_i; 

typedef back_insert_iterator< v_i > it_bk_insert; 


cout << "- please input numbers:\n"; 

v_i id_v_i; 


copy( it_is_i(cin), it_is_i() , it_bk_insert(id_v_i) ); 

sort( id_v_i.begin(), id_v_i.end() ); 

int sz = id_v_i.size(); 

for_each( id_v_i.begin(), id_v_i.end(), [sz](int i){cout <<"total number is:"<<sz<<"\n"<<i<<endl;} ); 

//copy( id_v_i.begin(), id_v_i.end(), it_os_i(cout, "\n") ); 

return 0; 

}



C++11


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




simple_cpp_c++11_for_each_lambda

jdtangjdtang・
5 个月前2017 年 1月 22 日星期日上午 11 点 26 分


// g++ -std=c++11 test.cpp && ./a.exe 

// usage :

// input: 3 4 5 8 7 6 \0 , then Enter

// lambda , iostream , adapt


#include <iostream>

#include <vector>

#include <algorithm>

#include <iterator>

using namespace std; 


int main(){

//cout<< 1 <<endl; 

typedef vector< int > v_i; 

typedef istream_iterator< int > it_is_i; 

typedef ostream_iterator< int > it_os_i; 

typedef back_insert_iterator< v_i > it_bk_insert; 


cout << "- please input numbers:\n"; 

v_i id_v_i; 


copy( it_is_i(cin), it_is_i() , it_bk_insert(id_v_i) ); 

sort( id_v_i.begin(), id_v_i.end() ); 

int sz = id_v_i.size(); 

for_each( id_v_i.begin(), id_v_i.end(), [sz](int i){cout <<"total number is:"<<sz<<"\n"<<i<<endl;} ); 

//copy( id_v_i.begin(), id_v_i.end(), it_os_i(cout, "\n") ); 

return 0; 

}



C++11


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




perl_sort_important

jdtangjdtang・
5 个月前2017 年 1月 20 日星期五晚上 10 点 32 分


*********************

test_sort.pl

*********************

#!perl

use strict ; 

my @arr = ();

map{

@arr[5-$_] = $_;

}(0..5);

print "@arr", "\n"; 

&sort_n(\@arr);


print join "\n", @arr;


sub sort_n (){

my ($a_) = (@_[0]);


for(my $i=0;$i<@$a_-1;$i++){

for(my $j=0;$j<@$a_-1-$i;$j++){

my $r0=@$a_[$j];

my $r1=@$a_[$j+1];

if ($r0>$r1){

(@$_[$j],@$_[$j+1]) = (@$_[$j+1],@_[$j]); 

}

} # end for j


} #end for i

@_[0] = $a_ ; 　　　#　very important line 

}



Perl


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




build_perl_script

jdtangjdtang・
5 个月前2017 年 1月 20 日星期五上午 11 点 13 分


*********************

bld_perl.sh

*********************

#wget http://www.cpan.org/src/5.0/perl-5.20.1.tar.gz
rm -rf perl-5.20.1
tar -xzf perl-5.20.1.tar.gz
cd perl-5.20.1
./Configure -des -Dprefix=/slowfs/us01dwt2p448/linqi/t/perl_bin_5.20.1_20170307 -Dusethreads -Duseshrplib

make
make test
make install





EOF



after build, see:

------

tree -L 2

.

├── bin

│ ├── a2p

│ ├── perl

│ └── perl5.20.1

├── lib

│ ├── 5.20.1

│ └── site_perl

└── man

├── man1

└── man3



7 directories, 3 files

for the lib:

/xx/arc_test/JD/tmp/localperl/lib

├── 5.20.1

│ ├── AnyDBM_File.pm

│ ├── App

│ ├── Archive

│ ├── Attribute

│ ├── autodie

│ ├── autodie.pm

│ ├── AutoLoader.pm

│ ├── AutoSplit.pm

│ ├── autouse.pm

│ ├── B

│ ├── base.pm

│ ├── Benchmark.pm

│ ├── bigint.pm

│ ├── bignum.pm

│ ├── bigrat.pm

│ ├── blib.pm

│ ├── bytes_heavy.pl

│ ├── bytes.pm

│ ├── Carp

│ ├── Carp.pm

│ ├── CGI

│ ├── CGI.pm

│ ├── _charnames.pm

│ ├── charnames.pm

│ ├── Class

│ ├── Compress

│ ├── Config

│ ├── constant.pm

│ ├── CORE.pod

│ ├── CPAN

│ ├── CPAN.pm

│ ├── DBM_Filter

│ ├── DBM_Filter.pm

│ ├── DB.pm

│ ├── deprecate.pm

│ ├── Devel

│ ├── diagnostics.pm

│ ├── Digest

│ ├── Digest.pm

│ ├── DirHandle.pm

│ ├── Dumpvalue.pm

│ ├── dumpvar.pl

│ ├── Encode

│ ├── encoding

│ ├── English.pm

│ ├── Env.pm

│ ├── experimental.pm

│ ├── Exporter

│ ├── Exporter.pm

│ ├── ExtUtils

│ ├── Fatal.pm

│ ├── feature.pm

│ ├── fields.pm

│ ├── File

│ ├── FileCache.pm

│ ├── FileHandle.pm

│ ├── filetest.pm

│ ├── Filter

│ ├── FindBin.pm

│ ├── Getopt

│ ├── HTTP

│ ├── I18N

│ ├── if.pm

│ ├── inc

│ ├── integer.pm

│ ├── IO

│ ├── IPC

│ ├── JSON

│ ├── less.pm

│ ├── Locale

│ ├── locale.pm

│ ├── Math

│ ├── Memoize

│ ├── Memoize.pm

│ ├── Module

│ ├── Net

│ ├── NEXT.pm

│ ├── open.pm

│ ├── overload

│ ├── overloading.pm

│ ├── overload.pm

│ ├── Package

│ ├── Params

│ ├── parent.pm

│ ├── Parse

│ ├── Perl

│ ├── perl5db.pl

│ ├── perlfaq.pm

│ ├── PerlIO

│ ├── PerlIO.pm

│ ├── pod

│ ├── Pod

│ ├── Safe.pm

│ ├── Search

│ ├── SelectSaver.pm

│ ├── SelfLoader.pm

│ ├── sigtrap.pm

│ ├── sort.pm

│ ├── strict.pm

│ ├── subs.pm

│ ├── Symbol.pm

│ ├── TAP

│ ├── Term

│ ├── Test

│ ├── Test.pm

│ ├── Text

│ ├── Thread

│ ├── Thread.pm

│ ├── Tie

│ ├── Time

│ ├── Unicode

│ ├── unicore

│ ├── UNIVERSAL.pm

│ ├── User

│ ├── utf8_heavy.pl

│ ├── utf8.pm

│ ├── vars.pm

│ ├── version

│ ├── version.pm

│ ├── version.pod

│ ├── vmsish.pm

│ ├── warnings

│ ├── warnings.pm

│ ├── x86_64-linux

│ └── XSLoader.pm

└── site_perl

└── 5.20.1



57 directories, 71 files



Perl


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




perlembed_how_to_use

jdtangjdtang・
5 个月前2017 年 1月 19 日星期四下午 5 点 39 分


*********************

interp.c.bld

*********************

cc -o interp interp.c `perl -MExtUtils::Embed -e ccopts -e ldopts`

sometimes , we cannot find the -lperl, so find it :

cd / && find_by_name 'libperl.so*' 2>/dev/null , then set LD_LIBRARY_PATH of the libperl.so or ln -s libperl.so.xxxx libperl.so


*********************

interp.c

*********************

#include <EXTERN.h> /* from the Perl distribution */

#include <perl.h> /* from the Perl distribution */

static PerlInterpreter *my_perl; /*** The Perl interpreter ***/

int main(int argc, char **argv, char **env)

{

PERL_SYS_INIT3(&argc,&argv,&env);

my_perl = perl_alloc();

perl_construct(my_perl);

PL_exit_flags |= PERL_EXIT_DESTRUCT_END;

perl_parse(my_perl, NULL, argc, argv, (char **)NULL);

perl_run(my_perl);

perl_destruct(my_perl);

perl_free(my_perl);

PERL_SYS_TERM();

}



//---------------------New interp.c that conduct perl in C ------------

// --- but cannot use c99?



#include <EXTERN.h>
 #include <perl.h>
 static PerlInterpreter *my_perl;
 int main (int argc, char **argv, char **env)
 {
     char *embedding[] = { "", "-e", "0" };
     PERL_SYS_INIT3(&argc,&argv,&env);
     my_perl = perl_alloc();
     perl_construct( my_perl );
     perl_parse(my_perl, NULL, 3, embedding, NULL);
     PL_exit_flags |= PERL_EXIT_DESTRUCT_END;
     perl_run(my_perl);
     /** Treat $a as an integer **/
     eval_pv("$a = 3; $a **= 2", TRUE);
     printf("a = %d\n", SvIV(get_sv("a", 0)));
     /** Treat $a as a float **/
     eval_pv("$a = 3.14; $a **= 2", TRUE);
     printf("a = %f\n", SvNV(get_sv("a", 0)));
     /** Treat $a as a string **/
     eval_pv(
       "$a = 'rekcaH lreP rehtonA tsuJ'; $a = reverse($a);", TRUE);
     printf("a = %s\n", SvPV_nolen(get_sv("a", 0)));
     perl_destruct(my_perl);
     perl_free(my_perl);
     PERL_SYS_TERM();

	 return 0; 
 }



EOF



Perl 编程


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




what_is_the_usual_so_for

jdtangjdtang・
5 个月前2017 年 1月 19 日星期四上午 11 点 01 分


25 open("/etc/ld.so.cache", O_RDONLY) = 3 

- /etc/ld.so.cache 包含了在/etc/ld.so.conf中指定的目录中查找到所有连接库。按顺序存储。



26 open("/lib64/libnsl.so.1", O_RDONLY) = 3

- network sever lib , like find hostname , IP address 


32 open("/lib64/libdl.so.2", O_RDONLY) = 3

- one of glibc lib, dynamic interface 


38 open("/lib64/libm.so.6", O_RDONLY) = 3

- math lib 


44 open("/lib64/libcrypt.so.1", O_RDONLY) = 3

- encrypt code lib 

50 open("/lib64/libutil.so.1", O_RDONLY) = 3

- utils 


56 open("/lib64/libc.so.6", O_RDONLY) = 3

- libc 


59 open("/usr/lib/libfreebl3.so", O_RDONLY) = 3

62 open("/lib64/libfreebl3.so", O_RDONLY) = 3


- redhat special lib , use for network filter and security


63 open("/usr/lib/locale/locale-archive", O_RDONLY) = 3


- text and language encode file 


64 open("/dev/urandom", O_RDONLY) = 3

- unblock random , vs. /dev/random , used to gen block-random, slower than urandom 


65 open("test.PL", O_RDONLY) = 3

- a perl script I used 

66 open("roman.txt", O_RDONLY) = 3

- a perl arg file, I used in this example



Linux 开发


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




A question to Thoughtworks :ans

jdtangjdtang・
5 个月前2017 年 1月 18 日星期三晚上 11 点 07 分


*********************

cal_roman_number.pl

*********************

#!/usr/bin/perl 


#

# copyright C by Jidor Tang<tlqtangok@synopsys.com>

# written at 2017-1-18

#



### main() ### 

&main();



sub main(){


my $DEBUG = 0; 

if ( $DEBUG || @ENV{DEBUG} ){

&usage_example(); 

exit 0; 

}


my %hash_global_pish_is_X = (); # save { pish -> X } 

my %hash_global_Silver_is_Num = (); # save {Silver -> 17 Credits }



my $filename = ""; 

@ARGV>0? $filename=@ARGV[0] : $filename='roman.txt'; 

open my $FP , "<",$filename ; 

my @arr_data = <$FP>; 

close $FP ; 


&parse_file_lines_and_cal_roman_number_to_console(\@arr_data);


}




### sub list ###

# 0 1 2 3 4 5 6

# I V X L C D M 

# 1 5 10 50 100 500 1000 


sub usage_example(){

my $roman_r0 = 'MCMXLIV';


# \\ get M+M if error, return "error_somethingxxx";

my $m = &valid_roman_num_and_return_add_sub_expr($roman_r0);


# get "100+1000-10 " 

my $expr = &repl_roman_with_true_num($m); 


my $cal_num = &eval_add_sub( $expr ); 


print qq{######################### A UNITTEST EXAMPLES #########################\n};

printf qq{%-33s\t%-5s%-22s\n}, qq{- original roman text}, qq{:},qq{ $roman_r0}; 

#print qq{- original roman text:\t$roman_r0\n}; 

printf qq{%-33s\t%-5s%-22s\n}, qq{- after changing to "+" "-"}, qq{:}, qq{ $m}; 

#print qq{- after changing to "+" "-":\t$m\n};

printf qq{%-33s\t%-5s%-22s\n},qq{- after changing to num express}, qq{:},qq{ $expr};

#print qq{- after changing to num express:\t$expr\n};

printf qq{%-33s\t%-5s%-22s\n},qq{- after eval to a num}, qq{:},qq{ $cal_num};

#print qq{- after eval to a num:\t$cal_num\n};

print qq{#######################################################################\n\n}; 


# print $cal_num, "\n"; 

}


sub eval_add_sub(){

my ($expr) = (@_[0]); 

return eval ( $expr ); 

}





sub parse_file_lines_and_cal_roman_number_to_console(\@arr){

# parse txt file content 

# first get %hash_global_pish_is_X 

# then get unit map to a num 

# then parse each question to number + unit 

my ($a_ ) = (@_[0]); 

my @arr = @$a_;


my $i = 0; 

while ( 1 ) {

chomp ( @arr[$i++] ); 

if ( @arr[$i] =~ m/ is [IVXLCDM]$/ ) {

next; 

}

else { last ;}

}


my $end_define_statement_loc = $i; 


#print $end_define_statement_loc, "---\n"; 

my %hash_name_to_roman = (); 

map{

my @t = split m/ /,@arr[$_]; 

@hash_name_to_roman{@t[0]} = @t[2]; 

}(0..$end_define_statement_loc-1); 


# set to global hash 

%hash_global_pish_is_X = %hash_name_to_roman; 



# return %hash_name_to_roman; 


# train measurement unit 

my %hash_unit_map = (); 

my $question_start = $end_define_statement_loc ; 

for ( $i= $end_define_statement_loc; $i<@arr; $i++){

chomp ( @arr[$i] ); 

if ( @arr[$i] =~ m/\d Credits$/ ){


map{ @arr[$i] =~ s/$_/@hash_name_to_roman{$_}/g; }(keys %hash_name_to_roman); 

# print @arr[$i] , "___\n"; 

my @t = split m/ /,@arr[$i]; 

my @t_cp = ( @t ); 

map{@t_cp[$_] = '';}(-4..-1);


my @pure_roman = (@t_cp) ; 

my $str_roman = join '', @pure_roman ; 

my $str_with_add_sub_roman = &valid_roman_num_and_return_add_sub_expr ( $str_roman ); 

if ( $str_with_add_sub_roman =~ m/error / ) {

die "- the trainning data is wrong , please check\n"; 

}


my $str_r_n_to_eval = &repl_roman_with_true_num( $str_with_add_sub_roman ); 

my $eval_num = &eval_add_sub( $str_r_n_to_eval ); 

@hash_unit_map{ @t[-4] } = eval "@t[-2]/$eval_num" ; 

next ; 

}


else {

# it is question ; 

$question_start = $i ; 

last ; 

}



} # end get unit 


# already get unit measurement 

# print %hash_unit_map ; 

%hash_global_Silver_is_Num = %hash_unit_map; 






# print @arr[$question_start], "----\n"; 

for ( $i = $question_start; $i<@arr; $i++){

$_ = @arr[$i];

chomp;

my $unit_num = 1; # save if has unit name or not , will be a number + Credits 

if ( m/much is / ){

$unit_num = 1; 

my $cal_str_roman = ""; 

my @t = split m/much is /;

$cal_str_roman = @t[1]; $cal_str_roman =~ s/\?//; 


my $question_out = $cal_str_roman ; # $question_out = "glob prok"


@t = split m/ /,$cal_str_roman; 

$cal_str_roman = join '', @t ; 



map{ $cal_str_roman =~ s/$_/@hash_global_pish_is_X{$_}/g; }(keys %hash_global_pish_is_X); 



my $str_roman = $cal_str_roman; # see "XMC" or something now 



my $str_with_add_sub_roman = &valid_roman_num_and_return_add_sub_expr ( $str_roman ); # see "X+M-C"

if ($str_with_add_sub_roman =~ m/error_/ ){

print "- $str_with_add_sub_roman in calc rules \n"; 

next ; 

}

my $str_r_n_to_eval = &repl_roman_with_true_num( $str_with_add_sub_roman ); # get "100+100-1"

my $eval_num = &eval_add_sub( $str_r_n_to_eval ); 

print "$question_out". "is $eval_num\n"; 


}

elsif( m/many Credits/ ){

# $unit_num ++ ; 


my $cal_str_roman = ""; 

my @t = split m/many Credits is /;

$cal_str_roman = @t[1]; $cal_str_roman =~ s/\?//; 


my $question_out_and_unit = $cal_str_roman ; # $question_out = "glob prok"


@t = split m/ /,$cal_str_roman; 

my $unit_name = @t[-1]; 


$cal_str_roman = join '', @t[0..@t-2] ; 



map{ $cal_str_roman =~ s/$_/@hash_global_pish_is_X{$_}/g; }(keys %hash_global_pish_is_X); 

# print $cal_str_roman ,"\n"; 



my $str_roman = $cal_str_roman; # see "XMC" or something now 



my $str_with_add_sub_roman = &valid_roman_num_and_return_add_sub_expr ( $str_roman ); # see "X+M-C"

if ($str_with_add_sub_roman =~ m/error_/ ){

print "- $str_with_add_sub_roman in calc rules \n"; 

next ; 

}

my $str_r_n_to_eval = &repl_roman_with_true_num( $str_with_add_sub_roman ); # get "100+100-1"

my $eval_num = &eval_add_sub( $str_r_n_to_eval ); 

# map unit name to num 

# $unit_name

my $unit_multi_value = @hash_global_Silver_is_Num{$unit_name} ; 

my $eval_num_multi_unit_value = $eval_num * $unit_multi_value ; 



print "$question_out_and_unit". "is $eval_num_multi_unit_value Credits\n"; 


} # else m/many Credits is /


else {

print "I have no idea what you are talking about\n"; 

}


my @arr = split m/ / ; 


} # end deal with question 






}




sub repl_roman_with_true_num(){

my ($m) = (@_[0]); 

my @arr = split m//,$m; 

my %hash = &def_hash_g_2_n();

map{$_ = @hash{$_} if m/[^\+\-]/;}@arr;

$m = join '', @arr;


return $m; 

}

sub valid_roman_num_and_return_add_sub_expr(){

my ($str_rom_) = (@_[0]); 

#my @arr_rom_ = @$addr_; 


#my $str_rom_ = join '',@arr_rom_; 


my $ret_code_verfy_3_dup_ = &verify_3_dup_($str_rom_);

if ( $ret_code_verfy_3_dup_ !~ m/ret_code_OK_verify_3_dup_/ ){

return "error_$ret_code_verfy_3_dup_ \n" ; 

}

my $n_m = &base_on_rule_repl_with_sub($str_rom_); 

if ( $n_m =~ 'error_' ){

return "error_$n_m \n"; 

}


return $n_m; 

# print $n_m; 



}


sub base_on_rule_repl_with_sub(){


my ($m) = (@_[0]); 

my @arr_m = split //, $m; 

my $len= @arr_m; 


#print @arr_m; 

for (my $i=0;$i< $len-1;$i++){


my $g_0 = @arr_m[$i+0] ;

my $g_1 = @arr_m[$i+1] ; 


if( &comp_2_ele($g_0, $g_1) ){ #big or eq 0

@arr_m[$i] = @arr_m[$i]."+"; 

next; 

}

else {

(@arr_m[$i], @arr_m[$i+1]) = (@arr_m[$i+1],@arr_m[$i]);

@arr_m[$i] = @arr_m[$i]."-"; 


if ( $i != ($len-2) ){@arr_m[$i+1] = @arr_m[$i+1]."+" ;}

$i++; 

}


} # end for ($i); 


$m = join '', @arr_m; 


# judge if pre and next is right :RULES 

# ? "I" can be subtracted from "V" and "X" only. 

my $error_see_not_V_X_sub_I = 'error_see_not_V_X_sub_I'; 

$_ = $m ; 

if ( m/[^VX]\-I/ ) {

return $error_see_not_V_X_sub_I; 

}

# "X" can be subtracted from "L" and "C" only. 

my $error_see_not_L_C_sub_X = 'error_see_not_L_C_sub_X'; 

$_ = $m ; 

if ( m/[^LC]\-X/ ) {

return $error_see_not_V_X_sub_I; 

}

# "C" can be subtracted from "D" and "M" only. 

# "V", "L", and "D" can never be subtracted.

my $error_see_sub_L_V_D = 'error_see_sub_L_V_D'; 

if ( m/\-[LVD]/ ) {

return $error_see_sub_L_V_D; 

}


return $m; 




} # end try_get_2_add_paren

sub verify_3_dup_(){

my ($m) = (@_[0]); 

my $err_DLV = "error dup DLV"; 

my $err_IXCM_dup_gt_4 = "error_IXCM_dup_gt_4"; 

my $err_IXCM_dup_3_but_4_gt = "error_IXCM_4_gt_dup"; 

my $err_ret_code_OK = "ret_code_OK_verify_3_dup_"; 

# D L V can never be repeated 

$_ = $m ; 

if ( m/([DLV])\1/ ){

return $err_DLV; 

}


# I X C M can be repeated three times in succession, but no more. 

$_ = $m; 

if ( m/([IXCM])\1\1.*\1.*\1/p ){

return $err_IXCM_dup_gt_4; 

}


# they appear 4 times if 3rd and 4th are sperator by smaller value , like XXXIX, 

if ( m/([IXCM])\1\1.\1/p ){

my $m = ${^MATCH}; 

my $idx=0; 


$idx = 0;

my $g_0 = &get_1_ele_from_dup_match($m, $idx ); 


$idx = 3;

my $g_1 = &get_1_ele_from_dup_match($m, $idx ); 

if ( &comp_2_ele( $g_0, $g_1 ) < 0 ){

return $err_IXCM_dup_3_but_4_gt; 

}

}


return $err_ret_code_OK; 


}


sub def_hash_g_2_n(){

my %hash = qw( 

I 1 V 5 X 10 L 50 C 100 D 500 M 1000 

);

return %hash; 

}

sub get_1_ele_from_dup_match(){

my ($m, $n) = (@_[0],@_[1]);

my @arr_m = split m//, $m; 

return ( @arr_m[$n] ); 

}


sub comp_2_ele(){

my ($g_0, $g_1) = (@_[0], @_[1]); 

my %h = def_hash_g_2_n(); 

my $ret_num = 0; 


# print (@h{$g_0}, @h{$g_1}); 

if (@h{$g_0} >= @h{$g_1}) { $ret_num = 1; }; 

return $ret_num; 

}





*********************

issue_to_solve.txt

*********************

[3;2~Problem Three: Merchant's Guide to the Galaxy

You decided to give up on earth after the latest financial collapse left 99.99% of the earth's population with 0.01% of the wealth. Luckily, with the scant sum of money that is left in your account, you are able to afford to rent a spaceship, leave earth, and fly all over the galaxy to sell common metals and dirt (which apparently is worth a lot).

Buying and selling over the galaxy requires you to convert numbers and units, and you decided to write a program to help you.

The numbers used for intergalactic transactions follows similar convention to the roman numerals and you have painstakingly collected the appropriate translation between them.

Roman numerals are based on seven symbols:

Symbol Value

I 1

V 5

X 10

L 50

C 100

D 500

M 1,000

Numbers are formed by combining symbols together and adding the values. For example, MMVI is 1000 + 1000 + 5 + 1 = 2006. Generally, symbols are placed in order of value, starting with the largest values. When smaller values precede larger values, the smaller values are subtracted from the larger values, and the result is added to the total. For example MCMXLIV = 1000 + (1000 ? 100) + (50 ? 10) + (5 ? 1) = 1944.

? The symbols "I", "X", "C", and "M" can be repeated three times in succession, but no more. (They may appear four times if the third and fourth are separated by a smaller value, such as XXXIX.) "D", "L", and "V" can never be repeated.

? "I" can be subtracted from "V" and "X" only. "X" can be subtracted from "L" and "C" only. "C" can be subtracted from "D" and "M" only. "V", "L", and "D" can never be subtracted.

? Only one small-value symbol may be subtracted from any large-value symbol.

? A number written in [16]Arabic numerals can be broken into digits. For example, 1903 is composed of 1, 9, 0, and 3. To write the Roman numeral, each of the non-zero digits should be treated separately. Inthe above example, 1,000 = M, 900 = CM, and 3 = III. Therefore, 1903 = MCMIII.

(Source: Wikipedia ( [17]Roman numerals - Wikipedia)

Input to your program consists of lines of text detailing your notes on the conversion between intergalactic units and roman numerals.

You are expected to handle invalid queries appropriately.

Test input:

glob is I

prok is V

pish is X

tegj is L

glob glob Silver is 34 Credits

glob prok Gold is 57800 Credits

pish pish Iron is 3910 Credits

how much is pish tegj glob glob ?

how many Credits is glob prok Silver ?

how many Credits is glob prok Gold ?

how many Credits is glob prok Iron ?

how much wood could a woodchuck chuck if a woodchuck could chuck wood ?

Test Output:

pish tegj glob glob is 42

glob prok Silver is 68 Credits

glob prok Gold is 57800 Credits

glob prok Iron is 782 Credits

I have no idea what you are talking about



*********************

readme.txt

*********************

# readme #

#

# copyright C by Jidor Tang<tlqtangok@synopsys.com>

# written at 2017-1-18

#


# dependencies #

- perl version >= 5.14

- Windows >= NT 



# how to build #

- no need to build , use perl's JIT 


# how to run #

perl cal_roman_number.pl roman.txt 


# how to see debug and unittest results #

export DEBUG=1

perl cal_roman_number.pl roman.txt 


# run and debug log #


--- log start ---


$cd jd_home_work


$ perl cal_roman_number.pl roman.txt

pish tegj glob glob is 42

glob prok Silver is 68 Credits

glob prok Gold is 57800 Credits

glob prok Iron is 782 Credits

I have no idea what you are talking about



------


$ export DEBUG=1 && perl cal_roman_number.pl roman.txt

######################### A UNITTEST EXAMPLES #########################

- original roman text : MCMXLIV

- after changing to "+" "-" : M+M-C+L-X+V-I

- after changing to num express : 1000+1000-100+50-10+5-1

- after eval to a num : 1944

#######################################################################



--- log end ---

*********************

roman.txt

*********************

glob is I

prok is V

pish is X

tegj is L

glob glob Silver is 34 Credits

glob prok Gold is 57800 Credits

pish pish Iron is 3910 Credits

how much is pish tegj glob glob ?

how many Credits is glob prok Silver ?

how many Credits is glob prok Gold ?

how many Credits is glob prok Iron ?

how much wood could a woodchuck chuck if a woodchuck could chuck wood ?


EOF



代码


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     











?

?写文章
?




斗鱼武汉面试经历2017-1-14

jdtangjdtang・
5 个月前2017 年 1月 18 日星期三晚上 10 点 41 分

当天，安排下午14：00的面试，由于住在穷乡僻壤，只能12：00+开始出发，301一趟，好不容易没有迟到，到了光谷软件园F3.
斗鱼只是传闻得风也来火也去的，其实嘛，名不副其实。在16楼，一进走廊，就觉得有点怪压抑的，可能是光线问题。

在大门处等着，希望有人经过时能给开门，但想想，谁会给一个陌生人开门？于是就满邮件搜索面试联系人员的电话，谁知道TM HR根本没有给电话。

HR在等了几分钟后，终于来了。被领进了后闻到一股淡淡的甲醛气味。真是烦闷，对之印象大打折扣。和我同时进去的还有一个深圳回来的小伙子，看起来深圳不太好混，问了一下，他是面试运维，与我不一样，我是面试开发。不相干，那个哥们很有趣，当着面试官和HR的面，直接劈头盖脸地问，武汉这边给多少钱？深圳给这么多钱活不下去啊！ 云云，真为那个小伙情商着急。

一会儿被带到一个密闭的充满毒气的会议室里等面试。面试官来，我当然客气地打个小笑脸，呵呵。“您好”。 然后就是走流程，“自我介绍”－》“项目经历”－》“为什么离职”。当然为什么离职说得很勉强，我也不知道为什么离职，就是做得不爽，想离。但我不是这么答的，我只是说“我想换个方向”。我的优势在于此。然后讨论各种技术问题，什么大数据，什么图像算法，什么机器学习， 都是怎么高端怎么讨论，当然这些都没什么卵用罗。我还是对于他们做得事情感觉略低端，比方说，他们会用爬虫去监控友方网站的舆情，然后设法干预，这些没有什么大意义，还有什么自动鉴黄，都是别人做得老掉牙的旧技术了。所以，感觉不是那么对品味了，于是就放松了，有什么说什么。

这一轮面了后，马上又有一轮面试，第二个技术面试官就不那么有趣了，属于没趣了，和他说话，不太投机，完全尴尬。只问了一些技术细节，SQL操作，我一答，他觉得不熟悉，其实只是“他觉得”。 我很快就不想理他了。匆匆结束了二面。

HR来了，聊了一下求职心事，套路嘛，还有什么目标城市，我说了，深圳，等企鹅。也许就是这个，让HR觉得不太稳定。

事后我当然是没有得到offer，当然这个也不一定是悲事，我本就无求，何来悲？我现在开始慢慢地喜欢上内核方面的东西，也许兴趣是可以引导的。 

－JD 于 2017.01.18 



程序员面试

武汉互联网


?0


?收藏


?分享
?编辑

?


2 条评论
?

jdtang






写下你的评论











卡西卡

卡西卡

没谈到薪资吗？


2 个月前2017 年 4月 24 日星期一晚上 11 点 28 分



jdtang

jdtang（作者）

没有 最后斗鱼拒了我


1 个月前2017 年 5月 2 日星期二晚上 11 点 13 分
     











?

?写文章
?




华为面试录2016-11-27　20:23

jdtangjdtang・
7 个月前2016 年 11月 27 日星期日晚上 8 点 23 分


---2016-11-2５---

华为面试录

头一天晚上，发给某君wh小师妹的qq消息终于有回复了，说是内部还有招聘，而且是紧急招聘，让我不用改简历，直接发过去给内推，发过去大概半小时后，收到HR（maybe)方面的来电，具体内容类似于调查户口，现在在哪，做的什么方面，聊几句就聊到了技术，HR多次把我拉回来，说“下次叫技术人员面试你”。

于是约了个面试时间，坑就坑在约的时间，由于没有查看agenda,约了个第二天早上９:30的，结果挂下电话，过了几个小时，想起来第二天上午１０：３０有一个会议，自己主讲。此时已经晚上很晚了，取消是不可能了，只好掐着点面试了。

第二天早早地去了公司一趟，万事俱备，只等９：３０.　９:15，约了wh,带了个路，送到大厅，等华为面试官的面试验证码。约十分钟后，下来了，给了一个临时的牌子，就可以临时上华为办公区了。

电梯有四个，但依然抵挡不住早上的滚滚洪峰，一阵好等。面试官很面善，会不时地说几句打趣的话，年龄的话，大概四十五岁上下。一会儿进了电梯，上到十楼，至办公区，我知道办公区是租的，看起来比较拥挤，新的办公大楼正在紧锣密鼓地建。上去后，我被安排到了一间会议室，面试官（feng)转身出去了，回来时手里拿了一份我的简历。

面试不像一个同事说的那样，扯扯谈，是实打实地真枪实弹地问各种技术问题，我提到了我经常使用的一个工具，居然被要求说这个工具是怎么做的？工作原理？它是商业软件，说实话，我也不是很清楚，就答的不是很好。其它的，他问了问开源代码读得多不多，平常喜欢看什么书，很多平常经常读的书一时想不起书名，也没有答好。中途，面试官接了一个短电话，我也趁机看了一下手机时间，快一个小时了，我还要赶回去开会。心急如焚啊，也无奈，好在这个时候面试也快结束，面试官抛出一个问题，“你平常写过多少行代码？”，我一听，愣了会，说实话，这个我没有数过，就说大概两万行吧，最后面试官问我，想问一下他们什么问题，我就问，如果这些（android自动化框架)能工作，为什么要经常加班？他说他们的产品迭代很快。这好理解，像互联网一样呗。还问了他几个小问题，华为看重社招生什么能力等等。

然后这个时候已经１０：25了，赶回公司至少要三分钟。这个时候，只好说，“不好意思，还要赶回去开个会”，感觉不太礼貌，也是没有办法罗。匆忙结束奔回。

总体感觉面试官比较注重的并非社招生的学习能力，而是架构能力和全局观，这两点上，都答得不太好。感觉这次面试大概率要挂了。


JD（马甲）　于　2016-11-27　20:22　武汉



面试经历

华为终端


?0


?收藏


?分享
?编辑

?


还没有评论
?

jdtang






写下你的评论










     









     















     















     







 




日志


返回日志列表 





npm_publish_js_code    2016-12-2 15:02 阅读(4)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

已经是第一篇 | 下一篇：junit_setenv_and... 

 




	

 

# How to publish your code to npm #

1. run $ npm init

2. make sure your code has at least those 4 files:

 ``` index.js  LICENSE  package.json  README.md

   and in the package.json, add github's address

3. npm adduser -> need one's A: and P: 

4. npm publish

5. if edit again,must edit package.json's version number, then do STEP#4



  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

已经是第一篇 下一篇：junit_setenv_and... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  




主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:17





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)





















 




日志


返回日志列表 





junit_setenv_and_run_via_cml    2016-11-29 23:20 阅读(1)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：nodejs_exports_a... 

 





开通黄钻


junit_setenv_and_run_via_cml
 


 

-----------------------------------
Junit examples , right click to see all the possible junit items 
export JAVA_HOME=/global/freeware/Linux/2.X/jdk1.8.0_65
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH

/remote/us01home41/linqi/workspace_003_junit/test_0/src/test_0

*********************
/remote/us01home41/linqi/java_setenv_1.8.0_65.env
*********************
export JAVA_HOME=/global/freeware/Linux/2.X/jdk1.8.0_65
export PATH=${JAVA_HOME}/bin:$PATH
export JUNIT_HOME=/slowfs/us01dwslow025/arc_test/linqi/tmp/eclipse
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib:${JUNIT_HOME}/junit-4.10.jar  # download from :https://github.com/downloads/junit-team/junit/junit-4.10.jar

*********************
src_0.java
*********************
package test_0;

public class src_0 {

        public int a = 9;
        public int b = 8;

        src_0(int a, int b) {
                this.a = a;
                this.b = b;
        }

        public int add_it() {

                int c = (a + b);
                a = b = c;
                return c;
        }

        public int sub_it() {
                int c = (a - b);
                a = b = c;
                return c;
        }

        public static void main(String[] args) {
                // TODO Auto-generated method stub
                System.out.println("hello world\n");

        }

}

*********************
src_0Test.java
*********************
package test_0;

import static org.junit.Assert.*;
import org.junit.Before;
import org.junit.Test;

public class src_0Test {

        src_0 id_src_0 = new src_0 ( 0, 0);
        int x =99;
        int y = 880 ;
        @Before
        public void setUp() throws Exception {

        id_src_0 = new src_0 (x,y);

        }

        @Test
        public void testAdd_it() {
                assertEquals(x+y, id_src_0.add_it());

                //fail("Not yet implemented");
        }

        @Test
        public void testSub_it() {
                assertEquals(x+y, id_src_0.sub_it());
                //fail("Not yet implemented");
        }

}

*********************
test.java
*********************

public class test {

public static void main(String[] args ){


}

};


*********************
test_runner.java
*********************
package test_0;

import org.junit.runner.JUnitCore;
import org.junit.runner.Result;
import org.junit.runner.notification.Failure;

import java.lang.reflect.Field;
import java.lang.reflect.Method;
//import java.lang.reflect.Modifier;  //Modifier.STATIC 

public class test_runner {
 public static void main(String[] args) {
  Result result = JUnitCore.runClasses(src_0Test.class);

  Class<src_0> id_class_src_0 = src_0.class;

  Field[] id_field = id_class_src_0.getDeclaredFields();
  Method[] id_method = id_class_src_0.getDeclaredMethods(); 
  
  System.out.println("- print fields");
  for (Field id_f : id_field) {
   System.out.println(id_f.getModifiers() +" "+  id_f.getType()+ " "+ id_f.getName());
   
  }
  
  System.out.println("- print methods");
  for (Method id_m : id_method ) {
   System.out.println(id_m.getModifiers()+" "+id_m.getReturnType()+" "+ id_m.getName());
  }

  System.out.println("-------");
  for (Failure failure_item : result.getFailures()) {
   System.out.println(failure_item.toString());
  }

  System.out.println(result.wasSuccessful());
 }
}
EOF

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：nodejs_exports_a... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:18





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   


 




日志


返回日志列表 





nodejs_exports_alias_cb    2016-11-29 23:19 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：mongodb_envset_s... 

 





开通黄钻


nodejs_exports_alias_cb
 


 
-----------------------------------
Node.js module.exports 
*********************
exports.js
*********************

/*
exports.var0="var0_text"; 
exports.fun0= function( ){
console.log( "this is fun0---\n"); 
};


console.log ( module.exports); 
*/

var myapp = []; 

myapp.var0 = "msg"; 
myapp.fun0 = function(){console.log("yes");};

exports= module.exports = myapp; 


*********************
index.js
*********************
var myapp = require("./exports.js"); 
console.log( myapp ) ; 

myapp.fun0() ; 


EOF


*********************
test.js
*********************
var m = require('./m.js'); 
var print = console.log ; 

print ( m.msg ); 

m.display() ; 








*********************
m.js
*********************
exports = module.exports = m ={}; 
m.msg = "msg from m.js"; 
m.display = function(){
 console.log ( "this is m.display()"); 
}; 


EOF



  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：mongodb_envset_s... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:18





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





mongodb_envset_script_on_remote_machine    2016-11-29 23:18 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：perl_driver_for_... 

 





开通黄钻


mongodb_envset_script_on_remote_machine
 


 *********************
startup_mongo.sh
*********************
#!bash

pwd_=/slowfs/us01dwslow025/arc_test/linqi/tmp/mongodb-linux-x86_64-rhel62-3.2.11/bin

netstat -ano |grep 22222  | grep mongo > /dev/null 2>&1
if [ "$?" -ne "0" ]; then
#       ./mongod --config mongodb.conf  &
if [ -e db/mongod.log ] ; then
        cat db/mongod.log >> db/mongod_all.log
        rm db/mongod.log
fi

        mongod --dbpath db --logpath db/mongod.log --port 22222 &
        sleep 2s
        perl -e 'print "- create mongodb server...\n" ;'

fi




./mongo arcdev4:22222/test


# mongod --dbpath db --port 22222 --shutdown

*********************
.mongorc.js
*********************
//--- an example ---

ld_ok = function (){
        db = connect("localhost:22222/test");
        print ("- load OK: \$HOME/.mongorc.js" );
};




lsh = function ( ){
                db.c0.find({},{_id:0}).sort({_id:-1}).limit(7).forEach(printjson);
};

// main
ld_ok();
lsh();

EOF






  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：perl_driver_for_... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:18





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





perl_driver_for_mongodb    2016-11-24 11:26 阅读(1)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：nodejs_mongodb_c... 

 





开通黄钻


perl_driver_for_mongodb
 


*********************
test.PL
*********************
#!perl


use Data::Dumper; 

use MongoDB;
 
my $client     = MongoDB->connect('mongodb://localhost:27017');
my $collection = $client->ns('test.bar'); # database foo, collection bar


my @arr = (

[ "iphone5s",
 [ "5", "5s", "6", "6s","7" ], 
],

); 

my $result     = $collection->insert_many(\@arr );




EOF
 
  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：nodejs_mongodb_c... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:18





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





nodejs_mongodb_connect_find    2016-11-23 20:13 阅读(1)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：perl_web_server_... 

 





开通黄钻


nodejs_mongodb_connect_find
 


*********************
test.js
*********************
var MongoClient = require('mongodb').MongoClient; 
var assert = require( 'assert') ;


var url = 'mongodb://localhost:27017/test';
MongoClient.connect(url, function(err, db) {
 console.log("Connected correctly to server");
 insertDocuments(db,function(){

  findDocuments( db, function(){


   db.close();
  } ); 
 });
});


var insertDocuments = function(db, callback) {
 // Get the documents collection
 var collection = db.collection('documents');
 // Insert some documents
 collection.insertMany([
   {a : 1}, {a : 2}, {a : 3}
   ], function(err, result) {
    //    assert.equal(err, null);
    //    assert.equal(3, result.result.n);
    //    assert.equal(3, result.ops.length);
    console.log("Inserted 3 documents into the document collection");
    callback(result);
   });
}




var findDocuments = function(db, callback) {
 // Get the documents collection
 var collection = db.collection('documents');
 // Find some documents
 collection.find({}).toArray(function(err, docs) {
  console.log("Found the following records");
  console.dir(docs);
  callback(docs);
 });
}


 
  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：perl_web_server_... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:18





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





perl_web_server_socket    2016-10-10 15:23 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：samba_config 

 





开通黄钻


perl_web_server_socket
 



 $ cat perl_web.PL
#!/usr/bin/perl

#==============
# Date: 2012-11-03
# User: wcdj
#==============

use Socket;
use Carp;
use FileHandle;

# [1] use port 8080 by default, unless overridden on command line
$port = (@ARGV ? $ARGV[0] : 8080);

# [2] create local TCP socket and set it to listen for connections
$proto = getprotobyname('tcp');
socket(S, PF_INET, SOCK_STREAM, $proto) || die;
setsockopt(S, SOL_SOCKET, SO_REUSEADDR, pack("l", 1)) || die;
bind(S, sockaddr_in($port, INADDR_ANY)) || die;
listen(S, SOMAXCONN) || die;

# [3] print a startup message
printf("<<< perl_web_svr accepting on port %d >>>\n\n", $port);

while (1)
{
        # [4] wait for a connection C(Client)
        $cport_caddr = accept(C, S);
        ($cport, $caddr) = sockaddr_in($cport_caddr);
        C->autoflush(1);
        print C "Hello world from server $port\r\n" ; 
 

        # [5] print who the connection is from
        $cname = gethostbyaddr($caddr, AF_INET);
        printf("<<< request from [%s] >>>\n", $cname);

        # [6] read request msg until blank line, and print on screen
        while ($line = <C>)
        {
                print $line;
                if ($line =~ /^\r/) {last; }
        }

        # [7] prompt for response msg, and input response lines,
        #     sending response lines to client, until solitary "."
        printf("<<< type response followed by '.' >>>\n");

        while ($line = <STDIN>)
        {
                $line =~ s/\r//;
                $line =~ s/\n//;
                if ($line =~ /^\./) {last; }
                print C $line . "\r\n";
        }

        close(C);

}


# how to test this:
1. run the perl perl_web.PL 
2. open web browser, and type: localhost:8080/
3. in the web server , type the text content , like : <html> <body>YES</body> </html>
4. see the web page ,expect "YES" 


  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：samba_config 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52


node.js_first_program_trigger_cb2016-09-13 14:55




本文最近访客




















Jidor的头像
Jidor
09:18





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





samba_config    2016-10-6 09:17 阅读(1)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：raspberry_pi_sta... 

 





开通黄钻


samba_config
 


 

-  samba -




sudo samba         # start daemon

sudo vim /etc/samba/smb.conf          # in the tail add:

sudo smbpasswd -a pi        # must add an linux user 


[global]


     #force user = pi

     #force group = pi





[u_12g]

        comment = u_12_g_dis

        path = /home/pi/tmp

        public = yes

        browseable =7 yes

        read only = no

        writable = yes

        create mask = 0775

        force create mode = 0775





[u_12g]

        comment=u_12g

        path=/mnt/u_12g

        browseable=yes

        writable=yes

        public=yes
        force user = pi
        force group = pi
 

after config, use "testparam" to see if smb.config is set up 










  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：raspberry_pi_sta... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


expect_usage_example2016-08-15 11:52


node.js_first_program_trigger_cb2016-09-13 14:55




本文最近访客




















Jidor的头像
Jidor
09:18





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





raspberry_pi_startup    2016-9-28 11:50 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：ubuntu_16.04_ins... 

 





开通黄钻


raspberry_pi_startup
 


1.must use a fat32 sd card : sandisk recommended. 
    ●    I tried on a nameless sd-tf card, burn is successful, but at last , no boot .

2.connect usb mouse , keyboard and HDMI and cable, then power on, 
    ●    here you can see the lights above power light will blink ( green ) and then screen should scoll some text. very fast . a picture of berry will display.　if there are some data transferring, all light may blink.
    ●    then log in with A:pi, P:raspberry.

3.config that with : raspi-config. 
    ●    set up the keyboard to US style .
    ●    enable ssh
    ●    vim cannot used, use vi instead.
    ●    glad to see it has perl embeded.

 
  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：ubuntu_16.04_ins... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:18





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





ubuntu_16.04_install_source.list    2016-9-28 07:28 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：node_js_server_l... 

 





开通黄钻


ubuntu_16.04_install_source.list
 


 this morning, I open my old laptop, found my ubuntu is installed correctly. 
but I cannot use vim even ater I tring "sudo apt-get update" with 163 souce.list.

the problem turns out to be, the 16.04 /etc/apt/source.list is not the same with old source.list
so I updated to aliyun, then I found I installed my vim.

that is great! the first time I contact with aliyun. very fast. it is!


  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：node_js_server_l... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:19





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





node_js_server_listen_and_client_send_msg    2016-9-20 20:52 阅读(1)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：node.js_first_pr... 

 





开通黄钻


node_js_server_listen_and_client_send_msg
 


 *********************
js.js
*********************
var print=console.log;
var fs = require("fs");
var util = require ( "util" );
var events = require ( "events" );
var child_process = require ( 'child_process' );

const dgram = require('dgram');
const server = dgram.createSocket('udp4');
server.on('error', (err) => {
console.log(`server error:\n${err.stack}`);
server.close();
});
server.on('message', (msg, rinfo) => {
console.log(`server got: ${msg} from ${rinfo.address}:${rinfo.port}`);
});
server.on('listening', () => {
var address = server.address();
console.log(`server listening ${address.address}:${address.port}`);
});
server.bind(41234);
// server listening 0.0.0.0:41234
*********************
support.js
*********************
const dgram = require('dgram');
const message = Buffer.from('Some bytes');
const client = dgram.createSocket('udp4');
client.send(message, 41234, 'localhost', (err) => {
client.close();
});


EOF


  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：node.js_first_pr... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:19





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





node.js_first_program_trigger_cb    2016-9-13 14:55 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：perl_yaml_file 

 





开通黄钻


node.js_first_program_trigger_cb
 



 var print=console.log; 
var fs = require("fs");
var util = require ( "util" ); 
var events = require ( "events" ); 





//var data = fs.readFileSync('txt.txt');
//print (data[0].toString()); 


var em = new events.EventEmitter(); 


em.once(
 'tr_0', 
 function do_tr_0(p_0, p_1){
  print ( "do_tr_0()", p_0, p_1 ); 
  
 } 
); 

var p_0 ='p_00'; 
var p_1 ='p_11'; 
em.emit('tr_0', p_0, p_1); 

------
var print=console.log; 
var fs = require("fs");
var util = require ( "util" ); 
var events = require ( "events" ); 




var em = new events.EventEmitter();
var ev = 'ev'; 

em.once(ev, ()=> {
print ( ev ); 
}); 

em.emit(ev); 
























 















  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：perl_yaml_file 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:19





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





perl_yaml_file    2016-9-8 14:10 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：opencv_vs_setup 

 





开通黄钻


perl_yaml_file
 


 *********************
test.PL
*********************
use YAML;




my $yaml = Dump [ 1..4 ];


my %hash = (
        name => Tang,
        Children => [qw/big_child second_child third_child/],
        wife => 'wife name'
);

$yaml = Dump ( \%hash );

print $yaml, "\n";

my $hash_addr= Load $yaml;
print Dump ( $hash_addr);

my  $VAR1 = {
        'results' => [
                {
                        'last_update' => '2016-01-05T18:00:00+08:00',

                        'location' => {
                                'country' => 'CN',
                                'id' => 'WT3Q0FW9ZJ3Q',
                                'array' => [1,2,4],
                        }
                }
        ]
};


$yaml = Dump ( $VAR1 );

print $yaml, "\n";





EOF

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：opencv_vs_setup 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:19





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





opencv_vs_setup    2016-9-7 21:35 阅读(3)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：opencl_vs_cml 

 





开通黄钻


opencv_vs_setup
 



1. set the env var : OPENCV_DIR to XXX\...\x86\vc11 ( if vs2012) 
2. set include dir in CTRL+W, S project prop -> c/C++ -> generel,  "$(OPENCL_DIR)\..\..\include
3. set the link general for lib path 
4. set the link -> input -> additional lib  -> edit , input the lib from $(OPENCL_DIR)\lib , ls |grep d.lib 
5. set the $(OPENCL_DIR)\bin , prepend to path, so it can be run .
6. make sure the link opt is /machine:x86 

then use the C++ code following to build:

/////////////////////////////////////////////////////////////////////////
/// opencv_test.cpp : Defines the entry point for the console application.
//

#include "stdafx.h"
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <iostream>

using namespace cv;
using namespace std;


void fun_proc(Mat img){

 cout<<"img.rows:"<<img.rows<<endl;
 cout<<"img.cols:"<<img.cols<<endl;
 cout<<"img.dims:"<<img.dims<<endl; 
 cout<<"img.channel():"<<img.channels()<<endl; 







 for ( int i=0; i<img.rows/2; i++ ){
 

  for ( int j=0; j<img.cols/2; j++ ){
  

   for ( int k=0; k<img.channels(); k++ ){
    uchar& tmp =  img.row(i).data[j*img.channels()+ k]; 
    tmp=0; 

  

   }

  }

 }




} 





int main( int argc, char** argv )
{


 char *img_path = NULL; 
 char *img_path_r0= "C:\\jd_p\\sw\\pro\\opencv\\opencv\\build\\doc\\lena_rgba.png";   //lena.jpg
 if( argc != 2)
 {
  img_path = img_path_r0; 

 }
 else {
  img_path = argv[1]; 
 }

 Mat image;
 image = imread(img_path, -1); // Read the file, read , no change it 


 image; 
 if(! image.data ) // Check for invalid input
 {
  cout << "Could not open or find the image" << std::endl ;
  return -1;
 }

 namedWindow( "Display window", WINDOW_AUTOSIZE ); // Create a window for display.










 fun_proc( image ); 


 imshow( "Display window", image ); // Show our image inside it.

 waitKey(0); // Wait for a keystroke in the window
 return 0;
}







  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：opencl_vs_cml 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:19


jidorBa的头像
jidorBa
2016年9月





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





opencl_vs_cml    2016-9-6 22:45 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：expect_usage_exa... 

 





开通黄钻


opencl_vs_cml
 



create a win32 program. create file ocl.cpp .


this is in VS2012
C:\Users\linqi\Documents\Visual Studio 2012\Projects\opencl_test_demo_1706\opencl_test_demo_1706>type ocl.cpp
// opencl_test_demo_1706.cpp : Defines the entry point for the console application.
//

#include "stdafx.h"
#include "CL\cl.h"
#include "stdlib.h"

#include "stdio.h"
//#pragma comment(lib, "OpenCL.lib")


#define MEM_SIZE (128)
#define MAX_SOURCE_SIZE (0x100000)
int _tmain(int argc, _TCHAR* argv[])
{
        cl_device_id device_id = NULL;
    cl_context context = NULL;
    cl_command_queue command_queue = NULL;
    cl_mem memobj = NULL;
    cl_program program = NULL;
    cl_kernel kernel = NULL;
    cl_platform_id platform_id = NULL;
    cl_uint ret_num_devices;
    cl_uint ret_num_platforms;
    cl_int ret;


         char string[MEM_SIZE];


    /* Get Platform and Device Info */
    ret = clGetPlatformIDs(1, &platform_id, &ret_num_platforms);

        printf ("%d\n", ret_num_platforms);

    ret = clGetDeviceIDs(platform_id, CL_DEVICE_TYPE_GPU, 1, &device_id, &ret_num_devices);
  printf ("%d\n", ret_num_devices);





          /* Create OpenCL context */
    context = clCreateContext(NULL, 1, &device_id, NULL, NULL, &ret);
    return 0;

}

 




copy lib\x64\OpenCL.lib .\




C:\Users\linqi\Documents\Visual Studio 2012\Projects\opencl_test_demo_1706\opencl_test_demo_1706>cl   /I"C:\jd_p\sw\pro\
intel_opencl\OpenCL SDK\6.1\include"  /D "_CRT_SECURE_NO_WARNINGS"        /DYNAMICBASE "OpenCL.lib"        ocl.cpp  
Microsoft (R) C/C++ Optimizing Compiler Version 17.00.50727.1 for x64
Copyright (C) Microsoft Corporation.  All rights reserved.

ocl.cpp
Microsoft (R) Incremental Linker Version 11.00.50727.1
Copyright (C) Microsoft Corporation.  All rights reserved.

/out:ocl.exe
ocl.obj
OpenCL.lib
kernel32.lib
user32.lib
gdi32.lib
winspool.lib
comdlg32.lib
advapi32.lib
shell32.lib
ole32.lib
oleaut32.lib
uuid.lib
odbc32.lib
odbccp32.lib

C:\Users\linqi\Documents\Visual Studio 2012\Projects\opencl_test_demo_1706\opencl_test_demo_1706>
  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：expect_usage_exa... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:19





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





expect_usage_example    2016-8-15 11:52 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：perl_multi_threa... 

 





开通黄钻


expect_usage_example
 



*********************
test.PL
*********************
#!/usr/bin/perl

print "Perl program\n";
print "hello world\n";

print "num1:" ;
while(<>){
        $_=$_*$_;
        print "$_\n";
        last
}


print "num2:" ;
while(<>){
        $_=$_*$_;
        print "$_\n";
        last
}

*********************
expect.exp
*********************
#!/usr/bin/expect


spawn perl test.PL


set password 123456
set num1 [lindex $argv 0]
set num2 [lindex $argv 1]
expect "num1" { send "$num1\n" }
expect "num2" { send "$num2\n" }
expect "*password*" { send "$password\n" }
expect -re "\[(.*)]:" {dosth}
 


interact


#####################
set password JJ+t**k_0
#####################

set mname [lindex $argv 0]
if {"$mname" == ""} {set mname "arctest4"}

spawn -noecho ssh -X $mname




expect {
    -re "^.*password.*$" { send "$password\n" }
}

interact
 

EOF

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：perl_multi_threa... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


node.js_first_program_trigger_cb2016-09-13 14:55




本文最近访客




















Jidor的头像
Jidor
09:19





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





perl_multi_thread_create_thread    2016-8-2 20:47 阅读(1)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：wilddog_write_an... 

 





开通黄钻


perl_multi_thread_create_thread
 


*********************
perl_td.PL
*********************
#!/bin/perl

use strict;
use threads;
use Cwd;
use POSIX qw(strftime);

################################################################################
# 函数名:  count
# 函数描述:  数数
# 输入:   name 随意输入一个名字
# 输出:   无
# 调用:
# 被调用:
# 返回:
################################################################################

my $Thread_1="Thread_1";
my $Thread_2="Thread_2";
my $Thread_3="Thread_3";
my $Thread_4="Thread_4";
my $Thread_5="Thread_5";
my $Thread_6="Thread_6";
my $Thread_7="Thread_7";








sub count4
{
   my ($name) = @_;
   my $current_time = strftime "%Y-%m-%d %H:%M:%S", localtime;
   my $i;
   my $cnt=0;
   for ($i = 0; $i <= $cnt; $i++)
   {
         sleep 3;
     print "$current_time  $name $i\n";
   }
}

sub count3
{
   my ($name) = @_;
   my $current_time = strftime "%Y-%m-%d %H:%M:%S", localtime;
   my $i;
   my $cnt=0;
   for ($i = 0; $i <= $cnt; $i++)
   {
         sleep 3;
     print "$current_time  $name $i\n";
   }
}


sub count2
{
   my ($name) = @_;
   my $current_time = strftime "%Y-%m-%d %H:%M:%S", localtime;
   my $i;
   my $cnt=0;
   for ($i = 0; $i <= $cnt; $i++)
   {
         sleep 3;
     print "$current_time  $name $i\n";
   }
}
sub count1
{
   my ($name) = @_;
   my $current_time = strftime "%Y-%m-%d %H:%M:%S", localtime;
   my $i;
   my $cnt=0;
   for ($i = 0; $i <= $cnt; $i++)
   {
         sleep 3;
     print "$current_time  $name $i\n";
   }
}

#创建第一批线程
my $thread_1_01 = threads->create('count1', $Thread_1);
my $thread_1_02 = threads->create('count2', $Thread_2);

# 等待第一批线程结束完成
$thread_1_01->join();
$thread_1_02->join();


#创建第一批线程
my $thread_1_03 = threads->create('count3', $Thread_3);
my $thread_1_04 = threads->create('count4', $Thread_4);

# 等待第一批线程结束完成
$thread_1_03->join();
$thread_1_04->join();

=pod
# console out #
2016-08-02 20:52:58  Thread_2 0
2016-08-02 20:52:58  Thread_1 0
2016-08-02 20:53:02  Thread_3 0
2016-08-02 20:53:02  Thread_4 0
=cut


EOF

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：wilddog_write_an... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:19





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





wilddog_write_and_read_trigger_callback    2016-6-21 23:17 阅读(4)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：javascript_wildd... 

 





开通黄钻


wilddog_write_and_read_trigger_callback
 


 *********************
rules.json
*********************
{
  "rules": {
    ".read": true,
    ".write": true,

    "jd_demo_book": {
      ".indexOn" : "page"
      }
  }
}

*********************
w.html
*********************
<html>
<title>this is my title </title>
<script src="jquery.js" type="text/javascript"></script>
<script src = "https://cdn.wilddog.com/js/client/current/wilddog.js" ></script>
<script type="text/javascript">

function var_dump(obj) {
    var obj_members = "";
    var sep = "";
    for (var key in obj) {
        obj_members += sep + key + ":" + obj[key];
        sep = ", ";
    }
    return ("[" + obj_members + "]");
}


$(function(){
//$("input").toggle( function(){alert("0"); }, function(){alert("1");} );

var ref = new Wilddog("https://jdapp.wilddogio.com/jd_demo_book");

/*--------------------------------
// the first time, we need to run
var return_str_ref =ref.set({
        0:{name:"python0",page:1000,},
        1:{name:"java1",page:101,},
        2:{name:"c++2",page:12,},
        3:{name:"perl3",page:103,},
}); //end set
-----------------------------------*/
//var ref_stock = ref.child("stock");

ref.update({
  0: {name: "updated_python0",page:10},
});

/*
var ref_push = ref.push(
        {name:"东方航空", price:3333}
);
*/
//alert ( ref_push.name );

/*
ref.orderByChild("name").equalTo("CRZ").once("value", function(snapshot) {
  snapshot.forEach(function(data) {

    console.log("The " + data.key() + " ---> " + data.val().name );

  });
});
*/

/*
ref.child("600003").once ( "value", function(D){
alert(D.val().price);
} );
*/

alert( "write finished " + ref.toString()) ;


} );    //end document ()

</script>
<body>




</body>

</html>


*********************
r.html
*********************
<html>
<title>this is my title </title>
<script src="jquery.js" type="text/javascript"></script>
<script src = "https://cdn.wilddog.com/js/client/current/wilddog.js" ></script>
<script type="text/javascript">
$(function(){
//$("input").toggle( function(){alert("0"); }, function(){alert("1");} );

var ref = new Wilddog("https://jdapp.wilddogio.com/jd_demo_book");


/*
ref.update({
ref_push.key():
        {name, "东方航空_new", };
});
*/

// curl -X PUT -d '{"name":{"jidor":"tang_0"}}' 'https://jdapp.wilddogio.com/stock.json'

//value，child_added，child_changed，child_removed


// each time, the value changed , then callback function will be invoked.
ref.Child(0).on("child_changed", function(snapshot) {

  snapshot.forEach(function(data) {

    var id_text = ( data.key() + "\n:page ---> " + data.val().page  )+ ("\n:name ---> " + data.val().name);
        alert ( id_text ) ;
  });
});













} );    //end document ()

</script>
<body>

<input type="button" value="button">  </input>
<p id="new_id" > abc </p>


</body>

</html>


// curl -X PUT -d '{"name":{"jidor":"tang_0"}}' 'https://jdapp.wilddogio.com/stock.json'
// -X PATCH
 

//value，child_added，child_changed，child_removed





  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：javascript_wildd... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:19





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





javascript_wilddog_usage    2016-6-19 21:39 阅读(1)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：perl_walkdir 

 





开通黄钻


javascript_wilddog_usage
 


 *********************
write.html
*********************
<html>
<title>this is my title </title>
<script src="jquery.js" type="text/javascript"></script>
<script src = "https://cdn.wilddog.com/js/client/current/wilddog.js" ></script>
<script type="text/javascript">

function var_dump(obj) {
    var obj_members = "";
    var sep = "";
    for (var key in obj) {
        obj_members += sep + key + ":" + obj[key];
        sep = ", ";
    }
    return ("[" + obj_members + "]");
}


$(function(){
//$("input").toggle( function(){alert("0"); }, function(){alert("1");} );

var ref = new Wilddog("https://jdapp.wilddogio.com/stock");

ref.set({
        600004:
                {name:"SNPS",price:22},
        600001:
                {name:"CRZ",price:33,},
        600002:
                {name:"oriential_plant",price:0},
        600003:
                {name:"huawei",price:3},


}); //end set

//var ref_stock = ref.child("stock");

ref.update({
  600004:
                {name: "Synopsys",price :111}
});

var ref_push = ref.push(
        {name:"东方航空", price:3333}
);

//alert ( ref_push.name );

ref.orderByChild("name").equalTo("CRZ").once("value", function(snapshot) {
  snapshot.forEach(function(data) {

    console.log("The " + data.key() + " ---> " + data.val().name );

  });
});


ref.child("600003").once ( "value", function(D){
alert(D.val().price);
} );


} );    //end document ()

</script>
<body>




</body>

</html>


EOF


https://jdapp.wilddogio.com/
wilddog A: tlq~~at126com P: yg+ 371~~~7 



  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：perl_walkdir 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:19





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





perl_walkdir    2016-6-17 07:52 阅读(2)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：perl_chinese_dec... 

 





开通黄钻


perl_walkdir
 


 *********************
test_.PL
*********************
#!perl use strict ;
use data::dumper;
use findbin qw($bin);
my $perl_p = @ENV{perl_p};
#print &get_sub($perl_p);
&walkdir($perl_p);
sub walkdir($root){
        my ($root) = ( @_[0] );
        if ( -d $root){
                my @roots = &get_sub($root);

                my $i = 0;
                for ( $i=0 ; $i< @roots; $i++){
                        my $root = @roots[$i];
                        walkdir($root);
                }
        }
        else {
                print "$root\n";
        }
}
sub get_sub($root){
        my ($root) = ( @_[0] );
        my @arr = ();
        if ( -d $root){
                @arr = `ls $root`;
                map{
                chomp;
                $_ = $root.get_SP().$_;
                }@arr;
        }
        return @arr;
}
sub get_SP(){
# get file path separator
        use File::Spec::Functions;
        my $SP = catfile('XX', 'XX');
        $SP =~ s/XX//g;    # on Linux will get "/", but Windows, will get "\";
        return $SP;
}

EOF

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：perl_chinese_dec... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:20


jd_jidor@qq.com_jidor_的头像
jd_jidor@qq.com_jidor_
2016年6月





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





perl_chinese_decode_utf8    2016-6-7 23:29 阅读(1)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：perl_sort_by_use... 

 





开通黄钻


perl_chinese_decode_utf8
 



 #!/usr/bin/perl
use strict;
#use warnings;
use utf8;
use Encode; 
use UTF8; 
 binmode( STDIN,  ':encoding(utf8)' );
 binmode( STDOUT, ':encoding(utf8)' );   
 binmode( STDERR, ':encoding(utf8)' );    


open my $FP, "<", "log.txt";     # file content: 
=pod
600579 ST黄海
600580 卧龙电气
=cut
my @arr = <$FP>; 
close $FP; 


# only if from the utf-8 files :{
#my $str = $arr[-1];
#  $str = decode_utf8( $str);  # very import line , if from files , else don't need 
#}

my $str_out = ""; 

my $str = @arr[-1]; 
$str = decode_utf8( $str );
print $str ;  
$str =~ s/6\d{5} //g; 
$str_out = $str; 




open my $FP_ , ">" , "txt.txt"; 
print $FP_ $str_out; 
close $FP_; 




*********************
test.PL
*********************
#!/usr/bin/perl
use strict;
#use warnings;
use utf8;
use Encode;
use UTF8;
 binmode( STDIN,  ':encoding(utf8)' );
 binmode( STDOUT, ':encoding(utf8)' );
 binmode( STDERR, ':encoding(utf8)' );


open my $FP, "<", "log.txt";
my @arr = <$FP>;
close $FP;





my $str_out = "";

my $str = @arr[-1];
$str = decode_utf8( $str );
#print $str ;
#$str =~ s/6\d{5}       //g;
my @arr_ = split //,$str;

#print "@arr_";
map{
if (m/[^\u4E00-\u9FFF]/ || m/\d/){ # got all the number and char and Chinese , Japan , South Korea symbols
if ( ! m/\d/){
if (! m/[a-zA-Z]/){
print ;         # get only Chinese Symbols
}

}

        };
}@arr_;


EOF




  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：perl_sort_by_use... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:20





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





perl_sort_by_user_define_function    2016-5-25 16:11 阅读(2)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：perl_oop_example 

 





开通黄钻


perl_sort_by_user_define_function
 


*********************
x.txt
*********************
2 4
4 6
5 1
8 3
4 1
6 5
8 1
2 2

*********************
ts.PL
*********************
#!perl
use Data::Dumper;

my @arr_txt = `cat x.txt`;


print sort sort_by_id_num @arr_txt;





### sub list ###


sub sort_by_id_num{
        - &get_f1($a) <=> - &get_f1($b)
        or
          &get_f2($a) <=>   &get_f2($b);
}


sub get_f1($str){
        my ($str ) = (@_[0]);
        chomp ( $str );
        $str =~ s/ .*$//;
        return $str;
}

sub get_f2($str){
        my ($str ) = (@_[0]);
        chomp ( $str );
        $str =~ s/^.* //;
        return $str;
}


sub get_id_list(){
        my ($arr_ ) = (@_[0]);


        my %hash_ret = ();
        for my $_line_ (@$arr_){
#print '$_line_:', $_line_;
                my @arr_id = split m/ /, $_line_;
#print @arr_id;
                @hash_ret{ @arr_id[2] }++;
        }
        return keys %hash_ret;

}

*********************
ans.txt
*********************
8 1
8 3
6 5
5 1
4 1
4 6
2 2
2 4

EOF



  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：perl_oop_example 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:20





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





perl_oop_example    2016-5-14 22:45 阅读(1)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：php_read_mysql_d... 

 





开通黄钻


perl_oop_example
 



 *********************
TTT.PL
*********************
#!perl
use TTT;
use Data::Dumper;
&main();

# sub
sub main{
my $ref = TTT->new();
print Dumper($ref);

}
*********************
TTT.pm
*********************
#!perl
package TTT;
use TT;
use Data::Dumper;

use vars qw(@ISA);

@ISA = qw(TT);
print Dumper(\@ISA);

sub new {
my $class = shift ;
my $ref = TT->new("avv", "bvv") ;
$ref -> {newadd} = "newadd_value";
return bless $ref, $class;
}

return 1;

*********************
TT.pm
*********************
#!perl
package TT;
use Data::Dumper;

### sub list ###
sub new{
my $this = shift ;


return bless {a=> shift, b=>shift}, $this;
}

sub set(){
my $this = shift ;
$this -> {a} = shift ;
$this -> {b} = shift ;
}
sub get(){
my $this = shift ;
my $a = $this -> {a} ;
my $b = $this -> {b} ;
print Dumper($a, $b);
}

return 1;










  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：php_read_mysql_d... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:20





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





php_read_mysql_database_select    2016-5-7 15:55 阅读(2)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：jquery_toggle_le... 

 





开通黄钻


php_read_mysql_database_select
 


 <?php
$server_name="localhost:3306"; //数据库服务器名称 
$username="zjwdb_528253"; // 连接数据库用户名 zjwdb_528253@localhost
$password="Zjw352938047"; // 连接数据库密码 
$mysql_database="zjwdb_528253"; // 数据库的名字 
// 连接到数据库 


//error_reporting(E_ALL);
//header("Content-type: text/xml");
//header("Cache-Control: no-cache");




$conn=mysql_connect($server_name, $username, $password); 
if (!$conn)
  {
  die('Could not connect: ' . mysql_error());
  }

// 一些代码...
echo "<text>connect db ok</text><br/>"; 

//mysql_close($conn);

echo "<text>connect return code: $conn</text><br/>"; 

//mysql_query("set names utf8");
// 从表中提取信息的sql语句 
//SELECT *  FROM  `messages` 
echo "<text> start get record from $mysql_database </text><br/>"; 

mysql_select_db($mysql_database, $conn);
  $result = mysql_query("SELECT * FROM messages");
  while($row = mysql_fetch_array($result))
  {
  echo $row['id'] . " " . $row['msg'];
  echo "<br />";
  }
  
  
mysql_free_result($result); 
// 关闭连接 
mysql_close($conn);  


// http://ftp528253.host559.zhujiwu.me/demo9-chat/backend.php

?> 
  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：jquery_toggle_le... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:20





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





jquery_toggle_learning    2016-4-30 23:55 阅读(1)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：perl_sqlite3_ 

 





开通黄钻


jquery_toggle_learning
 



 <html>
<title>this is my title </title>
<script src="jquery.js" type="text/javascript"></script>
<script type="text/javascript">
$(function(){
$("input").toggle( function(){alert("0"); }, function(){alert("1");} ); 

} ); 

</script>
<body>

<input type="button" value="button">  </input>
<p id="new_id" > abc </p>


</body>

</html>



----------------------------------------------------------------------------------------------------------------
$(function(){


$("input").toggle(    function(){alert("0"); },         function(){alert("1");}    ); 


} ); 
   






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：perl_sqlite3_ 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:20





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





perl_sqlite3_    2016-1-13 09:46 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：perl_Dumper_JSON... 

 





开通黄钻


perl_sqlite3_
 



 #perl
use strict; 
use DBI; 
#also need m DBD::SQLite
my $dbh=DBI->connect("dbi:SQLite:dbname=test.db","","",{RaiseError=>1,AutoCommit=>0});

#print $dbh; #HASH

my $sql="create table ip (id int null, name int null)";
#$dbh->do( $sql); #table already existed 
 

 


$sql = "insert into ip values( 1, 2 )";
$dbh->do( $sql );
if ( $dbh->err() ) {
 die "$DBI::errstr\n";
}
$dbh->commit();

$sql = " select * from ip;  ";
my $dbconn = $dbh->prepare($sql);
$dbconn->execute();
while ( my @row_arr = $dbconn->fetchrow_array ){
print "@row_arr\n"; 

}
$dbh->disconnect();

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：perl_Dumper_JSON... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:20





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





perl_Dumper_JSON_Curl_utf8    2016-1-6 09:44 阅读(2)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：structure{x:4} 

 





开通黄钻


perl_Dumper_JSON_Curl_utf8
 


 #perl
use strict; 
use feature qw(say); 
use WWW::Curl::Easy; 
use JSON; 
use Data::Dumper;
#use utf8;
#binmode(STDIN, ':encoding(utf8)');
#binmode(STDOUT, ':encoding(utf8)');
#binmode(STDERR, ':encoding(utf8)');

 

 

my $curl = WWW::Curl::Easy->new;

$curl->setopt(CURLOPT_HEADER,0);
$curl->setopt(CURLOPT_URL, 'https://api.thinkpage.cn/v3/weather/daily.json?key=O4GJVKNC67&location=wuhan&language=zh-Hans&unit=c&start=0&days=5');

# A filehandle, reference to a scalar or reference to a typeglob can be used here.
my $response_body;
$curl->setopt(CURLOPT_WRITEDATA,\$response_body);

# Starts the actual request
my $retcode = $curl->perform;
if ($retcode == 0) {
 print("Transfer went ok\n");
 my $response_code = $curl->getinfo(CURLINFO_HTTP_CODE);
 # judge result and next action based on $response_code
 print("Received response: $response_body\n");


} else {
 # Error code, type of error, error message
 print("An error happened: $retcode ".$curl->strerror($retcode)." ".$curl->errbuf."\n");
}

my $from_jason_to_perl_hash=decode_json($response_body); 
print Dumper($from_jason_to_perl_hash); 

print 'my decode ele----------------------'."\n";
print 'date from jSON',"\n"; 

print $from_jason_to_perl_hash->{results}->[0]->{location}->{name}; 
say; 

#print  %$from_jason_to_perl_hash{results}; 
#
#
#
my %hash_t_0=(); 
@hash_t_0{'a'}="A";
my %hash_inside=("k0","v0","k1","v1"); 

@hash_t_0{'b'}=[1,2,3,"1234"]; 

print Dumper(\%hash_t_0); 

print @hash_t_0{b}->[3]; 

 

print "\n".'my decode ele----------------------'."\n";

 

 

my $from_perl_hash_to_json=encode_json $from_jason_to_perl_hash; 
print $from_perl_hash_to_json; 

my %hash=(1,2,"ab","AB");
my @arr_from_hash=%hash; 
print Dumper(@arr_from_hash); 

my $encode_str=encode_json \%hash; 
print $encode_str; #{"ab":"AB","1":2}
my $decode_str=decode_json $encode_str; 

#print %$decode_str if $decode_str =~ m/HASH/; 
print Dumper($decode_str); # need print  

=pod
my str=q(
{"results":[{"location":{"name":"武汉","id":"WT3Q0FW9ZJ3Q","path":"武汉,武汉,湖北,中国","timezone_offset":"+08:00","timezone":"Asia/Shanghai","country":"CN"},"daily":[{"code_day":"9","wind_direction":"","high":"8","wind_direction_degree":"0","precip":"","wind_speed":"0","text_night":"多云","low":"4","wind_scale":"0","code_night":"4","text_day":"阴","date":"2016-01-05"},{"high":"10","precip":"10","wind_direction_degree":"","wind_direction":"","code_day":"4","date":"2016-01-06","code_night":"4","text_day":"多云","wind_scale":"3","low":"2","wind_speed":"12.87","text_night":"多云"},{"high":"7","precip":"20","wind_direction_degree":"","code_day":"13","wind_direction":"","code_night":"4","text_day":"小雨","date":"2016-01-07","wind_speed":"14.48","text_night":"多云","wind_scale":"3","low":"0"},{"wind_direction_degree":"","precip":"0","high":"9","wind_direction":"","code_day":"4","date":"2016-01-08","text_day":"多云","code_night":"4","wind_scale":"1","low":"1","text_night":"多云","wind_speed":"4.83"},{"wind_direction_degree":"","precip":"0","high":"9","wind_direction":"","code_day":"4","date":"2016-01-09","text_day":"多云","code_night":"13","low":"3","wind_scale":"2","text_night":"小雨","wind_speed":"11.27"}],"last_update":"2016-01-05T18:00:00+08:00"}]}  
); 
=cut

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：structure{x:4} 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:20





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   
 




日志


返回日志列表 





structure{x:4}    2015-11-11 17:06 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：C_language_va_li... 

 





开通黄钻


structure{x:4}
 


 #include <stdio.h>
#include <stdlib.h>
struct c_a{
unsigned char x:3;
unsigned char y:3;
unsigned char z:2;
};
int main(void) {
char x=0x46;
struct c_a* id_c_a= (struct c_a*)(&x);
printf ( "%d %d %d \n ", id_c_a->x , id_c_a->y, id_c_a->z);
//      puts(" */
        return EXIT_SUCCESS;
}

 
  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：C_language_va_li... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:20





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





C_language_va_list    2015-11-10 20:03 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：#if_#elif_#else_... 

 





开通黄钻


C_language_va_list
 


 // _test.cpp : Defines the entry point for the console application.
//

#include "stdafx.h"


#include <stdarg.h>

float ave(int N_, ...){
 int count; 
 va_list id_vlist; 
 float sum=0; 
 
 va_start( id_vlist, N_); 

 for( count =0 ; count < N_;  count+=1){
  
  sum  += va_arg( id_vlist, int ) ;  
  
 }
 
 va_end(id_vlist); 
 return sum/N_; 
 
 
}

#define EXIT_SUCCESS 1
int main(int argc, char* argv[])
{
 
 float x=ave(2,1,2); 
 printf("%f\n", x); 
 
 
 
 
 
 return EXIT_SUCCESS;  
 
 
 // fclose(fp); 
 
 printf("Hello World!\n");
 return 0;
}

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：#if_#elif_#else_... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:21





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





#if_#elif_#else_#endif_macro_    2015-11-9 10:22 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：windows_sleep_un... 

 





开通黄钻


#if_#elif_#else_#endif_macro_
 


 #include<stdio.h>
#define LETTER1 11
#define LETTER2 22
int main(int argc,char*argv[])
{

#if defined(LETTER1)
 printf("letter1\n"); 

#elif  defined(LETTER2) && LETTER2==2
 printf("letter2\n"); 
#else 
 printf("error\n"); 
#endif
 return 0; 

}

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：windows_sleep_un... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:21





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





windows_sleep_unistd_h    2015-11-9 09:50 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：Itel_x86_汇编_as... 

 





开通黄钻


windows_sleep_unistd_h
 


 #include <stdio.h>
#include <unistd.h>
//#include <windows.h>
int main(){

for(i=0;i<33;i++){
sleep(1);    // this is 1 second for unix 

printf("this is %d\n",i); 

}
return i ; 

}

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：Itel_x86_汇编_as... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:21





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





Itel_x86_汇编_assemble_lang    2015-8-30 19:14 阅读(1)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：ARC_CORE_interru... 

 





开通黄钻


Itel_x86_汇编_assemble_lang
 


 jidor@jidor:~/SCRATCH$ cat test.asm

; Makefile of asm 
; nasm -f elf64 -o test.elf  test.asm  && ld -o test.bin test.elf && chmod +x test.bin && ./test.bin

; hello.asm 
section .data            ; 数据段声明
        msg db "Hello, world!", 0xA     ; 要输出的字符串
        len equ $ - msg                 ; 字串长度

section .text            ; 代码段声明
global _start            ; 指定入口函数

_start:                  ; 在屏幕上显示一个字符串
        mov edx, len     ; 参数三：字符串长度
        mov ecx, msg     ; 参数二：要显示的字符串
        mov ebx, 1       ; 参数一：文件描述符(stdout) 
        mov eax, 4       ; 系统调用号(sys_write) 
        int 0x80         ; 调用内核功能

                         ; 退出程序
        mov ebx, 0       ; 参数一：退出代码
        mov eax, 1       ; 系统调用号(sys_exit) 
        int 0x80         ; 调用内核功能
  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：ARC_CORE_interru... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:21





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





ARC_CORE_interrupt_example    2015-8-21 21:18 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：Windows batch , ... 

 





开通黄钻


ARC_CORE_interrupt_example
 


 $ perl_show_all_file_content  *.h  *.c
*********************
ARCtimer.h
*********************
#define _reset_timer0  _sr(0x0, 0x21) ;
#define _read_timer0   _lr(0x21) ;
#define _init_timer0   _sr(0x3, 0x22); _sr(0x0, 0x21) ;
#define _set_limit0(x) _sr(x, 0x23);


/**** Examples for using the ARC timer ************** ;

#include "ARCtimer.h"

// Declare ARC Timer count value
   unsigned int timer_val=0;
// Initialse ARC Timer0
   _init_timer0 ;

// Reset ARC Timer0
   _reset_timer0 ;


// Read ARC Timer0 and print result
   timer_val = _read_timer0 ;
   printf("Number of ticks for function xxxxx was: \t%u \n", timer_val);

***** End of examples for using the ARC timer ********/

 

*********************
Interrupt_Example.c
*********************
#include <stdio.h>
#include "ARCtimer.h"

// Interrupt controller defines
#define INT_CTRL_IE (1 << 4) // Overall interrupt enable bit
#define PRIORITY 1          // Enables levels 1, and 0

short InterruptCount = 0;
double a, b, c, d;

int main () {

   printf("HS36 Starting execution\n");

        // Set up the timer for interrupt testing
        _init_timer0 ;        // Set up for timer 0
        _set_limit0(0x89) ; // Set wrap-around value. Interrupt will be generated when value is reached
        _seti(INT_CTRL_IE | PRIORITY); //Enable IE bit and set E to 2
//      _sr(16, 0x40B) ; // select control register for interrupt # 16
//      _sr( 1, 0x40C) ; // enable (1) / disable (0) interrupt # 16

        // Dummy code loop executes 1,000,000 times
   int i = 0 ;
   int val = 0xA ;
   for (i=0; i < 1000000 ; i++) {
           val = val + (val >> 1) ;
           val = val * (val - 1) ;
   }

   return val ;
}

// Keyword _Interrupt for ISR written in C
_Fast_Interrupt void IRQ_Timer0 (void) {
        InterruptCount++; // increment a counter for # of interrupts
        // clear the interrupt input signal if necessary
        //if (a < b) c = d ;
        _init_timer0 ;    // Clear the timer 0 interrupt
}


EOF
  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：Windows batch , ... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:21





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





Windows batch , cat.bat    2015-6-30 22:11 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：random_arr_from_... 

 





开通黄钻


Windows batch , cat.bat
 



 @echo off
:: Wrote by Jidor, at 2015-6-30 20:55
setlocal enabledelayedexpansion
set txt=%1
if "!txt!"=="" (
                echo cat filename 3-6 OFF
                ::pause
                goto :EOF
               )
set line_start=%2
:: control the line number
set set_num_on=%3
::echo !set_num_on!
echo ------
if "!set_num_on!"=="" (
                set set_num_on=OFF
                )
if "!set_num_on!"=="ON" (
                set set_num_on=ON
                ) else (
                        set set_num_on=OFF
                       )
        ::echo %set_num_on%
        ::set line_from_to=
        del /f /q _tmp_.txt  2>nul
        echo %line_start%|findstr /m "\-" > nul && echo YES> _tmp_.txt || echo NO> _tmp_.txt
        set /p var_of_YES_NO=<_tmp_.txt&& del _tmp_.txt


        ::echo %var_of_YES_NO%
        find /c /v "" %txt% | find ": " |repl "^.*\: " "" X > _tmp_.txt
        set /p txt_len=<_tmp_.txt && del _tmp_.txt
        ::      echo !txt_len!

 

        if "%var_of_YES_NO%"=="NO" (
                ::      echo only one num
                        set start_line=%line_start%
                        set to_line=!txt_len!
                        if "!start_line!"=="" (
                                set start_line=0
                                )


                        )

 

        if "%var_of_YES_NO%"=="YES " (
                        echo %line_start% |repl "\-.*$" "" X>_tmp_.txt
                        set /p start_line=<_tmp_.txt && del _tmp_.txt
                        echo %line_start% |repl "^.*\-" "" X|repl " " "" X>_tmp_.txt
                        set /p to_line=<_tmp_.txt&& del _tmp_.txt
                        ::      echo !to_line!
                        if "!to_line!"=="" (
                                set to_line=!txt_len!
                                )
                        if !start_line! GTR !txt_len! (
                                echo wrong start_line num: _!start_line!_
                                )
                        if !to_line! GTR !txt_len! (
                                echo set to_line num: !txt_len!
                                )
                        )
        :: end YES

        set cnt=1

        for /F "delims=" %%i in (%txt%) do (
                        if !cnt! GEQ !start_line! (
                                if !cnt! LEQ !to_line! (
                                        if "!set_num_on!"=="ON" (
                                                echo !cnt!: %%i
                                                )
                                        if "!set_num_on!"=="OFF" (
                                                echo %%i
                                                )
                                        )
                                )
                        set /a cnt+=1
                        )
        :EOF
         del /f /q _tmp_.txt  2>nul
         endlocal
         @echo off

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：random_arr_from_... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:21





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





random_arr_from_c++    2015-5-25 20:44 阅读(2)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：my_javascript_ta... 

 





开通黄钻


random_arr_from_c++
 


 #include <iostream>
#include <cstdlib>
#include <ctime>
#include <cstdio>
#include <Windows.h>
int get_one_rnd_num(int seed_){
        srand(seed_);
        return rand();
}
void get_rnd_arr(int *arr_, int num_){
        int i ;
        arr_[0]=get_one_rnd_num(time(NULL));
        for(i=1;i<num_;i++){
                arr_[i]=get_one_rnd_num(arr_[i-1]);
        }//end for(i)
}
void pt_arr(int *arr_,int len_){
        for(int i=0;i<len_;i++){
                printf("%d ", arr_[i]);
        }
        printf("\n");
}//end pt_arr()
void swap(int *a_, int *b){
        int t=*a_; *a_=*b; *b=t;
}
void rnd_arr_via_base(int *ret_arr, int len_ret_arr, int *base_rnd_arr, int len_base=100){
        if(len_base<len_ret_arr){
                printf("- ERROR\n");
                exit(0);
        }
        int i ;
        for(i=0;i<len_ret_arr;i++){
                swap( &ret_arr[(base_rnd_arr[i])%(len_ret_arr-i)], &ret_arr[len_ret_arr-1-i]) ;
        }
}
int main(){
        const int len=200;
        int arr_rnd[len]={0};
        get_rnd_arr(arr_rnd, len);
        const   int id_len=5;
        //int arr_sort[id_len]={1,2,3,4,5};
        //
        int i=0;
        int arr_sort[id_len];
        for(i=0;i<id_len;i++) arr_sort[i]=i+1;
        rnd_arr_via_base(arr_sort, id_len, arr_rnd, len);
        pt_arr(arr_sort, id_len);
        //pt_arr(arr_rnd, len);
        return 0;
}
// JD @ 2015-5-25　20：44
  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：my_javascript_ta... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:21





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





my_javascript_table_    2014-12-21 22:13 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：Javascript_lucky... 

 





开通黄钻


my_javascript_table_
 


 <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd"> 
<html> 
<head> 

<title> New Document </title> 
<meta name="Generator" content="EditPlus"> 
<meta name="Author" content=""> 
<meta name="Keywords" content=""> 
<meta name="Description" content=""> 
<style>
td {text-align:center}
.body{
   background-image: url("bg.png");
   background-position:top center;
   background-repeat: no-repeat;
  }
</style>

</head> 
<script type="text/javascript"> 
//--- GLOBAL VAR_ ---
var all_num = 115 ; 
var arr_eli=[
9,

6
]; 
var cnt_click_R0 = 3; 
//---

var arr_all=new Array(all_num); 

 

 

//----------------------------

//---- function list fun_()---
// init_arr ( arr_ ) ; 
// Array.removeEleAt( index ) ; 
// sleep( 44 ) ; 
// arr_R0_sub_R1(R0_, R1_); 
// get_1_random( from_num, to_num_ ) ; 
// get_not_0_ele_from_arr(arr_ ); 
// get_N_not_0_ele_from_arr(arr_ , arr_eli_, N_) ; 
// num_2_3bit_str( num_ ) ; 
// write_num_to_tr_cellnum( id_tr_, cell_num_, id_text_ ) ; 
// show_arr_to_tb(id_tb_, arr_ )

 

// set_table_with_arr10( 
//-----
function init_arr( arr_ ){
//### from 1 ~ N ( all the person ) 
for ( i = 0 ; i< arr_.length; i++){
arr_[i]=i+1; 
}
}

 

function arr_R0_sub_R1( R0_, R1_){
 for (i=0;i< R0_.length; i++ ){
  for (j=0;j< R1_.length; j++){
   if ( (R0_[i] == R1_[j]) && (R0_[i] != -1)  ) {
   R0_[i]=-1;
   }
  
  }
 
 }

}// end arr_R0_sub_R1

function get_1_random(from_num_, to_num_ ) {
var f_num=Math.floor(Math.random() * (to_num_ - from_num_+1) + from_num_); 

//alert( f_num ) ; 
return f_num ; 

}

function get_not_0_ele_from_arr(arr_,arr_eli_ ){
var len=arr_.length; 
while(true){
var rnd_index = get_1_random(0, len-1 );
if( arr_[rnd_index] != -1 ) {
 var tmp=arr_[rnd_index]; 
 arr_[rnd_index]=-1; 
arr_eli_.push( tmp ); 
//alert ( arr_eli_ ) ; 
return tmp ; 

}
}


}; //end get_not_0...

 

function get_N_not_0_ele_from_arr(arr_ , arr_eli_, N_){
var arr_N= new Array();
for(i=0;i<N_;i++){
arr_N.push( get_not_0_ele_from_arr(arr_ ,arr_eli_ ) ); 

}
//alert( arr_N ) ; 
//alert ( arr_eli_ ) ; 
return arr_N; 
}; //end get_N_not_0...

function num_2_3bit_str(num_){
var i=Math.floor(num_/100); 
var j=Math.floor(( num_ - i*100)/10); 
var k=num_%10; 
var str=""+i+j+k; 
str=str.replace( /^0/,' '); 
str=str.replace( /^ 0/,'  '); 
return str ;  
}


function write_num_to_tr_cellnum( id_tb_,rows_idx_, cells_idx_, id_text_ ){
var td_templ  ='<p   style="font-family:Impact;color:yellow;font-size:44px"><b>XXX</b></p>' ; 
var text=num_2_3bit_str(id_text_);
document.getElementById( id_tb_ ).rows[rows_idx_].cells[cells_idx_].innerHTML=td_templ.replace('XXX',text);
}

function show_arr_to_tb( id_tb_, arr_ , rows_, cols_ ){

for(i=0;i<rows_;i++){
 for(j=0;j<cols_;j++){
write_num_to_tr_cellnum( id_tb_,   i , j , arr_[ i*cols_+j] );
 }
}

}

 

 


//----------------------------------

//--- fun test_ area---
var arr10_0=new Array(); 
var arr10_1=new Array(); 
var arr10_2=new Array(); 
var id_tb_0='id_tb_0'; 
var id_text_0="id_text_0"; 
var id_text_show=" " ; 


function test(){
id_text_show="" ; 
init_arr( arr_all ) ; 
document.getElementById( id_text_0 ).value=id_text_show ; 

// sub all the initial array
arr_R0_sub_R1( arr_all, arr_eli ) ; 
//var id_tb_0='id_tb_0';

arr10_0=get_N_not_0_ele_from_arr( arr_all, arr_eli, 10); 
 arr10_1=get_N_not_0_ele_from_arr( arr_all, arr_eli, 10); 
 arr10_2=get_N_not_0_ele_from_arr( arr_all, arr_eli, 10); 

 

 

 


}// end test () ---

 

function fun_(){};
function fun_(a  , b){}; 


function input_onClick(){

var rows_=2; var cols_=5; 
//cnt_click_R0
if( cnt_click_R0==3) {
show_arr_to_tb( id_tb_0, arr10_0 , rows_, cols_ );

document.getElementById( id_text_0 ).value+=(arr10_0.toString()+"\n") ; 
}
else if( cnt_click_R0==2) {
show_arr_to_tb( id_tb_0, arr10_1 , rows_, cols_ );
document.getElementById( id_text_0 ).value+=(arr10_1.toString()+"\n") ; 
}
else if( cnt_click_R0==1) {
show_arr_to_tb( id_tb_0, arr10_2 , rows_, cols_ );
document.getElementById( id_text_0 ).value+=(arr10_2.toString()+"\n") ; 
document.getElementById( "id_btn_0").disabled = true; 
}

else {};

cnt_click_R0--; 
} // onclick () 


//-------------------------

</script> 


<body class="body" topmargin="0" leftmargin="0" bgcolor="red" onLoad="test();  ">
<EMBED src='start_cn.wav' autostart="false" hidden='true' loop='false' name='_play_start' >
<EMBED src='click.wav' autostart="false" hidden='true' loop='false' name='_play_click' >
<EMBED src='happy.wav' autostart="false" hidden='true' loop='false' name='_play_happy' >
<EMBED src='oo.wav' autostart="false" hidden='true' loop='false' name='_play_oo' >
<EMBED src='stop.wav' autostart="false" hidden='true' loop='false' name='_play_stop' >


<input id="id_btn_0"  type="button" value="抽签" onClick="input_onClick();" style="color:blue; font-size:22px;position:relative;top:250px;left:371px"> </input>

<center>

<textarea id="id_text_0"  border="0"      readonly="true" style="background:transparent;color:yellow; font-size:22px; height:75px;width:732px;position:relative;top:277px;"> </textarea>
</center>


<table id="id_tb_0" align="center" border="3"  bgcolor="red"   fontsize="44"   style="color:yellow; font-size:31px; background:url(tb.jpg) no-repeat;height:350px;width:732px;position:relative;top:300px;"> 

<tr> 
  <td><p   style="color:yellow;font-size:44px"><b>XXX</b></p>  </td>
 <td><p   style="color:yellow;font-size:44px"><b>XXX</b></p>  </td>
 <td><p   style="color:yellow;font-size:44px"><b>XXX</b></p>  </td>
 <td><p   style="color:yellow;font-size:44px"><b>XXX</b></p>  </td>
 <td><p   style="color:yellow;font-size:44px"><b>XXX</b></p>  </td>

</tr>

<tr> 
 <td><p   style="color:yellow;font-size:44px"><b>XXX</b></p>  </td>
 <td><p   style="color:yellow;font-size:44px"><b>XXX</b></p>  </td>
 <td><p   style="color:yellow;font-size:44px"><b>XXX</b></p>  </td>
 <td><p   style="color:yellow;font-size:44px"><b>XXX</b></p>  </td>
 <td><p   style="color:yellow;font-size:44px"><b>XXX</b></p>  </td>
</tr>

 

 

</table> 

 

 

 

 


</body > 

 


</html>

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：Javascript_lucky... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:21





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





Javascript_lucky_draw_    2014-12-13 17:57 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：Image_myclass_db... 

 





开通黄钻


Javascript_lucky_draw_
 


 <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 TRANSITIONAL//EN">
<html>
<head>
<title> 2006年会抽奖系统</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<script language="javascript">
 
// global variables 
var timer;
var flag = new Array(100);
var existingnum = new Array(100);
var clickTimes = 0;
var randnum;
var cellnum =1;
var mobile = new Array();
// set data here!!
mobile[0]=13020000100;
mobile[1]=13020000101;
mobile[2]=13020000102;
mobile[3]=13020000103;
mobile[4]=13020000104;
mobile[5]=13020000105;
mobile[6]=13020000106;
mobile[7]=13020000107;
mobile[8]=13020000108;
mobile[9]=13020000109;
mobile[10]=13020000110;
mobile[11]=13020000111;
mobile[12]=13020000112;
mobile[13]=13020000113;
mobile[14]=13020000114;
mobile[15]=13020000115;


mobile[16]=13020000116;
mobile[17]=13020000117;
mobile[18]=13020000118;
mobile[19]=13020000119;
mobile[20]=13020000120;
mobile[21]=13020000121;
mobile[22]=13020000122;
mobile[23]=13020000123;
mobile[24]=13020000124;
mobile[25]=13020000125;
mobile[26]=13020000126;
mobile[27]=13020000127;
mobile[28]=13020000128;
mobile[29]=13020000129;
mobile[30]=13020000130;
mobile[31]=13020000131;
mobile[32]=13020000132;
mobile[33]=13020000133;
mobile[34]=13020000134;
mobile[35]=13020000135;
mobile[36]=13020000136;
mobile[37]=13020000137;
mobile[38]=13020000138;
mobile[39]=13020000139;
mobile[40]=13020000140;
mobile[41]=13020000141;
mobile[42]=13020000142;
mobile[43]=13020000143;
mobile[44]=13020000144;
mobile[45]=13020000145;
mobile[46]=13020020146;
var num = mobile.length-1;
function getRandNum(){
document.getElementById("result").value = mobile[GetRnd(0,num)];
}
function start(){
clearInterval(timer);
timer = setInterval('change()',50); 
}
function ok(){
clearInterval(timer);
}
function GetRnd(min,max){
 
randnum = parseInt(Math.random()*(max-min+1));
return randnum;
}
function setTimer(){
 timer = setInterval("getRandNum();",10);
 document.getElementById("start").disabled = true;
 document.getElementById("end").disabled = false;
}
function clearTimer(){
 noDupNum();
 clearInterval(timer);
 document.getElementById("start").disabled = false;
 document.getElementById("end").disabled = true;
 
}


function noDupNum(){
 // to remove the selected mobile phone number
 mobile.removeEleAt(randnum);
 
 // to reorganize the mobile number array!!
 var o = 0;
 for(p=0; p<mobile.length;p++){
 if(typeof mobile[p]!="undefined"){
 mobile[o] = mobile[p];
 o++;
 }
 }
 num = mobile.length-1;
 }
// method to remove the element in the array
Array.prototype.removeEleAt = function(dx)
 {
 if(isNaN(dx)||dx>this.length){return false;}
 this.splice(dx,1);
 }
// set mobile phone numbers to the table cell 
function setValues(){
 document.getElementById(cellnum).value = document.getElementById("result").value ;
 cellnum++;
 }
</script>
</head>
<body>
<center>
<div> </div>
<div id="main">
 <div>
 <h1>中奖号码</h1>
 
 <p>
 <input id="result" type="text" size="30" style="height:130px;width:800px;border:2px solid red;font-size:120;" readonly/></p>
 <p>
 <input id="start" type="button" value="开始" style="border: 1px solid; border-color: #aaa 000 #000 #aaa;width:4em; background: #fc0;" onclick="setTimer()" />
 <input id="end" type="button" value="停" style="border: 1px solid; border-color: #aaa 000 #000 #aaa;width:4em; background: #fc0;"onclick="clearTimer();setValues();" disabled/>
</p>
 <p><strong>一等奖（10名）</strong></p>
 <table width="946" height="79" border="1">
 <tr>
 <td><input name="text36" type="text" id="36" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="28" readonly/></td>
 <td><input name="text37" type="text" id="37" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text38" type="text" id="38" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text39" type="text" id="39" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text40" type="text" id="40" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 </tr>
 <tr>
 <td><input name="text41" type="text" id="41" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="28" readonly/></td>
 <td><input name="text42" type="text" id="42" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text43" type="text" id="43" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text44" type="text" id="44" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text45" type="text" id="45" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 </tr>
 </table>
 <p>二等奖（15名）</p>
 <table width="951" height="88" border="1">
 <tr>


 <td><input name="text21" type="text" id="21" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="28" readonly/></td>
 <td><input name="text22" type="text" id="22" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text23" type="text" id="23" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text24" type="text" id="24" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text25" type="text" id="25" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 </tr>
 <tr>
 <td><input name="text26" type="text" id="26" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="28" readonly/></td>
 <td><input name="text27" type="text" id="27" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text28" type="text" id="28" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text29" type="text" id="29" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text30" type="text" id="30" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 </tr>
 <tr>
 <td><input name="text31" type="text" id="31" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="28" readonly/></td>
 <td><input name="text32" type="text" id="32" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text33" type="text" id="33" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text34" type="text" id="34" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text35" type="text" id="35" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 </tr>
 </table>
 <p>三等奖（20名）</p>
 <table width="961" height="102" border="1">
 <tr>
 <td><input name="text1" type="text" id="1" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="28" readonly/></td>
 <td><input name="text2" type="text" id="2" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text3" type="text" id="3" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text4" type="text" id="4" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text5" type="text" id="5" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 </tr>
 <tr>
 <td><input name="text6" type="text" id="6" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="28" readonly/></td>
 <td><input name="text7" type="text" id="7" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text8" type="text" id="8" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text9" type="text" id="9" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text10" type="text" id="10" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 </tr>
 <tr>
 <td><input name="text11" type="text" id="11" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="28" readonly/></td>
 <td><input name="text12" type="text" id="12" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text13" type="text" id="13" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text14" type="text" id="14" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text15" type="text" id="15" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 </tr>
 <tr>
 <td><input name="text16" type="text" id="16" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="28" readonly/></td>
 <td><input name="text17" type="text" id="17" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text18" type="text" id="18" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text19" type="text" id="19" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 <td><input name="text20" type="text" id="20" style="height:30px;width:190px;border:1px solid red;font-size:25;" size="20" readonly/></td>
 </tr>
 </table>
 <p> </p>
 <p> </p>
 <p> </p>
 </div>
</div>
<center>
 </body>
</html>
  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：Image_myclass_db... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:21





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





Image_myclass_dbg_test    2014-11-17 15:49 阅读(4)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：A股随借主力之风 

 





开通黄钻


Image_myclass_dbg_test
 



#include<stdio.h>
#include <math.h>
#include <stdlib.h>
#include <time.h>
typedef unsigned char uchar;
typedef unsigned char byte;

#define WIDTH_ALIGN(_w,_align) \
       ((_w%_align!=0)?(_w/_align+1)*_align:_w)
#define WIDTH_4(_w) WIDTH_ALIGN(_w,4)
#define SEED 133
#define IMG_CNT_MAX 100

#define GET_IMG_i_j(img_,i,j) (img_->lpbuf[i*W+j])

typedef struct img_{
uchar *lpbuf;
int h ;
int w ;
}img;
typedef struct _imglist{
       int cnt;
       img* img_arr[IMG_CNT_MAX];
}img_list;
static img_list id_img_list;


img* create_img(int h,int w);

void show_img_data(img *img);
void set_img_rnd(img *_img);

void clear_img(img *img);
void add_gray(img *img);


void free_img(img *id_img);
void merge_img(img *dst,float alpha,img *img_a,float belta, img *img_b);
void free_all_img();
//---- main() ---

int main(int _n,char ** _v){

int i=9;
img *id_img=create_img(3,5);
set_img_rnd(id_img);
show_img_data(id_img);


free_all_img();



return 0;
}
//-----------


img* create_img(int h,int w){
int W=WIDTH_4(w);
uchar* lpbuf=(uchar*)(malloc(W*h));
img *id_img=(img*)(malloc(sizeof(img)));
id_img->lpbuf=lpbuf;
id_img->w=w;
id_img->h=h;

id_img_list.img_arr[id_img_list.cnt++]=id_img;


return id_img;
}
void free_all_img()
{
int cnt=id_img_list.cnt;
int i;
for(i=0;i<cnt;i++){
printf("i is %d\n",i);
if(id_img_list.img_arr[i])
free_img(id_img_list.img_arr[i]);

}
id_img_list.cnt=0;
}//end free_all_img();

void free_img(img *id_img){
       if(id_img==NULL) return ;

uchar *lpbuf=(id_img)->lpbuf;
if(lpbuf==NULL) return ;
free(lpbuf);
lpbuf=NULL;
free(id_img);
id_img=NULL;
}//end free_img();
void show_img_data(img *img_){
if(!img_) return ;
int i;
int j;
int W=WIDTH_4(img_->w);
for(i=0;i<img_->h;i++){
for(j=0;j<img_->w;j++){
       printf("%3d",GET_IMG_i_j(img_,i,j) );
}//end for j
printf("\n");
}//end for i




}//end show_img__data()
void set_img_rnd(img *_img){
int W=WIDTH_4(_img->w);
int i;  int j ;
for(i=0;i<_img->h; i++){
for(j=0;j<_img->w;j++){

 uchar*p=&GET_IMG_i_j(_img,i,j);
srand(i+SEED);
int temp=(int)rand();
//srand(temp+i+j-*(p-1)+*(p-W+j-1));

srand(temp+i+j*j);
*p=(uchar)(rand()%255);

}//end for j
}//end for i

}//end set_img_rnd ()

void clear_img(img *img){
int W=WIDTH_4(img->w);
int i;
int j;
for(i=0;i<img->h;i++)
       for(j=0;j<img->w;j++)
              GET_IMG_i_j(img,i,j)=0;

}//end clear_img()
void add_gray(img *img){
int i;int j;
int W=WIDTH_4(img->w);
int w=img->w;
int h=img->h;
for(i=0;i<h;i++){
for(j=0;j<w;j++){
uchar *p=&(GET_IMG_i_j(img,i,j));
int temp=*p+15;
if(temp>255) temp=255;
*p=temp;
}
}

}//end add_gray()

void merge_img(img *dst,float alpha,img *img_a,float belta, img *img_b)
{
       int w_a=img_a->w;
       int w_b=img_b->w;
       if(w_a!=w_b) return ;
int w=w_a;
int h=img_a->h;
int W=WIDTH_4(img_a->w);
uchar *lpbuf_a=img_a->lpbuf;
uchar *lpbuf_b=img_b->lpbuf;
uchar *lpbuf_dst=dst->lpbuf;
int i; int j ;
for(i=0;i<h; i++){
for(j=0;j<w;j++){
uchar *p_a_i_j=&lpbuf_a[i*W+j];
uchar *p_b_i_j=&lpbuf_b[i*W+j];
uchar *p_dst_i_j=&lpbuf_dst[i*W+j];
int temp=(int)(alpha*(*p_a_i_j)+belta*(*p_b_i_j));
if(temp>255) temp=255;
*p_dst_i_j=(uchar) temp;
}
}
while(1);

}//end merge_img()

 
  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：A股随借主力之风 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:21





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





A股随借主力之风    2014-11-1 21:16 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：股市投资日记 

 





开通黄钻


A股随借主力之风
 


 
跟庄家走，做不输的股民

庄家建仓手册

－快速建仓，封死涨停板；

－低迷时期进货，震荡建仓；

－ 主动清洗盘；

－多日收于小涨，造成心理恐慌 ；

－ 利用非正式平台内幕，人为制造利空；

－ 对年报借题发挥，打压股价（与上市公司勾结）；

－来回震荡吸筹；

－ 技术骗线，多发卖出信号，心理战；

－ 压力线时，主动抛筹，以逗吸散筹；

－ 圆底形吸筹，时间半年左右 ；

－ 人为构筑价格箱，箱顶抛筹，箱底吸；

－ 上升旗中建仓，

－ 反弹吸筹，然后一路高进；

－ 公开抛筹，暗里吸筹；

－ 在低位暗吸筹，借风炒作；

－ 制造出逃假象，造成恐慌，吸筹；

－ 打压至极却跌无力，勾结上市公司，出尽利空，以达到恐慌性吸筹；

－ 横盘吸筹，直到完全控盘；

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：股市投资日记 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:22





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





 股市投资日记    2014-10-19 12:42 阅读(1)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：PPT_Shortcuts 

 





开通黄钻


股市投资日记
 



投资日记

初入股市

2014年下半年,随着手边的积蓄增多,闲置起来的奖金放在手上就有些不安分起来,想让它增值,以实现个人的财务自由(我深知,单纯地依靠打工是不可能实现这个目的的),在经历过比特币投资失败后,我逐渐变得愈加谨慎起来,所以也是很忐忑地投了P2P.细算了一下,觉得P2P年化11%的收益还是太低了,于是决定投身股海,觉得凭借自己的聪明才智和对于财报的敏感度,应该能打出一片新天地.

把yjb_开通后,就往里面充入了800元,某天中午又偶然发现用同花顺可以实现手机端App交易,在一片不稳定中,买了200股的中国南车.当天就有小小的涨幅,心里窃喜.买卖就这样开始了,带着巴菲特式价值投资的满腹经纶和理想主义,就这样开启了漫漫A股股市之旅.




成长历程

初期一切都很顺利,不懂就里的术语一大堆,都被一个个啃一下,"多头","空头","M2","量化宽松",也开始更加关注中国国内宏观经济,关注新闻联播,但从来不但是却忽视了一点,全世界是一个有机的统一的整体,很多事情会牵一发而动全身.在经历了几个夜晚苦读财报,加上股市在一片看似利好中,飞涨虚悬,我开始寻机操底.但是终究还是刚出茅庐,经验太嫩,犯了一些大忌.




决策过程的心理

在中国南车一路原地踏步的情况下,又开始伺机建仓.买入了第二去看好的家族股:好想你.首先是基于对于他们产品的感性认识,我吃过他们家产的枣,味道很不味,又加上那天他们价格降至几日内最低,因此我买入了400股.都是挂单买的,一个挂单21.88,300股,一个挂单21.90,100股,一会儿就买上了.说得很巧,第二天,它只涨了一点点,到第二天,居然一飞冲天.可是由于太年轻,价值投资的思想在作祟,我最终还是没有准备卖出去.接一下的几天点,在国外市场跌声不休的四面楚歌里,它保持每天跌2.3%以上跌得比我买入价格还要低的新低位.

在好想你疯涨的当天,我感觉似乎找到了规律.于是又入了东方园林17.67,300股@2014-10-15和伊利股份24.01,200股@2014-10-14.在经历一天的跳水后,我的总市值不断缩水,心里也不由一紧,暗自叫苦.这一天是周四,下跌的股市一直不休,看得让人心焦.下午的时候,又在自以为很低的价格上买入了一个服装股,报喜鸟,觉得他们可以会成为双十・一的一支潜力股,买入后他就是我的负债,真是后悔不已.买报喜鸟表明了我作为一个投资者的不成熟之处:之前对于这个股票甚至不了解,没有关注过它的财报,也没有了解它的市场,只因为价格新低,就贸然入手,结果只能是悲剧.买伊利则是看重它的蓝筹本质,肯定不会因为一时的市值缩水而大减.后面在黑色周五的大行情,它不降反涨,真是很不错的股票.在此慌乱中,居然又做错了一件大事,当中国南车涨到5.37时,把手上的蓝筹全卖出了.卖完后,打开手机一看,居然是中俄牵订了跨国高铁修筑协议,欲哭无泪啊.信息啊,情报啊,真是太重要了.

只顾本国大环境的我,忽略了美股的状况.随着美股,欧股的大行情不断下挫,中国A股也是人心惶惶.终于抗不住国际压力.开始狂跌.我的市值也一天天缩水,后面干脆不看.但想着,自己一直是以价格投资作为底线的.应该不至于犯什么错.惟一担心的就是报喜鸟.这个亏损的服装行业,不知道会不会拖累我的大盘蓝筹?

这个周五晚上,看了一下,美股居然强势回归,令人心生许多想象.就看下周一(2014-10-20)的开盘信息了!
  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：PPT_Shortcuts 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:22





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





PPT_Shortcuts    2014-10-8 15:39 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：dos_edit_registe... 

 





开通黄钻


PPT_Shortcuts
 


 

PPT shortcut:

ctrl + delete : delete previous word 

num + ENTER : go page num

B / W : black pane or white pane

P/N : Previous and Next pane

ctrl + P : pen in show status

E : erase all the trajectory 

ctrl + A : get Arrow when show 
  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：dos_edit_registe... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:22





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





dos_edit_register_system_user_env    2014-9-24 17:55 阅读(1)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：archi_bld_mess_i... 

 





开通黄钻


dos_edit_register_system_user_env
 


 
@echo off 
::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
::  TEST AREA  ::
:: MY_ROOT= c:\arc\software
:: MY_PATH= %MY_ROOT%\bin;%tmp%;%MY_ROOT%;%windir%;%tmp%;%MY_ROOT%\bin;%tmp%
::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

 

::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
::  GLOBAL DEFINES  ::
set tmpfile=%tmp%\tmp.txt

set SYS_ENV=HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Session 
set USER_ENV=HKEY_CURRENT_USER\Environment

 set _ENV_=%USER_ENV%
 set my_path_R0=MY_PATH

::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::


 reg query %_ENV_% /v MY_ROOT | findstr REG_

if errorlevel 1  (
echo errror MY_ROOT!
goto :eof 
)


 set _ENV_=%USER_ENV%

:: # regex to strip %MY_ROOT%\bin ; 
 set target_to_subst=.MY_ROOT..bin.*?;


:: # txt.txt ,  MY_PATH strip all %MY_ROOT%\bin 

reg query %_ENV_% /v %my_path_R0%|findstr REG_|repl "^\s+.*\s+(\S)" "$1" X |  repl %target_to_subst%  ""  > txt.txt
 for /F "tokens=1-8* delims=" %%i in (txt.txt) do (
set varx=%%i && del txt.txt
)
echo  -------------R0----------------------
echo %varx%
echo  ---------------------------------------
 reg add "%_ENV_%" /v MY_PATH /t REG_EXPAND_SZ /d "%%MY_ROOT%%\bin;%varx%" /f

 

::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
::  TEST AREA  ::
::  refresh register info  ::
::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::

 

taskkill /f /im explorer.exe > nul
start "" "explorer.exe"

reg query %_ENV_% /v %my_path_R0%

 

:EOF

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：archi_bld_mess_i... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:22





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





archi_bld_mess_info    2014-9-15 09:58 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：perl_module_Jido... 

 





开通黄钻


archi_bld_mess_info
 


---------------------------------------------MESS INFO---------------------------------------------







> pushd /slowfs/us01dwslow025/arc_test/linqi/ia_p/archi_ia/ia_win32 && sh  build_ia_pkg.sh 2014.03-SP1




-README-

sh build_ia_pkg.sh 2014.03-SP1

     [CALL] perl config_rel_p4_View_iap_xml.PL 2014.03-SP1 

#note: 

     . config p4 client's view, bakup old iap_xml file, then update iap_xml ( version number, new p4 sync id ... ) ; 

     . p4 sync new archi version SRC, then run ia_build iap_xml; 







---architect ia_linux---

> pushd /slowfs/us01dwslow025/arc_test/linqi/ia_p/archi_ia/ia_linux && sh  build_ia_pkg.sh 2014.03-SP1










NEED to edit the permission of all the files ; 







# verify :




# ~/linqi/archi_p/arch_2014.03-sp1/linux/ARChitect$ ls

# architect.properties bin docs EULA.pdf flexlm jre lib logging.properties plugin verify




# /SCRATCH/ARC/ARChitect_1055$ ls

# architect.properties bin docs EULA.pdf flexlm jre lib logging.properties plugin verify Uninstall ARChitect IP Configurator




#verify archi_ia

# ---Program Area---

export DIR0=~/linqi/archi_p/arch_2014.03-sp1/linux/ARChitect 




 export DIR1=/SCRATCH/ARC/ARChitect_1140    # ARChitect install dir ROOT --- ROOT/jre




declare -a arr_a

arr_a=(architect.properties bin docs EULA.pdf flexlm lib logging.properties plugin verify)  # no jre and Uninstall.*




for i in "${arr_a[@]}"

do 

#printf "$DIR0/$i  \n" printf "$DIR1/$i  \n"

diff -uwqr $DIR0/$i $DIR1/$i

done 


 




---build ARChitect---

SRC + docs:

//dwarc/Tools/ARChitect/main/dev/... //uswa/architect/...

//dwarc/TechPubs/UserDocs/Output/5079_ARChitectTools_Bookshelf/trunk/jar/... //uswa/architect/docs/javahelp/... 

//dwarc/TechPubs/UserDocs/Output/5079_ARChitectTools_Bookshelf/trunk/pdf/... //uswa/architect/docs/pdf/...

//dwarc/TechPubs/UserDocs/Output/5079_ARChitectTools_Bookshelf/trunk/pdfzip/... //uswa/architect/docs/pdfzip/...




---on ETEST3---

pushd C:\cygwin\home\linqi\tmp\arch_2014.03-sp2 && cd dev\build_env\daily*




relbuild.bat 




---for windows:

pushd ~/linqi/archi_p/arch_2014.03-sp2 &&  rm -rf build/out/verify build/logs && mkdir build/win32 && mv build/out build/win32/ARChitect

---for linux:

pushd ~/linqi/archi_p/arch_2014.03-sp2 &&  rm -rf build/out/verify build/logs && mkdir build/linux   && mv build/out build/linux/ARChitect







---p4 add  && p4 submit :

//dwarc/Tools/ARChitect/2014.03-SP2/build/... //linqi/linqi/archi_p/arch_2014.03-sp2/build/







p4 Views from etn:  revertunchanged

       //dwarc/Tools/ARChitect/2014.03-SP2/dev/... //arch_linux_bld/architect/...

        //dwarc/TechPubs/UserDocs/Output/5079_ARChitectTools_Bookshelf/trunk/jar/... //arch_linux_bld/architect/docs/javahelp/...

        //dwarc/TechPubs/UserDocs/Output/5079_ARChitectTools_Bookshelf/trunk/pdf/... //arch_linux_bld/architect/docs/pdf/...

        //dwarc/Tools/ARChitect/2014.03-SP2/tst/... //arch_linux_bld/arch_test/...

        //dwarc/Tools/ARChitect/2014.03-SP2/build/linux/ARChitect/... //arch_linux_bld/build/out/...




---





         //dwarc/Tools/ARChitect/2014.03-SP2/dev/... //etest5_arch_win_bld/architect/...

        //dwarc/TechPubs/UserDocs/Output/5079_ARChitectTools_Bookshelf/trunk/jar/... //etest5_arch_win_bld/architect/docs/javahelp/...

        //dwarc/TechPubs/UserDocs/Output/5079_ARChitectTools_Bookshelf/trunk/pdf/... //etest5_arch_win_bld/architect/docs/pdf/...

        //dwarc/Tools/ARChitect/2014.03-SP2/tst/... //etest5_arch_win_bld/arch_test/...

        //dwarc/Tools/ARChitect/2014.03-SP2/build/win32/ARChitect/... //etest5_arch_win_bld/build/out/... 










---
1. p4 sync , then must  run edit :    find . | p4 edit 

2. cp files to this dir , then add :     find . | p4 add 

3. p4 submit , probably show change list,   run : p4 submit -c  387712

4. p4 submit -c 387712 | grep open

5. p4 revert file_opened




 

p4 tag -l ARChitect_v2014.03-SP2-eng1 //dwarc/Tools/ARChitect/2014.03-SP2/...

path of installer is wrong ?

for windows :

check out -> add -> revert  -> submit 










---ARChitect release for engneer---

1. fill with 

Product=ARChitect    

version=I-2014.03-SP2-eng1    

CCList=ejacobs@synopsys.com; puzyrev@synopsys.com    

Source=/slowfs/us01dwslow025/arc_test/linqi/installer_rel/I-2014.03-SP2-eng1/    

Release TYPE=build/patch/release

    

Source must include: ~/linqi/archi_p/arch_2014.03-sp2/dev/docs/pdfzip/ARChitectTools_Bookshelf_pdf.zip




---media pkg creation---




/slowfs/us01dwslow025/arc_test/linqi/installer_rel/I-2014.03-SP2-eng1/ARChitect_I-2014.03-SP2_eng1_setupLinuxI386.bin
 



/slowfs/us01dwslow025/arc_test/linqi/installer_rel/I-2014.03-SP2-eng1/ARChitect_I-2014.03-SP2_eng1_setupWin32I386.exe
 



/slowfs/us01dwslow025/arc_test/linqi/installer_rel/I-2014.03-SP2-eng1/ARChitect_ReleaseNotes.pdf
 



/slowfs/us01dwslow025/arc_test/linqi/installer_rel/I-2014.03-SP2-eng1/ARChitectTools_Bookshelf_pdf.zip










---archi p4 submit---




(before bld)    p4 sync -f 

(before bld)    p4 edit 

<-bld->

(after bld)       p4 add 

(after bld)       p4 submit ; 




---for Linux---

export P4CLIENT=arch_linux_bld ; p4 client 

  p4 sync -f 




find_by_name '*'|xargs   p4 edit 

cd $home_p/*p4/arch*lin*   && cd arch*/*_env/da*  && relbuild.sh 

find_by_name '*'|xargs  p4 add 

export P4CLIENT=arch_linux_bld && p4 submit 





p4 sync point :

export P4CLIENT=arch_linux_bld




---for win32---

> export P4CLIENT=arch_win32_bld ; p4 client     

> find_by_name '*'|xargs   p4 sync -f 

> find_by_name '*'|xargs   p4 edit 

> pushd P:\*p4\arch*win*   && cd archi*\*_env\d*  && relbuild.bat

> find_by_name '*'|xargs  p4 add 

> export P4CLIENT=arch_win32_bld && p4 submit 







set Views -> sync -f -> p4 edit -> bld -> p4 add -> p4 submit







#!bash

#---for linux---

export _OS_=linux 

find_by_name='find ./ -name '

echo "- p4 sync..."

export P4CLIENT=arch_${_OS_}_bld  && p4 sync 

pushd $home_p/ia_p4/$P4CLIENT

pushd build/out

p4 edit `$find_by_name '*' `

popd

###bld###

echo -e "- begin build...\n"

pushd architect/build_env/dailybldtst  && relbuild.sh && popd 

logs_ant=`tail build/logs/*ant* |grep -i success`

if ! [[ "$logs_ant" =~ "SUCCESSFUL" ]] ; then 

echo -e "- build failed ! \n" && exit

fi


pushd build/out

p4 add `$find_by_name '*' `

p4 submit

popd








(before bld)    p4 sync -f 

(before bld)    p4 edit 

<-bld->

(after bld)       p4 add 

(after bld)       p4 submit ; 







:: bat file to sync -> edit -> add -> submit 

:: perl p4 

set _OS_=win32

p4 set P4CONFIG=p4config.txt




set P4CLIENT=etest5_arch_win_bld

set P4PORT=p4p-us01:1900

p4 sync 

:: C:\cygwin\home\linqi\ia_p4\etest5_arch_win_bld\etest5_arch_win_bld :: 

pushd %win7%\ia_p4\%P4CLIENT%\%P4CLIENT%

call :show_ws

p4 sync 




pushd build\out

call :show_ws

echo -e "- p4 edit \n"

dir /s /b | p4 -x - edit 

popd 

::_______

::###bld###

pushd architect\build_env\dailybldtst 

call :show_ws

echo  "- begin build %_OS_% ...\n"

relbuild.bat

popd > /nul







pushd build/out

printf "- p4 add \n"




dir /s /b | p4 -x - add 

username_=$(basename `cd && pwd`)

if [ "$des" == "" ]; then

        des="${username_} submit @ `date` "

        echo "- des is $des"

























:show_ws

p_w_d=%CD%

echo  "- current workspace is:\n\t%p_w_d% "

GOTO :EOF













---README for linux architect rel---

Usage:

    sh arch_linux_bld.sh -d "this is version 2"




 # to see views, notes its version 

        export P4CLIENT=arch_linux_bld &&  p4 client   

































  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：perl_module_Jido... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:22





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





perl_module_Jidor.pm    2014-8-20 16:31 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：java_CALL_perl 

 





开通黄钻


perl_module_Jidor.pm
 


 *********************
/home/linqi/perl_p/Jidor.pm
*********************
#!perl
use feature qw(say);
use strict;

package Jidor;
require Exporter;
our @ISA=qw(Exporter);

#use Jidor qw(Jidor_Usage subst_dot subst_foreach smart_match);
our @EXPORT=qw(Jidor_Usage subst_dot subst_foreach smart_match);

#--- Usage:
# !perl
# BEGIN{push @INC,@ENV{perl_p};}
# use Jidor qw(Jidor_Usage subst_dot subst_foreach smart_match);
# -
#  subst_dot( @arr );                   ;# @arr return to @arr;
#  subst_foreach ( $file_name, @arr )   ;# @arr is the list for searching str and replace string
#  smart_match( $tag, @arr_num_or_str ) ;# -1 not match,or $loc_i is return
# -
#---END Usage

 

 


sub Jidor_Usage(){
        my $perl_pm_dir = @ENV{perl_p}.'/';
        my $Jidor_pm = 'Jidor.pm';
        my $pm_full_path =$perl_pm_dir.$Jidor_pm;
        my @arr=`cat $pm_full_path |grep -A9 -P 'Usage\:' `;
        say @arr;
}
sub subst_dot(\@){
#my @arr = @_;
        map{
        chomp;
        s|\\|\\\\|g;
        s|\/|\\\/|g;
        s|\.|\\\.|g;
        s|\-|\\\-|g;
        }@_;

#print "@_";

} #end subst_dot();

# @arr = ("str1","str1_new","STR2.2","STR3.3";
# subst_foreach($file_name, @arr) # s/@arr[0]/@arr[1]/g;
sub subst_foreach($ \@){

        my ($file_name, $arr_str) = @_;
        my @arr=@$arr_str;
        my $len=@arr;
        say " len of arr is $len";
        if(@arr%2 == 1){
                say "- error subst str list ! ";
                exit(1);
        }
        &subst_dot(@arr);
# print "@arr";
        my $i=0;
        my $cmd_total='';
        my $arr_len=@arr;
        map{
        $cmd_total .= q(perl -i.bak -pe ' ) if $i == 0 ;

#$cmd_total .= q(s/@arr[).$i.q(]/@arr[).($i+1).q(]/ ; );
        $cmd_total .= qq(s/@arr[$i]/@arr[($i+1)]/; );
        $cmd_total .= qq(' $file_name ) if $i == ($arr_len-2);
        $i=$i+2;
        }(0..$arr_len/2-1);
        say "$cmd_total";
        system($cmd_total);
        return $cmd_total;
} # end subst_foreach

sub smart_match($ \@){
        my ($tag,$arr_str) = @_;
        my      @arr=@$arr_str;
        my $i=0;
        for( $i=0;$i<@arr;$i++){
                last if( $tag == @arr[$i] || $tag eq @arr[$i] ) ;

        }#end for()
        return -1 if ($i == @arr);
        return $i;

}

 

*********************
_perl.PL
*********************
#!perl
BEGIN{push @INC,@ENV{perl_p};}
use feature qw(say);
use strict;

use Jidor qw(Jidor_Usage subst_dot subst_foreach smart_match);
#Jidor_Usage();

EOF

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：java_CALL_perl 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52











评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





java_CALL_perl    2014-8-15 10:15 阅读(1)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：java_jre_jvm_set... 

 





开通黄钻


java_CALL_perl
 


 




Java - Perl 
链接：百度网盘：_perl_
no "use " , not "pm" in _perl.PL 

 

=pod

###--- 

pushd C:\Users\linqi\linqi\tmp\jerl-7c5d8784a6ff\jerl-7c5d8784a6ff\java

javac -classpath ..\jars\jerl.jar; testJerlVMCall.java && java -classpath ..\jars\jerl.jar;..\java;. testJerlVMCall

or : java -jar jerl.jar _perl.PL

###-

=cut 

















import org.ibex.nestedvm.Runtime;

import org.ibex.nestedvm.UsermodeConstants;

import org.ibex.nestedvm.Runtime.*;

import org.ibex.nestedvm.util.*;

import org.ibex.nestedvm.*;

import java.io.*;





public class testJerlVMCall { 


public static void main(String[] args) throws Exception { 


final Runtime rt1, rt2, rt3; 

rt1 = (Runtime) Class.forName("jerl").newInstance(); 

rt2 = (Runtime) Class.forName("jerl").newInstance(); 

rt3 = (Runtime) Class.forName("jerl").newInstance(); 

// Runtime.InputOutputStreamFD fd = (Runtime.InputOutputStreamFD) rt1.getFD (UsermodeConstants.STDOUT_FILENO); 

// Runtime.InputOutputStreamFD std = (Runtime.InputOutputStreamFD) rt1.getS TDOutputFD(); 

System.out.println("== Example of how to use Jerl without using the perlVM wrapper =="); 

System.out.println("==== print hi from perl ===="); 

//rt1.start(new String[]{"jerl","-E 'print qq(hi); ' "}); 

// rt1.start(new String[]{"jerl","-m-feature"}); 

// rt1.start(new String[]{"jerl","-h"}); 

// 

String perlProggie = new String( " print qq(hello) ;"); 

perlProggie= "-e {" + perlProggie +"}" ; 

rt1.start( 

new String[]{"jerl","_perl.PL" } ); 

//rt1.start(new String[]{"jerl","C:\\Users\\linqi\\linqi\\tmp\\j erl-7c5d8784a6ff\\jerl-7c5d8784a6ff\\java\\_perl.PL"}); 

rt1.execute(); 


System.out.println("==== show access to IOStream ===="); 

// System.out.println("FD:string-->"+fd.getOutString()+"<--rt1"); 

// System.out.println("STDOut:string-->"+std.getOutString()+"<--rt1"); 






} 

} 



  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：java_jre_jvm_set... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:22





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





java_jre_jvm_setting    2014-8-11 16:47 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：wtee_dos_tee 

 





开通黄钻


java_jre_jvm_setting
 


 .when run java in pure jre, need to set env like following :


jre setting:

::set path=C:\ARC_mqx1635\mqx_jre\bin;C:\Java_JDK\bin;%path%; 

set path=C:\ARC_mqx1635\mqx_jre\bin;%path%; 

REM javac C:\Users\linqi\Desktop\Hello.java 

REM java -cp C:\Users\linqi\Desktop Hello

-

and jdk version must match jre version.
-cp == -classpath 
 
   






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：wtee_dos_tee 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:22





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





wtee_dos_tee    2014-7-2 14:05 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：ls_show_dir_colo... 

 





开通黄钻


wtee_dos_tee
 


 
http://pan.baidu.com/s/1kTE8czd


usage: 
            wtee -?



My favorites  | Sign in 



 
wintee 

Tee command for Windows 
 







 

Project Home Downloads Wiki Issues Source 



Search 




for 



  




FAQ   


Featured, wintee, point2 

Updated Feb 4, 2010 by rsb...@gmail.com 

Frequently Asked Questions

This page contains questions I'm frequently asked about wintee. 

1. How do I use wintee? 

I have tried to maintain the interface in the GNU version of tee within wintee for consistency and familiarity. 

Wintee will take any input from standard input and copy the data to standard out and any files specified on the command line. The most common way for people to use wintee will be to pipe the output of some command into wintee using the "|" operator on the command line. 

For example: 

echo Hello world | wintee output1.txt output2.txt 

would save the text Hello world into files named output1.txt and output2.txt and would also display the text Hello world on the standard output device (most likely the console). This is in fact the way in which I always use wintee as it allows me to see the output of the command being executed and saves a copy of the output for later review. 

There are a couple of command parameters that wintee accepts: 


Parameter 
 
Purpose 
 

a 
 
append to the given file(s), do not overwrite 
 

i 
 
ignore interrupt signals 
 

? 
 
display the help screen and exit 
 

--version 
 
output version information and exit 
 

--help 
 
display the help screen and exit 
 

By default wintee will replace any file specified as a command parameter. To avoid losing any previous contents of the output file(s) use the -a parameter to force wintee to append the output to the end of the files. Currently the append setting is global to all of the files specified, but I can see where a person would want to overwrite one file but append to a different file such as a networked syslog file. 

Specifying the -i command parameter causes wintee to ignore all interrupt signal with the exception of the kill signals which cannot be ignored. This is useful if you have multiple console windows running and you want to avoid accidentally causing a problem by pressing 

<ctrl>

-c. 

The remaining command parameters should be self explanatory. 

2. Why did you write wintee? 

For the past number of years, I've been developing exclusively in Linux for embedded devices. During this time, I became very dependent on the tee command for aiding the debugging of applications, shell scripts and make files. Since I've come to work for Point2 Technologies, all of my development work has been on the Windows platform. As anyone who has ever used the Windows command console for executing command scripts can attest to, the screen buffer can easily be filled prior to the end of a script's execution. Unless a person is redirecting output to a file or other stream, any important messages in the beginning of the script's execution can be lost and can lead to some very difficult to debug issues. The GNU tee application solves this problem by copying standard input messages to both standard output and an arbitrary number of other streams. Unfortunately Windows does not ship with a tee type command, so I decided that I could write one in a very short time. The end result is wintee. 

3. What platforms can I use wintee on? 

I have only run wintee under the command console for Windows XP Home and Professional, but it should run under any 32 bit version of Windows. I haven't tried running wintee on a 64 bit version of Windows, but I'd like to hear from anyone who does so I can update this wiki page with the results. 

I used Borland C++ 5.02 to develop wintee as a console application. That being said, I haven't tried wintee on a true DOS platform, so again, if anyone wants to see if the application will run under a true DOS distribution, I'd like to hear what your results are so I can update this wiki page with the results. 

4. I've found a bug, how do I report it? 

If you find a bug in this application, please report it on the issues page for this project. The issue page can be found here. 

5. I'd really like to have more features/functionality. How do I request that these be added to wintee? 

If there is a feature you feel that wintee is missing, please report it using the issues page for the wintee project. The issue page can be found here. 
 
 

Comment by mdvdl...@gmail.com, Jan 22, 2010 

Greetings, I wanted to let you know that I downloaded wintee and ran it on my Windows 2003 x64 box and it runs nicely. I haven't found any issues so far. Thanks for writing this util. It saves me from reinventing the wheel. Cheers. Mario. 

Comment by jonathan...@gmail.com, Aug 1, 2012 

I also just wanted to say that I ran it on Windows 7, 64bit and it ran with no issues. Thanks so much for this VERY useful little Windows addition! 

Comment by replyto...@hotmail.com, Sep 23, 2012 

1) To install wtee, copy the executable to one of the locations specified in your PATH environment value. 

2) This article is incorrect. The name of the executable is wtee, and not wintee. 

3) There is no illustration of the control parameters. Use nix style commands. For example, dir | wtee -a output.txt 

Cheers, 

Michael LoneWolf? at http://www.MKRD.info/ (www.MKRD.info) 

Comment by tosat...@gmail.com, Oct 9, 2012 

Can some one please tell me how redirect stderr with wtee pls? 

Comment by TheChrisPratt, Nov 5, 2012 

Sure, use this on the command line: 

dir 2>&1 | wtee dir.txt 

(Chris) 

Comment by ammukuma...@gmail.com, Nov 20, 2012 

I've tried this for 64 bit and it worked fantastic. Thanks i was looking for this long time. 

Comment by xFinr...@gmail.com, Feb 5, 2013 

Windows 8 x64 seems to work fine with this. 

Thank you kindly! 

Comment by wubb...@gmail.com, Apr 3, 2013 

Thank You gave me nice functionality 

Comment by minerd...@gmail.com, May 28, 2013 

Unable to run wtee in a path with spaces and uable to output to log file with spaces. When added double quotes to both wtee path and log file path the cmd window flashes and the log file never gets any output. It does work of the bat file path is in double quotes. I.e. "C:\test spaces\test.bat" 2>&1 | "C:\test spaces\wtee.exe" "C:\test spaces\output.log" 

Comment by RonMille...@gmail.com, Dec 2, 2013 

I ran this on win 8.1 x64. As far as I can tell it does not work, or else I am not sure how I am supposed to use it. 

For example, after running the "wtee.exe", where am I actually supposed to type the commands. In the "wtee" window that pops up if I type anything it simply echos it back to me. If the .exe is running and I type in a shell "echo Hello world | wintee output1.txt output2.txt" I get the message: 

'wtee' is not recognized as an internal or external command, operable program or batch file. 

Not sure if it is the environment or tester error on my part, thanks. 

Comment by jackwrig...@gmail.com, Dec 3, 2013 

Thanks for the useful utility. We've been ussing in it a batch file to catch&log the console output like this: 

echo Executing scripts in SysStart?... call %~dp0\Tools\ExecuteAlphabetically?.cmd %~dp0\SysStart? | %~dp0\Tools\wtee -a %~dp0\SysStart?.log 

but here's a slight problem with it, though. After ExecuteAlphabetically?.cmd has finished executing scripts from the directory SysStart? the console prompt never returns. Piping with wtee keeps the console open forever and it is not possible to write more commands in the same batch file to do something else afterwards. 

\Tools\ExecuteAlphabetically?.cmd is as simple like this: ---start--- for /f %%x in ('dir /b /on %1\.cmd') do call %1\%%x ---end--- 

Would be nice if there was a way to signal to wtee.exe that it shoud terminate now (maybe through echoing a special sequience of escape characters to stdout or something) and do not keep waiting for input from that pipe forever, so the call returns and the file SysStart?.log and the console will be eventually closed. Thanks! 

Comment by eloiseta...@gmail.com, Jan 2, 2014 

"exit /b" in the batch file, and calling "test.bat | wtee.exe logfile.log" worked for me :) (@jackwrig) 

Comment by kenny.c...@seagate.com, Jan 28, 2014 

It works! finally found this useful DOS tool. I used it on Windows7 64-bit pro. Thank you so much. 

 

? Sign in to add a comment 







Terms - Privacy - Project Hosting Help 

Powered by Google Project Hosting 

 
  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：ls_show_dir_colo... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:23





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





ls_show_dir_color    2014-6-18 20:10 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：SNPS_BCLUB_summa... 

 





开通黄钻


ls_show_dir_color
 


1 cp /etc/DIR_COLORS ./.dircolors
2. add it in .bashrc; 

# enable color support of ls and also add handy aliases
if [ -x /usr/bin/dircolors ]; then
            test -r ~/.dircolors && eval "$(dircolors -b ~/.dircolors)" || eval "$(dircolors -b)"
                alias ls='ls --color=auto'
                    #alias dir='dir --color=auto'
                        #alias vdir='vdir --color=auto'

                            alias grep='grep --color=auto'
                                alias fgrep='fgrep --color=auto'
                                    alias egrep='egrep --color=auto'
                            fi

3. change .dircolors : .dir 01:34 -> 01:36 ; 

4. source .bashrc  
  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：SNPS_BCLUB_summa... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:23





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





call_back_function_in_C    2014-6-5 17:42 阅读(5)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：MW_IDE_Perl_DOS_... 

 





开通黄钻


call_back_function_in_C
 


 
作者：陈玉鸣 
出处：http://www.cnblogs.com/chenyuming507950417/ 
本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。


回调函数

（1）概念：回调函数，顾名思义，就是使用者自己定义一个函数，使用者自己实现这个函数的程序内容，然后把这个函数作为参数传入别人（或系统）的函数中，由别人（或系统）的函数在运行时来调用的函数。函数是你实现的，但由别人（或系统）的函数在运行时通过参数传递的方式调用，这就是所谓的回调函数。简单来说，就是由别人的函数运行期间来回调你实现的函数。



/*

how to implement a cb procedure

*/

#include <stdio.h>
 

//declare a cb ; 

typedef void (*cb)(int id_p0); 
 

//implement id_cb ; 

void id_cb(int id_p0){

printf("this is id_cb(%d) \n",id_p0); 

}
 

//implement Frm()

void Frm(cb id_cb, int id_p0){

id_cb(id_p0); 

}
 

void main(){

int id_p0=9999; 

Frm(id_cb, id_p0); 

}



 

（2）标准Hello World程序：

int main(int argc,char* argv[])
{
printf("Hello World!\n");
return 0;
}

      将它修改成函数回调样式：


复制代码
//定义回调函数
void PrintfText() 
{
printf("Hello World!\n");
}

//定义实现回调函数的"调用函数"
void CallPrintfText(void (*callfuct)())
{
callfuct();
}

//在main函数中实现函数回调
int main(int argc,char* argv[])
{
CallPrintfText(PrintfText);
return 0;
}
复制代码

      修改成带参的回调样式：


复制代码
//定义带参回调函数
void PrintfText(char* s) 
{
printf(s);
}

//定义实现带参回调函数的"调用函数"
void CallPrintfText(void (*callfuct)(char*),char* s)
{
callfuct(s);
}

//在main函数中实现带参的函数回调
int main(int argc,char* argv[])
{
CallPrintfText(PrintfText,"Hello World!\n");
return 0;
}
复制代码

      至此，对回调函数应该有了一个大致的了解。

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：MW_IDE_Perl_DOS_... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:23


CAE_Elliot_ell_的头像
CAE_Elliot_ell_
2015年4月





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





MW_IDE_Perl_DOS_SHELL_Notes    2014-5-25 20:36 阅读(2)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：perl_smartmatch_... 

 





开通黄钻


MW_IDE_Perl_DOS_SHELL_Notes
 


 ①ctrl+shift+R　open Resource :like .c





②File->switch workspace 




③cygwin clr --ctrl + L 




④ mcc link.cmd -g -Xtimer0 -arcv2em main.c interrupt.s -o main.out -m > main.map  ----How to compile in Cygwin?

⑤vim C++ color highlight 




 cp /usr/share/vim/vimXX/vimrc_example.vim ~/.vimrc ----

OR 


cp test.c $HOME/test5.c

⑥ ctrl+r , redo; 




 ⑦ 小数点，重复上一次操作，

⑧ shift + v, 块选；

⑨ from system clipboard to  vim: shift + Insert ; 

 ⑩







Haifeng Han (haifeng) is a new user and will need to run

ssh arcdev1      :ssh linqi@arcdev1

---p4_  ---

p4 sync

p4 edit filename.txt  ; set file as open permission ; 

vim fn.txt 

p4 opened  ; #view which file can opened ; 

p4 revert  ;  revert edit permisson ; 

p4 help sync  : p4 help detail ; 

p4 diff fn.txt   # compare depot and local ; 

-
http://url.cn/RZcWPN  Linux p4 CONFIG
http://url.cn/RZcWPN p4 operate





//dwarc/Tools/nsim/2013.03/...<SPACE>//linqi/nsim201303/...

把shell类型换成bash


p4 -p p4p-`/usr/local/bin/siteid`:1900 passwd


p4 -p p4p-`/usr/local/bin/siteid`:1900 login -a

before being able to access the depot.
You should also set your P4PORT to:
export P4PORT="p4p-`/usr/local/bin/siteid`:1900" (sh/ksh/bash)

p4 client




CPUe^含有微指令集

磁柱是分割槽的最小单位 ；

主要分割与延伸分割最多可以有四笔(硬碟的限制)

cd - : --回到上一级Parent

cp -r Music Music2 ---copy dir

rm -ri Music2 -----delete a dir with prompt; 
信号量 与 互斥量 －－－获得与释放的线程不一样

临界区－－－本进程可获取

stdin-0 stdout-1 stderr-2  redirection：

ls *.h *.txt 1>stdout.txt 2>stderr.txt   ;  2>&1 :




bc into bash-computer and set scale=3 -> 1/3=.333;

man date --- with [/or?]STRING to search certain STRING

ls -X ---sort by extension name  

sort -k2n -u  ccac.c  : field2 sort in unique

---

#define DECLARE_TWO(A,B,_count) \

static int A[_count];  \

static int B[_count]; 

-

info ls ---detail of commands , with '?' to  know how to keyshorts

nano test.c ----vim test.c

gcc -E test.c -o test.i  ---test.i Preprocess course

have inital data and static --- save in .data segment while not inital in .bss 

---objdump ---

objdump -s -j .data jidor_elf.elf




objdump -h a.out

view variables segment : objdump -s -d a.out>txt.txt &&vim txt.txt

objcopy -j .text jidor.elf onlytext.elf 

objdump -h onlytext.elf 

---elfdump---

elfdump -th *.elf ; 

elfdump -z *.elf ; 




set variables segments(only global static )---__attribute__((section("mySEG"))) int global_int=0x42;




static int x=0--not inital , in .bss or if =1 in .data

vim: yy copy whole line

readelf -h a.out ---can get little_endian info;

readelf -t example.elf  -> get  sym-table, and it's addr , depicted in link_cmd.lcf file;

[ 4] .text

       PROGBITS 00000220 000094 000b32 01 0 0 16

--- link_cmd.lcf ---

MEMORY

{

    VTABLE: ORIGIN = 0x00000000 LENGTH = 0x200  #(WR)

    ICCM: ORIGIN = 0x00000200 LENGTH = 64K - 0x200

    ICCM_ROM: ORIGIN = 0x00010000 LENGTH = 63K

    ICCM_OVR: ORIGIN = 0x0001FC00 LENGTH = 1K

    DCCM: ORIGIN = 0x80000000 LENGTH = 32K

    DCCM_ROM: ORIGIN = 0x80008000 LENGTH = 31K

    DCCM_OVR: ORIGIN = 0x8000FC00 LENGTH = 1K

}



SECTIONS

{

    GROUP: {

                .vectors: {}

            } > VTABLE



    GROUP: {

                *(TEXT) ALIGN(4) : {}

                *(LIT) ALIGN(4) : {}

            } > ICCM



    GROUP: {

                .sdata? ALIGN(4) : {}

                .sbss? ALIGN(4) : { * {.sbss} }

                _SDA_BASE_=SIZEOF(.sdata)+SIZEOF(.sbss)<= 255?ADDR(.sdata):ADDR(.sdata)+256;

                *(DATA) ALIGN(4) : {}

                *(BSS) ALIGN(4) : {}

                .stack ALIGN (4) SIZE(DEFINED _STACKSIZE?_STACKSIZE:4096): {}

                .heap? ALIGN (4) SIZE(DEFINED _HEAPSIZE?_HEAPSIZE:0): {}

            } > DCCM

}

---

readelf -sh jidor_ccac.elf |grep myFunName : get func and it's size; 

chmod ugo ---chmod u=wrx o=x txt.txt;

!ch - - - press UP can get implement "chmod" + history ->Enter is good

x : if you can cd to the dir|| w : delete files;

more test.c and Space --- less can use page and down ; 

vim  sigil ". " may used to insert a space between chars.




--- tar_ ---

tar -cjf txt.tar.bz2 txt.txt --- j :bzip2 ,c: create; 

tar -xfv txt.tar.bz2  -C /tmp       --- x : extract and get all files -> /tmp;

tar -tvf dir.tar -- view tar files :f must put end ;

tar xfv dw_sensor_ip_subsystem_v1.1.0 : on server : 

unzip mdbissue.zip -d tmpdir4/ ;   extract .zip file ; 

？　－－－echo $? ,0 ,cmd is successful; 







read -a array_a  ;  -- echo "${array_a[1]} ; 

for i in `seq 0 ${#array_a[@]}`

do

        echo "ok"

done

read TLQ  ; | waitting for inputting: if "tlqtangok is good"

delete from left : #(##) --- etc: echo ${TLQ#*ok i} -> "s good"

.~/.bashrc---set personal env;

cat >newtxt.txt <txt.txt---create new txt.txt and input; 

cat -s txt.txt ;  ignore space line

cut -f 2 txt.txt  ;  get field=2  ;

cut -f1-2 txt.txt ;  

split -b 1G -d movie.rmvb movie_  ;  split file into 1G each ; 

cat txt.txt |tee -a txt.txt     ;  stdout && > to file; 




ls | grep -n 'txt' --- grep txt from cmd display include the line number;

grep -n '^g.*g' txt.txt --- start ,g and end with g; 

-

at -f cp_win7_sh.sh now +11min ; 定时jobs ; 

-


－－－－－src obj OK－－－－－－


.phony: clean




cfiles=$(wildcard src/*.c)

notdir=$(notdir $(cfiles))

# dirname /home/txt.txt  OR  basename /home/txt.txt

-

cd `dirname \`find_by_name relbuild.sh\``   cd to dirname

-


obj=$(notdir:.c=.o)

ofiles=$(addprefix obj/,$(obj))


?obj:=$(patsubst src/%.c,obj/%.o,$(src))







exe.exe:$(ofiles)

gcc -o $@ $^

obj/%.o:src/%.c

gcc -o $@ -c $^




clean : 

rm -rf obj/*.* *.exe;

－－－－－－－－－－－－－

wildcard -通配符；

patsubst -替换；

addprefix - 前缀；







var1=$(ls) ,echo $(var1)




－－－－Makefile 中　mkdir -------

optimaze for code ; 

-O equates to -O6

peripherals (volatile data) can be mapped to a non-cacheable region

---ccac makefile---

all:p_test_hss.elf




p_test_hss.elf:p_test_hss.o

        ccac -av2hs -o "$@" "$<"




p_test_hss.o:p_test_hss.c

        mkdir dep;  # create .u depency files in dep/ Dir;

        ccac -av2hs -o "$@" -Humake -Hdepend="dep" -c -g "$<"

clean:

        rm -rf *.elf *.o dep/*.* *.u






--- Compile HS in ccac_--- 

S1: > ccac -arcv2hs -o ccac.o -c ccac.cpp : get obj for Linker; 

S2: > ccac -arcv2hs -o ccac.elf ccac.o : get .elf

S3: > mdb -arcv2hs -cl -run ccac.elf : Run the .elf in mdb ; 

---mdb_ debug---

---ssi macro to exit:

cond_macro show_ssi pc_exit_addr

evalq $i=pc

while($i != $pc_exit_addr){evalq $i=pc; ssi;}

endm




restart

run

evalq $pc_exit_addr=pc




restart

log log

show_ssi $pc_exit_addr

log off











mdb> ssi sso isi iso  

        /r ssi 4 ;  

fillmem 0x-FillValue 0x-From 0x-size; 

fillmem $1 $2 $3

mem $2 

prop use_aux=0x0004,aux_0x0004 : gives AUX a name; 

eval aux_0x0004

evaluate $put_bank_reg(1,3,0)  : change addr 3 with value 0

evaluate $read_byte(0x1000)  :read from memory in byte ; 

evalq $mem_nu=0x8888;

eval *(long*)$mem_nu=0x20_20_10_10  , byte = unsiged int ; 




memory main; 




memset 0x55(addr_start)  0x03(set value) 512(size of byte)

/c mems 0x12 0x10000 22 ; search pattern 0x12 from 0x10000, size 22; 

module --> get each segments, .txt .what?




emem 0x99 0x2222 ( set 0x99 with value 0x2222, then show them)

read stat32.txt  ; P366

---interrupt---

evaluate stat = stat | 0xC000000 // Enable interrupts

evaluate tctl0=3 ; 

evaluate timr0=tlim0




timer 0 is vector 3 with address 3*8 or 0x18

break 5*8 

break address, exec command

run 

evaluate timr0=tlim0




macro m_name p1 p2 p3

$p1

endm

unmacro m_name




display f1/main  ; mem f1/main

evalq $x=9 ;  evalq $x++ ; eval $x; 

eval $i =9; 

while ($i) { print ok; evalq $i -= 1;}

{if($y==1) then print it is 1; }




mdb>{reg r0; reg r1;}

eval $read_byte(0x09)   - read 1 byte from mem;  $read_short; 

$write_byte(addr, value)  and $write_short ; 

return : cause debugger to return from current function; 




ccac -av2hs -g -o ccac.elf ccac.c  ;  compile ->build

mdb -av2hs -cl -run ccac.elf

mdb> run |break main(func)

mdb> step |stepi |stepo 




mdb> mem | mem 0x0a 

mdb> register | reg | aux 0x04 

mdb> modules -->>.text, .data, .bss




-grep="long long" globals

/r isi 5  : repeat for 5 times ; 

/n1 mem pc : show number line 1; 




c: http://url.cn/Ny6Tha  addr alignment align







---ARCv2 disassembly ---

st_s %r0,[%sp,16]

ld_s

b_s

bl_s fun - in stack the fun ; 

j_s ：return from the call

sub_s %sp,%sp,3

add_s

-

mov  ld st 

bl printf

sub add 

st.aw %blink,[%sp,-24]

cmp %r0

cmp_s %r0,11

bne_s 

ld.ab %blink,[%sp,20]

.cfa_offset {r3, r2, r1}, -12 




---ARC c/c++ ref---

struct my_stru{

int i; 

int j; 

int k; 

}stru_0={.j=99, .k=88}; 

int arr_a[20]={[5...8]=6}; 

in main: 

int k= stru_0.k; 

C99 case 'A'...'Z': {do; break; }










---END mdb debug---

---ccac -S -Hanno--- assembly and source code

ccac -Hanno -S test.c   +++=>  test.s , 




make -f hello.mak





DIR=name name2

all:$(DIR)

$(DIR):

mkdir $@




---main.c and f1.c --- must *.c not *.cpp---

//main.c

extern void f1();

int main(int n, char ** v) {

 f1();

 return 0;

}

//f1.c

#include "stdio.h"

void f1() {

 printf("=== f1() ===\n");

}




----------------------------------

---grep---

cat * |grep -v "README\|readme" ;  v －versely 反向；

ls | grep 's[123]' |xargs rm -rf　　－－　Pass params to rm

rm `ls|grep 's[123]'` : rm in condition; 




make --f=mkf.file

---gcc_ g++---

gen map :  gcc test.cpp -Wl,-Map,testgcc.map  

gcc -MM main.c -get dependence file ;

gcc -c foo.c bar.c  && ar crs libfoo.a foo.o - get libfoo.a with ar binulitls;

gcc -o main.exe -L.    main.c  -lfoo  : order of .c and lib_files;

ar x libc.a ----- Extract files to *.o ; 

ar t | ar d --- table and delete *.o ; 





---Libs name---

aom : automatic overlay manager  ;

crt : C Runtime 

angeltim1 : Xtime0 ; 

libcct.a meteware c++ compiler libs

libstlex : exception ; 

libhlt.a : hostlink lib ; 

libfpud.a : double float unit; 

libmwcl.a : mw compactLib; 

---




in order to cygwin with arcdev4:

I need: ssh  lftp; 

---

hcac : compiler C/C++ for arc series ： From C--> .o && .out Files




hcac.exe -arc600 -g -Hnocopyr -o hello.o -c hello.c  ｜№：

hcac       -arc600 -o hello.out hello.o 

mdb -a6 -run hello.out

- Simplify:  

hcac -o a.o -c a.c

hcac -o a.out a.o

mdb -run a.out




 Another way to implement this:

----

mcc -o a.elf a.c   ||  mcc -arcv2em -o main.out  main.c  

mdb -run a.elf

----




－－

DIR1 DIR2 DIR3:

        $(MAKE) -C $@ all GCC=$(GCC)  : change the DIR_path before make; 




Host Timer used for real time system;

--------


sc_clock clock1("clock1", 20, 0.5, 2, true);

This declaration will create a clock object named clock with a period of 20 time

units, a duty cycle of 50%, the first edge will occur at 2 time units, and the first

value will be true.

vim comment change color:

cd && vim .vimrc  add highlight comment ctermfg=6 / green;

---vim_ substitute:---

comment:      :%s/^[^I ]\+/#/g   ;   %s/^[^I ]\{1,}/#/g   ; 

vim regex vs Perl regex ; 

sub e.g. :  %g/^$/d; 

                %s/\(.*\)$/\1/g    ; 
格式化全文： gg=G
serial op:    




%s/^[\t ]\+//g|%g/^$/d   => gg=G ; 



use perldo in vim :

perldo s/^\s+//g ; 




--endvim_

autocomplete: ctrl + N and Ctrl +X   --Vim

Eclipse : Ctrl + Shift + /  --- can comment a BLOCK;

---module---

use :  module list   to get all the server app;  then which vcs??

sc_bv< 256> data5;   data5.to_string(SC_HEX) --　Hex for viewing

module available architect; 

module unload architect ; 

module load architect/2014.03 : to do this, set the shell ENV; 




module would affect ENV like : LM_LICENSE_FILE & SNPSLMD_LICENSE_FILE ; 

---




---mount command---

export ABCD =`sudo mount -t vboxsf share share`

>sudo mkdir share

>$ABCD

>sudo umount share




--- ssh access server and download ---




-

ssh RSA gen pub key:  http://url.cn/O7s7AW
ssh log and keygen



. 







local> ssh-keygen -t rsa ; [ENTER][ENTER]..

local> ssh-copy-id -i ~/.ssh/id_rsa.pub jd@two.linuxlearn.net [enter p:tlq~~ok]

local> ssh jd@two.linuxlearn.net 

server>; 

OK

-










in ~/.ssh DIR:

ssh-keygen -t dsa --->get id_dsa and ~.pub; 

->  scp -r ~.pub  a:~/ ; mv to ~/.ssh   : recrusively ; 

-> mv ~.pub to authorized_keys

-> at last, save id_dsa and id_dsa.pub to local ~/.ssh/  ; 

---end ssh ---

server @ int : typeface and keyboard mapping

courier 14 , deleteKey: escape sequence; 




du -ch nSIM | grep "total"


beta test - customer ; 




clipboard from system to VIM: ctrl+shift+V

OR:      mouse select and in system , middle key mouse




－－－

Perforce server operation:

need .bashrc ,to add P4CLIENT=linqi

>p4 client , edit the vim FILE, 

add the tail like this:   

//dwarc/nsim/src/... //linqi/...

then: 

>p4 sync

--mount VBOXaddition.iso failed, solve: eject vboxaddition,and re-add addition.


---My ENV List---

win7 - /mnt/share_c/.../linqi/    which has txt.txt

cpwin7:  alias cpwin7 txt.txt to HOME

mount_Share_c : alias , mount Share_c

umount_Share_c

apt: 

   apt-install: alias , apt-get install

stn +2 : alias , shutdown in 2min   

CREATE symbol link for gmake:

ln -s /usr/bin/make　/usr/bin/gmake

diff t1 and t2:  vimdiff txt1 and txt2;




under Ubuntu g++: 

g++ test.cpp

---test.cpp---


#include <stdio.h>

#include <iostream>

using namespace std;

int  main(){

cout<<"Hello world from cout"<<endl;

printf("Hello world from printf\n");

return 0;

}//---END---




find ../ -name '*.c' : find_ all the file in a dir;

under Linux, gcc include file loc:/usr/include/c++/4.6 e.g. <iostream> usin...




ESC==0x1B; 

---

typedef char *pstr; 

pstr id_pstr; 

typedef char LINE[88]; 

LINE text;  

text[0]='A'; 

printf("%s\n",text); 







-

---

Event was traggled by user, while the MSG is sent by the SYSTEM.




---Link script---

Right: 

MEMORY {




RAM: ORIGIN = 0x0 LENGTH = 1M

}

GROUP SIZE(100K):{




*(TEXT) : {}

* (LIT) :{}

} =0x1111 > RAM 

If not fill , then fill with 0x1111; 

_TIMER_GET  --- _lr ( 0x21 );

---

timer AUX

if (countup==0) {

        _SR(0, AUX_TIMER_CONTROL); /* don't enable interrupts */

        _SR(TIMER_WRAP, AUX_TIMER_LIMIT);

        _SR(0, AUX_TIMER_COUNT);

    } else {

        _SR(REG_CONTROL_IE_BIT|REG_CONTROL_NH_BIT, AUX_TIMER_CONTROL);

        _SR(TIMER_WRAP, AUX_TIMER_LIMIT);

        _SR(countup, AUX_TIMER_COUNT);

    }

---Interrupt---

void _Interrupt _timer_isr(void){

counter ++ ; 

}

volatile uint_64 counter; 

    _int_install_isr(VECTOR_TIMER, (isrfunc)_timer_isr);

    _int_set_priority(VECTOR_TIMER, 0);

    _timer_initialize(TIMER_COUNTUP_VALUE);

read couter every time...

---Timer Go!!!---

---dos_ ---

systeminfo|findstr /i memory     ; DOS get memory ; 

findstr /RI "go[a-z]o" txt.txt  :Regex in dos ; 

dos set var: ls > txt.txt&&set /p var=<txt.txt&& del txt.txt  ; 

doskey ll= dir /B  ; set alias in dos  ;

dir /O-E ;   # by Extension , sort the files in dir ; 

MS-DOS search --

in nautilus File DIR > dir /s *.c  , get all the .c file recursively ; 

DOS find: type hellojava.java| find /I "Hello"  

-

rmdir /s /q pic  ;  delete all files and dir in pic ; 

pushd C:\ARC ;   ->  c:\ARC> ;   then %cd% = c:\ARC ; 

popd == cd - ; 

%1 = @ARGV[0]  in  perl ; 

%~dp[0-N]  is @ARGV[0] root0:\root1\root2  ; 




-

dos 并行；

@echo off

echo Starting bat1

start "" "bat1.bat"

echo Starting bat2

@echo off

start "" "..\arch_bat\HS234_base.bat"

-










cygwin 环境下 运行MS-DOS cmd.exe : 


  > cmd /C go0  , go0.bat is windows batch file , help cmd ; 

> $echo "obase=16; ibase=16; 111+222"|bc   bc set 16进制；





raspberry ip : arc -a ; 








---Perl_ Learning--- 





perl bclub_(\@,\@)  http://url.cn/PjGu1m ;

perl example http://url.cn/RlHusP ;

http://url.cn/MPxUg4  : perl cmp_ver_0_1 

-


@hash{c}||='vc';  #%hash key not exist, then add into

say %hash;  #print hash

@hash=%hash;

say "@hash";   #a va b vb...

-


---perl ref example ---

return [$_0,\%hash];  #ret of  ret_2_arg()

};

my $_0=ret_2_arg();


my($_1,$_2)=@$_0;

say $_1;

say %$_2;
-
$_0++, $_1++;

-

qx(perldoc -t -f $_) ;  avoid \oxff; 

-

$_="0 1 2 3 4 5 6 ";

my @arr= (split ) [2..5];

@arr_2=@arr[2..5]; 

@arr[0..1]=("help", "me");  #insert into@arr , two e; 

-

perl reference---

my @arr=(

        [1,2,3],

        [0,4,7],

        [5,6,8],

);

say "@arr"; #say reference ADDR;

map{

say @$_ if ref $_;

}@arr;

my( $arr_0,$arr_1,$arr_2)=@arr; 

say @$arr_2; 

-




---perl STDERR---

my @perl_cml=qw(perl bak.perl.PL);

open STDERR, ">",'/dev/null';

system(@perl_cml);

close STDERR;

-

@arr=grep {$_%2}@arr; 

open FP, '<', '_perl.PL';

@arr=grep {m/abc/}<FP>; 

-

cat _perl.PL | perl -e ' @arr =<>; print @arr ; '; 

-

perl format: 

s/\W/ /g;

s/\s+/ /g;

-

use Carp; 

carp $_;     2 at _perl.PL line 11 ; 

perl substitute: $mystring =~ s/abc/ABC/g; 

perl chdir($dirname); 

mkdir -p dirname , not prompt ; 

perl  printf("%.2f",$num); 

my ($firststr,@_2th_arr)= @_;  two arguments ; 

my $perlp=@ENV{"perlp"};    Paren; 

=pod

...

=cut 

1.if (){} elsif(){};

2.sub_fun($a,@array_a); 

3.=pod ~~~ =cut; 

4.if((defined(@ARGV[0]) && defined(ARGV[1])); 

5.open IN, '<', "$files";

@all_files=<IN>;

close(IN); 

-

1.windows path delimiter is ' \ ' ; 

2. perl chmod 0755 != shell chmod 0755; 

> chmod -R 0755 test/  ;   -R , Recrusively ; 

3. select(undef,undef,undef,0.05) , appropriate sleep time; 

4.perl sometimes can't '\' ,correct ?

5.if ( !-e $file_name) Capitial is the same.

6. grep(!m/ARC7/ && !m/em/\d/, @cmp_file);

perl , `ls`  vs system('ls') system ==Real time return ; 

do 'perlname.PL' == system ('perl perlname.PL'); 

" perl  _perl.PL dir0 dir1 " ; 

system("$cmd_perl","$arg_file","$DIR_0","$DIR_1");

open FP, '|-', 'date';

my $datecmd=<FP>;

-

($_1,$_2) = ($_2,$_1); # exchange to $vars

push @arr_head, @arr_tail; # can coalesce 2 @

@removed=splice @arr_ori,1,2,qw(2 3 4);

@array = sort @array ; # not change ori

@array = (); # clear up an arr;

-

chomp(@array); #chomp each e;

perl sub_routine , can be any place;

my ($_) =@arr ; # get first @array[0];

@ARGV[0]='perl.txt'; my @arr=<> or carp "carp w: $!"; # <> can read

@ARGV[0..N];

use autodie; # in open ... or die , leave out or...

-

select FP; select STDOUT; #use FP as stdout ;

delete @hash{book_idx}; # only delete %hash e;

metachar '.' in Regex /s can match anychar;

\w will match ' _ ';

\R match Unix and Windows CR;

-

\s +=newline;

\N = ' . ' with m/matchstr/s any words include \n;

m/match/x ; # /x ignore space ;

m/match$/m ; m = multi ;

\B not boundary , antonym to \b;

-

my %hash=(); @hash{e}=undef; \

exists $hash{e} && say "exists "; \

defined $hash{e} && say "defined"; # find if exists a key;

$_ = "@arr " ; 

-

m/(?<lable_1>) (\k<lable>) /x -> @+{lable_1}; # add lable to $1,$2;

+? *? {1,5}? # not greedy version of Regex;




-

 cat txt.txt |perl -e '@arr=<>; $_="@arr";$i=0; while( m/(?<L1>(twarn\( (.*?) \)[^,]) )/gsx) {$i++; push @arr_out,@+{L1} ; print "$i:\t@+{L1}\n\n";} ; ;'

::not greedy try capture all the () multimatch; 

-

 perl -p -i.bak -e "s/hash/HASH/g" txt*.txt ; # perl cmd line mode ;

perl naked block: my $_0; {my $_0; };

last = break; next = continue; -> LB less big ;

-

$_=""this is \n my god's frind"; \

my @arr= split ; # = split /\s+/s if $_ only multi-space as delimiter;

perldoc CGI ; #perl help of .pm;

if(-e 'file.txt' && -w _) ; # " _" is new visit filename;

my @arr=<*.PL *.txt>; # get file list; 

-
perl file exist: 

my $file_name='file.txt'; 

if ( ! (-e $file_name && -e $file_name2)  ) {

say "not exist"; exit; 

}



---

my our local ; 

my=local , our =public ; 


---

2 @arr as param.

#!perl


use feature qw(say);


sub fun {

my($_1,$_2) = @_;




say "@$_1", " -----", "@$_2"; 
# also: my @arr=keys %$hash1; 

# fun(\%hash1, \%hash2); 

# say %hash;  









};


@test_str=qw("test" "str");

@test_arr=qw(2 3 4 5 6);

fun(\@test_str,\@test_arr);

---





perl sleep 0.25s

select(undef,undef,undef,0.25);




perl array combine into one:

@array_all=(@array_1,@array_2); 

%hash_new = (%hash_1,%hash_2); 

or 

push @array_1,@array_2;

===show all file in a dir===

#perl _perl.PL *.c >txt.c 

#!perl

use 5.010_001;

$param_1=@ARGV[0];

$_=1;

@arr=();

while($param_1 ne ''){

say "------$param_1------";

$lsout=`cat $param_1`;

say $lsout;


$param_1=@ARGV[$_];

 $_=$_+1;

};

say "EOF";

===




|| && 不可{ }连用；

#---perl cmp---

open OUT, ">diff.html";

print OUT "<style type='text/css'>\n", diff_css(), "</style>\n";

print OUT diff_files('p_0903/System/ARCv2HS CCT/this.axml', 'p_0904/System/ARCv2HS CCT/this.axml');


close OUT;


#END ---

CPAN 自动安装模块命令

perl -MCPAN -e "shell"

cpan> install Text::Diff::FormattedHTML; 

#---BEGIN---END---


BEGIN{

 say "begin---";

 $var1=9999999;

}





END{

 say "end---";


}




die "exit when END{} run ---"; 

##---


my @files=<.* *>;

say @files;

##---

chomp($_=<fp>); #no space <fp>

##---read file from fp

chomp(@lines=<fp>);

say @lines;

say reverse <fp>; #reverse a <fp>

##

#--------constant------

use constant NICE_VALUE => 10;

say NICE_VALUE;

#----------------------

use List::Util qw(first sum max shuffle maxstr);

@getshuffled=shuffle @give;

#----------------------

use POSIX qw(nice strftime);

my $today = strftime('%Y-%m-%d',localtime());

say $today; # 2013-12-27

-

@array = (2.2222222, 1.10000000000000,3.888455455);

map{ $_=sprintf("%.3f",$_) ;} @array ;  #四舍五入；

#END---

#----------------------

sub map{

$a=$_;

$_=$a**2;

return ;

};

@array = (2, 1.1,3);

grep{ &map ;} @array ;

say "@array";

#END --------

#--grep{} @array : change @array-------

@array =qw (12 5 7 6 47 44 );

grep { $_+=1 } @array;

## in grep , use $_ , but don't change, then @array not change;

say "@array";


$a=@array[2];

say $a;

#END --------

#----------------------

## qw( a 11) 与 （11, 33.44) ;  

@arr=( 6.12 , 6.08333 );

$_=@arr[0]-@arr[1];

say ;

@arr=qw( 6.12       6.08333 );

&println();

$_=@arr[0]-@arr[1];

say ;

#END --------

#----------------------Hash Split---

%hash=(

a=>_1a,

b=>_1b,

c=>_1c);

@key_ac=qw{

a

c

b

};

#or @key_ac=(a,            c    );

@arrayHash=@hash{@key_ac};

say "@arrayHash";

#END --------

#----------------------

&println();

@array = qw (abc 3 a4 dfksjfd );

my $str=sprintf ("%s", "@array" );


say $str;

@array = split / /, $str;

say @array;


#END --------

#----------------------

&println();

@array = qw (1,2, 3,4);

my $str=sprintf ("%s", "@array" );

$_=$str;

chomp;

s/\s*,\s*/,/g;

@array = split / /;

say ( @array[3] );


#END --------

#----------------------

&println();

$SIG{'INT'}='my_int_handler';

sub my_int_handler{

say "do clean up()";

exit();

};

#-

-Matrix

$a_2d=[

        [1,2],

        [3,4],

        [5,6]];


say "$a_2d->[1][1]";




-opendir

opendir (fp_c, "../linqi");

local @dots=readdir(fp_c);

for (@dots){

say $_;

}

$n1=77_22.009_008;




-time in Perl; 

#!/usr/bin/perl

#print "this is perl program!\n";

use 5.010;

#open File and its properity:

open (fp_c, "txt_xx.txt");

$sz=-s fp_c;

#say $sz;

$mTime=(stat(fp_c))[9];

#say $mTime;

say localtime($mTime);

 sub DateFormat

{

  local @A =@_; #YYYYDDMMHHMMSS

  return sprintf("%04s-%02s-%02s %02s:%02s:%02s",$A[5]+1900,$A[4]+1,$A[3],$A[2],$A[1],$A[0]);

}


my $fileTime=DateFormat(localtime($mTime));

say $fileTime;




-

open (fp,">txt_xx.txt") or die "not open txt.txt";

print (fp "here is the string\n");

-




－regex

~~ 智能匹配

1.$result~~ @arr , result in arr;

2.$result ~~ %hashT, $result in Keys HashT;

3.$result ~~/[a-z]/

if(my @arr=split /\s+/, $_ ) {

say "@arr";

my $_=join ":",@arr;

print $_;


}




if(my @arr=split /\s+/, $_ ) {

print "@arr";

}




#!/usr/bin/perl

#print "this is perl program!\n";

use 5.010;


while(<>){

        chomp;

last if($_ eq "q"||$_ eq "exit" ||$_ eq "n"||$_ eq ":w") ;


$spase_="\\s+";

if( / \A(?<L1>[A-Z]{2}) (\s+)

        (?<L2>\d{4}) (\s+)

        \g{L1} ($spase_)

        (?<L3>Male|Female|male|female) (\s*) /x ){


say "find the 1st: $+{L1}, 2st: $+{L2}, 3st: $+{gender}" ;

}

else {

say "your miss the match!\n";

}



}

-

{    \A : Front of line;

     \z: End of line; 

     \btxt\b  word txt word;

      

#!perl

use 5.010_001;

sub println{

say "\n---------------------";

}



#----------------------


#1 . ~~ for match

$name = "helloworld.txt";

println();


$_=$name;


if( m| \.txt \z |ix ){ #后缀.txt

say "your match:\n{PRE:${^PREMATCH}} <

${^MATCH}> {POST:${^POSTMATCH}}";

}




$_=$name;

say "match: ${^MATCH}" if( m| \.txt \z |ix );

say "match: ${^MATCH}" if( $name ~~ m| \.txt \z |ix );

%hashT=(

1=>11,

2=>22);

say "OK" if %hashT ~~ /22/ ;

say "OK" if %hashT ~~ %hashT2 ;

say "$ARGV[0]";  # perl _perl.txt arg0

$_=$date_d=` date `;

print ": ${^MATCH}" if ( m| \b20\d{2}\b |x) ;

#----------------------

#----------------------

$_=$ARGV[0];

given ($_){

when (1) {say 1; break;};

when (2) {say 2; break;};

default {say "default";};


}

#END --------

#----------------------

println();

@lsArr=`ls -al`;

@lsArrrwx=qw();

foreach (@lsArr){

if( m| ^d[-rwx\+]{10} |x){

local $i;

$_=my $ma=${^MATCH};

@lsArrrwx[$i++]=$ma;

};

say "@lsArrrwx";

}

#END --------

-

my %hash_=(

        a => "b",

        c => "d"

);

my @arr=keys %hash_;

print "@arr";

foreach (sort keys %hash_){

        print "$_ => $hash_{$_}\n";

}




-

#!/usr/bin/perl

#print "this is perl program!\n";

open F_OPEN ,'< txt1.txt';   ==> 单引号；

while(<F_OPEN>){

 chomp;

 if ($_){

printf "$_"."end\n";

 }#end if($_);

}


close F_OPEN;

-




@n1=("4","5");

$ans=@n1[0]*@n1[1];

print ( "ans is $ans\n, $#n1 " );

-

foreach (0..3){

print $_." " ;

}

-

$n_pop=pop (@n1);

print (@n1,$n_pop);

-

---

---Python Learning---





-python get the line and split with ','-

table=[];

for line in open("txt","r"):

 line=' '.join(line.split());

 line_e=line.split(' ');

 table.append(line_e);

print table;

print ("this is %s" %(table[1][1]));

-







tuple is only readable .

-python raw_input-

yourname=raw_input("input your name: ");

print ("your name is %s ), % yourname ); 

-




while(b>0):



print a;

a-=1;

if statement---

if(a<0) 

  print a;

else: 

   print b; 




for statement:

name =['a',"ab","abc"]

for i in name:

     print i; 




function def:

#py.py 

def fun(n):

      "this this the __doc__ of fun"

      print "fun()";

      return n+9;

print fun(222);

print fun.__doc__;

functon call:

1.from py1 import fun  : in py1.py , we have def fun(n): ...

#py.py

f=open("fout.txt","wb");

print>>f , "hello, world to fout.txt"; 




-my_list.append(my_dict);- list append dict ;

---End Python---




---mcc -c prime.c : -> prime.o  , mcc -o : -> prime.out

---.bat Files---

mcc -batX?

@if errorlevel 1 goto Lable_Error




:Label_Error

@echo "this is a Lable_Error "

-Xspfp  : single precision float point.

-Xbs : barrel shift; 

-Xll64 : enable 64-bit load/store Instruction;

-Hkeep : keeps the Object Files; 




sizeac analyze.o : x+x+x+xx= total_xx; 










---Nautilus---

sometimes nautilus go0 can't work, because of the COF of mdb,

tackle method: mdb nautilus.elf, change the target to nsim>>>




ssh login server:    ssh -Y linqi@arcdev4, test '-Y' by > ' xeyes' in virtualBox

in Int/, can login in ARChitectHS: 

> ssh -X linqi@arcdev4  ; 


 use: alias ssh_arc4 = 'ssh -X linqi@arcdev4' ; 

> ARChitectHS




---vim substitute 替换---

:s/-/^M-/g   , '-' -> '- '+ ENTER ;  while ^M = ctrl+ v & ctrl+m; 




MSS_ : Memory Subsystem.

get server hardWare configuration: > cat /etc/motd/

---qsub---

qsub -P bnormal -o output_txt.txt txt.txt  ; 

qstat -u linqi 

---

Shell in any HOME-DIR: cd ~haifeng   ; 

ctrl+ K , got the reference of the function; 

---

how to run latest ARChitect on the sever?

1. set $ARCHITECT_ROOT to ~~/ARChitect/

2. Add PATH with $ARCHITECT_ROOT/bin/linux; 

3. #module load architect; 

4. ssh -X linqi@arcdev4 ; 

---

IP核分为软核（Soft Cores）、硬核（Hard Cores）和固核（Firm Cores）三种。

软核为能综合的HDL描述，硬核为芯片版图，固核为门级HDL描述

SoC设计分为IP核提供者和SoC集成者

IP核可复用：

１可配置；２不同工艺，不同综合脚本，适应新工艺；３多平台仿真，有Verilog，也有VHDL；

A->U->T : Application -> Utilities -> Terminal ; 

---

.bat set variables: 

set var1=ARC

:: set a variables

dir /D c:\%var1% 

---.bat check variable

@ECHO off

set var1=abc

echo %var1%

set var1=abc2

echo %var1%

pause

---




in vim : ^M is CTRL +V then CTRL+M, DOS Feature; 

shell FIFO pipe:

---master.sh

fifo=/tmp/tmpmaster.txt

rm -f $fifo

mkfifo $fifo


while :

do

printf "input your cmds: \n"

read my

printf "`date` $my " > $fifo

done

---client.sh

fifo=/tmp/tmpmaster.txt


while :

do

read cmd args < $fifo 2>/dev/null

if [ ! -z $cmd ]; then

echo " $cmd : $args "

sleep 1

fi

done

rm -f $fifo

-







echo -n , " some string"

echo -e "this is a line,and ENTER! \n\n"; 




or : printf "\n my string \n" 







---shell_  script ---




-

md5sum perl.PL ;   35f16d8c50f133ea8fe79a31048204bf perl.PL

-

perl regex , shell grep: $out_str=`cat txt.txt|grep -P "\\d" ` 

cat -<<EOF>txt.txt

>1

>2

>EOF

-

---return arr_a

declare -a arr_a

arr_a=( a1 a2 a3 4 a5 )


function fun(){

declare -a arr_b

i=0

for v in "$@"

do

        arr_b[i]=${v}_

        ((i++))

done

echo "${arr_b[@]}"

}


declare -a T_a


T_a=(`fun "${arr_a[@]}" `)

printf "${T_a[1]}"

-

for i in ${arr_a[@]}

do

        printf "$i"

done




((i++))

.ini: 

CFG=`dirname $0`/CFG.ini

[ -f $CFG ] && . $CFG

echo "$int_a"

-

var1=

[ -z $var1 ] && printf " \n-z "




pass space : echo My Document |xargs -0 ls   

timeout -s 15 3 ./test.sh  ;   3 s  send signal=15 to *.sh




if [[ "$arch_version" =~ "13" ]] || [[ "$arch_version" =~ "09" ]] ; then
        arch_version=$v0;

printf "$1\n";

printf "$2\n";

if [ "$1" = "myhelp" ] || [ "$2" = "" ] ; then

        printf "help\n";

fi

---shell function---

function func(){




for i in $*   # this is params list 

do

        printf "$i\n"

done

printf "$* \n"; 

array_a=(1 2 3 4 5 6)

echo `shuf -e ${array_a[@]} `

}


echo " this is : `func` "

func 1 2 a3 a4 




function f1(){

param1=$@;

#echo "$param1"

p1=$1

p2=$2

p3=$3

echo "$p1";

};


# --- main () ---

f1 p1 p2 p3





---count file number---

ls |grep '^p_' |wc -l

grep -n '^g.*g' txt.txt --- start ,g and end with g; 

---#include---

#include <stdio.h>

#include <stdlib.h>

#include "hss.hss"

extern void f1(int i);

extern void f2(int i);

extern void f_h(int i);

-

while ---hss.hss---

#include "stdio.h"

#include "stdlib.h"

void f_h(int i);

void f1(int i);

void f2(int i); 

---Detect memory leak:
set ENV :export MALLOC_TRACE=$HOME/m_trace_txt#include <mcheck.h>int main(){mtrace() ;// some malloc() statement ; muntrace(); }gcc -g test.c ~/m_trace_txt
---

on server:

valgrind --tool=memcheck ./jidor_ccac.elf

valgrind  --log-file=log.txt  jidor_ccac.elf




---stack Frame in call---

http://user.qzone.qq.com/2589079022/blog/1396341707 

main()

    |__ fun()

        |__in_fun()

before fun() call in_fun(), fun() would do:

1. 将返回地址放入栈底；

２. 保存fun() 中可见的参数push to STACK,left -> right，include :

    _params; 

    local_fun_i; 

３. load in_fun(_param) to %r0 , then CALL ; 




--- C++11 ---

---override---

not virtual, if add override keyword, show compiler error!

-

-for_each & lambda; 

#include<iostream>

#include<cstdio>

#include<thread>

#include<atomic>

#include<algorithm>

using namespace std;

int main(){

        inta[4]{1,2,3,4};

        autototal=0;

        for_each(a,a+4,[&](int i){

                        total+=i;

                        });

        cout<<total<<endl;

        return0;


}

...

deep copy:

#include <iostream>

#include <cstdio>

using namespace std;

class A{

public:

        int *x;

int y=1;

A():x(new int(y)){};

         A(const A& A_):x(new int(A_.y)){};

~A(){delete x;};

};

int main(){

A id_A0;

A id_A1(id_A0);

return 0;

}




---

auto a=fun(float x); 

int a=9;  decltype(a) b=99; 

for(auto &a: arr){

cout<<a; 

if(a==4) break; 

}; 

c++11 template<---

-

http://url.cn/K8rNbJ multi-thread examples 0f c11

-

template<class T_0,class T_1>

auto fun(T_0 t_0,T_1 t_1)->decltype(t_0+t_1)

{

        return t_0+t_1;

}

-

Constructor call a Constructor: 

class A{

        public:

                int x;

                int y;

        public:

                A(int x_,int y_):x(x_),y(y_){};

                A():A(3,4){};

};


int main(int _n, char ** _v){

A id_A=A(44,55);

A id_A_2=A();

cout << id_A.x<<endl<<id_A_2.x<<endl;

return 0;

}

---nullptr---

void fun(char * ptr){

ptr==nullptr && cout<<"ptr is nullptr\n";

};

-

---enum---

template<class T> struct A { enum E: T; }; 

 template<class T> enum A<T>::E: T { e1, e2 }; 

 A<int>::E e = A<int>::e1;

-

class A{

        public:

        enum{red, yellow,black};

        int x=red;

        int y=yellow;

};

enum Enums: unsigned char{

var0, var1=99

};

int a=Enums::var1; 

-

auto g_c=UR"(*????)";


        while(*g_c)

                printf("%c ",*g_c++);

-

---template---

template<class Int,class ...A> void f(Int int_,A ...args){

cout<< int_<<endl;

};

int main(int n_,char ** v_){ 

f(1);

f(9,3);

f(9,9,8);

return 0;

}

-

lambda expression---

int fun(int i){

int fun_a=9;

//i++;

[&,fun_a,i]{      // [=] value , not ref; 

//i++;

//fun_a++;

cout<<i<<endl;

int ret_cod=fun_a; 

return ret_cod; 

}();

//cout<<ret_code<<endl;

cout<<i<<endl ;

cout<< "ret_code " <<endl ;

return 1;

};

auto functest=[](int i){cout<<"here is lambda test \n"<<i<<endl; };

functest(544);

－

right angle brackets---

template<int> struct X{};

template<class T>struct Y{};

Y<X<1>> id_Y0;

Y<X<(1>>2)>> id_Y1; if not paren, error ; 

-

Rvalue references

class A{}; 
const A source_const_rvalue();
 const A& source_const_ref();

 const A&& source_const_rvalue_ref();

-
--- VCS guide---

get *.v  , then compile:

#---

#--- how to compile and simulator an Verilog file---

all:target.simv


target.simv:Gen_Clock.v xor.v xor_tb.v

# vcs -o $@ $^

        vcs -o $@ $^ -debug

clean:

        rm -rf *.simv *.daidir *.key

#---

run with -gui : watch waves ; 

./*.simv -gui 

example:  http://url.cn/L8tugr ;


---ARCtest ---

before that in build/ , need to run

a. Make install

b. Make designware_libraries

 > make compile 

then : ARCtest -iss -test=1-10

           ARCtest -test=1-10; 

-


2014-05-25



  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：perl_smartmatch_... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:23





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





perl_smartmatch_implement    2014-5-25 15:57 阅读(1)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：ssh_keygen_login... 

 





开通黄钻


perl_smartmatch_implement
 


 sub e_in_arr($\@){
my($e,$addr_arr)=@_;
my @arr=@$addr_arr;
map{return 1 if $_==$e ;}@arr;
return 0;
}

if e_in_arr($arr_loc[$loc_i] , @arr_t); 
  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：ssh_keygen_login... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:23





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





ssh_keygen_login_alias_HostName    2014-5-25 13:35 阅读(8)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：permutation_exte... 

 





开通黄钻


ssh_keygen_login_alias_HostName
 








-

ssh RSA gen pub key:  http://url.cn/Ivj2Xy







local> ssh-keygen -t rsa ; [ENTER][ENTER]..

local> ssh-copy-id -i ~/.ssh/id_rsa.pub jd@two.linuxlearn.net [enter p:tlq~~ok]

local> ssh jd@two.linuxlearn.net 

server>; 

OK

-

### .ssh/config ###
Host jd
Hostname one.linuxlearn.net
User jd
Port 22
CheckHostIP no
Compression yes
ForwardAgent yes
#ForwardX11 yes
#ForwardX11Trusted yes

host jd2

  user jd

  hostname one.linuxlearn.net

  port 22

  identityfile ~/.ssh/id_rsa




  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：permutation_exte... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:23





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





permutation_extention_Perl    2014-5-23 12:04 阅读(14)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：linux p4 config 

 





开通黄钻


permutation_extention_Perl
 






#> perl _perl.PL 2>/dev/null 

#!perl

use feature qw(say);

#--- TEST ---


my $loc_i=0;

my $MAX=4; # the num you want to make the

my @arr_loc=qw(0 0 0 0);


#---start permutation


for(@arr_loc[$loc_i]=0;@arr_loc[$loc_i]<$MAX; @arr_loc[$loc_i]++){

        next if $arr_loc[$loc_i] ~~ @arr_loc[0..$loc_i-1];

        $loc_i++; #---











        for(@arr_loc[$loc_i]=0;@arr_loc[$loc_i]<$MAX; @arr_loc[$loc_i]++){

                next if $arr_loc[$loc_i] ~~ @arr_loc[0..$loc_i-1];

                $loc_i++; #---

                for(@arr_loc[$loc_i]=0;@arr_loc[$loc_i]<$MAX; @arr_loc[$loc_i]++){

                        next if $arr_loc[$loc_i] ~~ @arr_loc[0..$loc_i-1];

                        $loc_i++;



                        for(@arr_loc[$loc_i]=0;@arr_loc[$loc_i]<$MAX; @arr_loc[$loc_i]++){

                                next if $arr_loc[$loc_i] ~~ @arr_loc[0..$loc_i-1];



                                say @arr_loc ;

                        }#end for $k




                        $loc_i--; 

                }#end for $j

                $loc_i--; #---

        }#end for $i













        $loc_i--; #---

}#end for $i


#---end permutation











###-Usage-: $ time  perl _perl.PL 2>/dev/null ###
#!perl
use feature qw(say);

### CONFIG AREA ###
if ( @ARGV == 0 ){
die "- please input num\n";
}
my $MAX = @ARGV[0];
####### END #######

my @a=qw();
my $len_a=$MAX*2-1;
my $file_header='
#!perl
use feature qw(say);
#--- TEST ---
my $loc_i=0;
my $MAX='."$MAX".'; # the num you want to make the
my @arr_loc=qw();
#---start permutation
';
my $for_header='for(@arr_loc[$loc_i]=0;@arr_loc[$loc_i]<$MAX; @arr_loc[$loc_i]++){      next if $arr_loc[$loc_i] ~~ @arr_loc[0..$loc_i-1];       $loc_i++;       #---;
'x ($MAX-1);




my $say_kernel='     for(@arr_loc[$loc_i]=0;@arr_loc[$loc_i]<$MAX; @arr_loc[$loc_i]++){ next if $arr_loc[$loc_i] ~~ @arr_loc[0..$loc_i-1]; say @arr_loc ;  }#end
' ;

#=pod
 my $say_kernel='     for(@arr_loc[$loc_i]=0;@arr_loc[$loc_i]<$MAX; @arr_loc[$loc_i]++){ next if $arr_loc[$loc_i] ~~ @arr_loc[0..$loc_i-1];  ;  }#end
' ;
#=cut

my $for_tail='$loc_i--;      }    #end for
' x ($MAX-1) ;


open FP, '>', "bak.perl.PL";
select FP;
say "$file_header","$for_header\n","$say_kernel\n","$for_tail";
close FP;
select STDOUT;

my @perl_cml=qw(perl bak.perl.PL);
open STDERR, ">",'/dev/null';


system(@perl_cml);

close STDERR;
`rm bak.perl.PL`;

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：linux p4 config 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:23





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





linux p4 config    2014-5-20 11:07 阅读(2)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：perl_learning_ob... 

 





开通黄钻


linux p4 config
 


 
 Perforce 官网：
http://www.perforce.com/perforce/doc.current/manuals/p4guide/chapter.configuration.html#DB5-24024
  
http://www.perforce.com/perforce/doc.current/manuals/p4guide/chapter.usingp4.html
  

linux下使用P4（命令行）

分类： Linux工具2009-11-27 18:00 6680人阅读 评论(0) 收藏 举报

linuxperforce虚拟机工作branchvmware

 环境变量:
export P4PASSWD=abcdefg
export P4CLIENT=dyoldfish.com    //这个是workspce
export P4USER=dyoldfish
export P4PORT=192.168.1.198:1666

 

命令：
1、p4 client  #配置本地信息，文件下载在哪里在这里面配置，Root项
2、p4 sync   #从perforce 下载文件
3、p4 login  #登陆perforce 
4、p4 help   #显示关于命令的帮助
5、p4 -h     #显示关于p4的帮助
6、 p4  labels  ...   #显示和这个目录相关的标签 
7、p4 sync @dyoldfish_label #同步标签dyoldfish_label中的所有文件
8、p4 files @dyoldfish_label  #查看标签dyoldfish_label所包含的文件列表
9、p4 revert     #回复所有打开的文件
10、p4 revert -n ... #回复所有打开却没提交的文件
11、p4 branch dyoldfish_brach   #新建分支
12、p4 integrate -b   dyoldfish_brach   #合并分支dyoldfish_brach中描述的文件
13、p4 opened  #查看打开的文件
14、p4 help commands  #查看p4所有命令的帮助
15、p4  dirs  -H .   #显示当前目录
16、p4 branches    #显示所有的分支 
17、 p4 delete  filename   #从p4删除文件 
18、p4 changelists -L ...   #显示当前目录下面所有文件的修改注释
19、p4 label dyoldfish_label   #新建标签 dyoldfish_label，编辑标签
20、p4 tag -l dyoldfish_label ... #把当前目录下面的所有文件添加到标签 dyoldfish_label
21、p4 changes ...   #当前目录的changelist
22、 p4 sync @10931     #sync file @changelist
23、 p4 sync ...@10929  #only sync  localfile@changelist
24、p4 help revisions    #查看关于文件范围的帮助

25、p4 edit filename  对文件进行编辑，相当于图形界面中的check out

 

所以我们经常用到就是同步 p4 sync

编辑， p4 edit；然后提交 p4 submit -d "description" filename or dir；当然在提交之前最好看一下哪些文件被check out了，以免误操作，我们可以用p4 opened.

 

p4 unshelve -s 323071是把别人shelve上去的文件弄下来，但不会check out

 

 

 

export好变量之后，然后用1进行配置，就可以用p4 sync进行代码下载了 如p4 sync //depot/proj1/...@21

./p4 sync //XMS/SS7_Mainline/HMCallAnalyzer/java/com/empirix/hm/realtime/commandbar/...（目录）

./p4 sync //XMS/SS7_Mainline/HMCallAnalyzer/java/com/empirix/hm/realtime/commandbar（文件）

如果commandbar是目录则后面要加上/...，如果是文件的话就不用

 

 

 

在虚拟机上使用p4

 

一共分为如下几步：

1.     要在Linux上用P4，就需要虚拟机能够访问外网

2.     安装及配置P4

3.     配置源代码环境

 

下面具体介绍一下各个步骤：（我称我们的工作机本身为“主机”）

1.     配置虚拟机访问外部网络。设置步骤如下

1）共享主机网卡

本地连接 -》 属性 -》高级 -》选择允许其它网络通过本...，并选择家庭网络连接为 VMware Network Adapter VMnet1

2）设置虚拟机IP信息

选择Traditional ….

3）设置静态IP

IP     192.168.0. xxx

Subnet mask 255.255.255.0

DNS        192.168.0.1（编辑/etc/reslove.conf）

Default Gateway  192.168.0.1

2.     安装及配置P4

1)     下载客户端http://www.perforce.com/perforce/downloads/index.html 我使用的是The Perforce Command-Line Client (P4)

2)     把客户端放在文件夹 /usr/local/bin 。这样能在任何目录直接使用p4命令

3)     配置客户端，在线帮助有很多种方式，我使用配置文件方式。步骤如下

a.     在/usr下面新建一个文件夹p4config (可以自定义)，在文件夹里面新建文件p4.configfile.

b.     用VI打卡p4.configfile,输入如下配置

 

P4CLIENT=（定义你的工作空间，比如ygxu_xms）

P4PASSWD=（你的密码）

P4PORT=10.12.33.133:1700

P4USER=（你的用户名）

 

保存退出。

c.      配置环境变量。修改后需要重启这个才生效

用vi打开 /etc/profile，末尾处加入

 

#

# pv4 config file path

#

if test -z "$P4CONFIG" ; then

        export P4CONFIG=/usr/p4config/p4.configfile

fi

 

d.     测试环境配置是否成功

命令 p4 info，如果显示了连接信息，则OK，否则会提示连接不上

 

3.     配置源代码环境

使用命令 p4 client会有如下信息显示

 

Client:  你上面配置的工作空间

Update: 2010/01/19 20:38:36

Access: 2010/01/21 02:57:38

Owner:   你的用户名

Host:   linux

Description:

        Created by ygxu.

Root:   /home/hammer

Options:        noallwrite noclobber nocompress unlocked nomodtime normdir

SubmitOptions:  submitunchanged

LineEnd:        local

View:

       ….

        //XMS/SS7_Mainline/... //Arthur_Xms/XMS/SS7_Mainline/...

       ….

 

两个地方需要修改：

a . Root .这个决定你的代码会放在什么地方，如上，我的是/home/hammer

b. View.这个决定你需要取哪些代码下来，因为一般不会把全部代码取下来，在Linux上我们一般只需要XMS的SS7_Mainline,所以把其他的删掉，修改成上面这个样子

      

      注意事项，一定要保证空间足够，建议先删掉原来的SS7_Mainline，使用Shrink工具回收空间之后再取代码。

      好了，使用p4 sync命令吧，就可以继续工作了！

      关于p4的使用命令，文档如下：

http://www.perforce.com/perforce/technical.html



  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：perl_learning_ob... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:24





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





perl_learning_obfuscation    2014-5-16 16:31 阅读(1)   



赞

评论(1)
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：multi_thread_2_e... 

 





开通黄钻


perl_learning_obfuscation
 


($_1,$_2) = ($_2,$_1);  # exchange to $vars 
push @arr_head, @arr_tail;  # can coalesce 2 @
@removed=splice @arr_ori,1,2,qw(2 3 4); 
@array = sort @array ;  # not change ori
@array = ();  # clear up an arr; 
-
chomp(@array); #chomp each e; 
perl sub_routine , can be any place; 
my ($_) =@arr ;  # get first @array[0]; 
@ARGV[0]='perl.txt'; my @arr=<> or carp "carp w: $!";    # <> can read 

@ARGV[0..N]; 
use autodie;   # in open ... or die , leave out or...
-
select FP; select STDOUT;  #use FP as stdout ; 
delete @hash{book_idx};  # only delete %hash e; 
metachar '.' in Regex  /s can match anychar; 
\w will match ' _ '; 
\R match Unix and Windows CR; 
-
\s +=newline; 
\N =  ' . ' with  m/matchstr/s  any words include \n; 
m/match/x  ;  # /x ignore space ; 
m/match$/m ; m = multi ; 
\B not boundary , antonym to \b; 
-
my %hash=(); @hash{e}=undef; \
exists $hash{e} && say "exists "; \
defined $hash{e} && say "defined";  # find if exists a key; 
-
m/(?<lable_1>) (\k<lable>) /x  -> @+{lable_1}; # add lable to $1,$2; 
+? *? {1,5}?  # not greedy version of Regex; 
 perl -p -i.bak -e  "s/hash/HASH/g" txt*.txt ;  # perl cmd line mode ; 
perl naked block: my $_0;   {my $_0; }; 
last = break; next = continue;  -> LB less big ; 
-
$_=""this is                       \n my god's frind"; \
my @arr= split ;  # = split /\s+/s if $_ only multi-space as delimiter; 
perldoc CGI  ;   #perl help of .pm; 
if(-e  'file.txt' && -w _) ; #  " _"  is new visit filename; 
my @arr=<*.PL *.txt>;   # get file list; 

 

 

 

 

 

 

 

 

 


#--- PAGE 2 ---
use Carp; use feature qw(say);
my @arr=<*.PL *.txt>; 
say "@arr\n"; 



  






赞

评论(1)
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：multi_thread_2_e... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:24





评论(1)


显示评论签名









jd_jidor@qq.com_jidor_ 
jd_jidor@qq.com_jidor_




1楼 评论时间: 2014-05-16 16:33:16

回复







perl obfuscate  








































上一页 1  下一页 
转到 页 确 定









发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   












 




日志


返回日志列表 





multi_thread_2_example    2014-4-28 16:44 阅读(3)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：perl_show_all_fi... 

 





开通黄钻


multi_thread_2_example
 


 #include<iostream>
#include<cstdio>
#include <pthread.h>
using namespace std;
pthread_mutex_t m=PTHREAD_MUTEX_INITIALIZER;
static long long total=0;
void* fun(void *){
        for(long long i=0;i<0x3;i++){
                pthread_mutex_lock(&m);
                total += i;
                pthread_mutex_unlock(&m);
        }
}
int main(int n_,char ** v_){
        pthread_t id_thread0, id_thread1;
        pthread_create(&id_thread0,NULL,&fun,NULL);
        pthread_create(&id_thread1,NULL,&fun,NULL);
        pthread_join(id_thread0,NULL);
        pthread_join(id_thread1,NULL);
        cout<< total<<endl;
        return 0;
};
//---in C++ new feature:
#include<iostream>
#include<cstdio>
#include <thread>
#include<atomic>
using namespace std;
atomic_llong total{0};
void fun(int ){
        for(int i=0;i<10;i++){
                total+=i;
        }
}
int main(){
        thread id_tr0(fun,0);
        thread id_tr1(fun,0);
        id_tr0.join();
        id_tr1.join();
        cout<< total<<endl;
        return 0; }

 
  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：perl_show_all_fi... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:24


韩海锋_hf_haifeng_的头像
韩海锋_hf_haifeng_
2015年3月





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





perl_show_all_files_contents    2014-4-23 16:29 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：VCS user guide a... 

 





开通黄钻


perl_show_all_files_contents
 


 #!perl
use 5.010_001;
$param_1=@ARGV[0];
$_=1;
@arr=();
while($param_1 ne ''){
say "------$param_1------";
$lsout=`cat $param_1`;
say $lsout;

$param_1=@ARGV[$_];
        $_=$_+1;
};
say "EOF";
linqi@arcdev1:~/perl_p$ cat show_file_content.PL
#!perl
use 5.010_001;
$param_1=@ARGV[0];
$_=1;
@arr=();
while($param_1 ne ''){
say "------$param_1------";
$lsout=`cat $param_1`;
say $lsout;

$param_1=@ARGV[$_];
        $_=$_+1;
};
say "EOF";

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：VCS user guide a... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:24





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





VCS user guide and example of *.v    2014-4-23 16:25 阅读(2)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：Stack_and_Frame_... 

 





开通黄钻


VCS user guide and example of *.v
 





get *.v  , then compile:

#---

#--- how to compile and simulator an Verilog file---

all:target.simv


target.simv:Gen_Clock.v xor.v xor_tb.v

# vcs -o $@ $^

        vcs -o $@ $^ -debug

clean:

        rm -rf *.simv *.daidir *.key

#---

run with -gui : watch waves ; 

./*.simv -gui 

example:  http://url.cn/L8tugr ;



 ------Gen_Clock.v------
// Microelectronics Students' Group
// FEUP/DEEC              Jan/2013
// web:  usgroup.eu
// mail: info@usgroup.eu
`timescale 1ns/10ps

module Gen_Clock (CLK);
        output CLK;
        reg CLK;

        parameter Period = 10; // 100 MHz clock frequency

        initial
                CLK = 0;

        always #(Period/2)
                CLK = ~CLK;
endmodule
 

------xor_tb.v------
// Microelectronics Students' Group
// FEUP/DEEC              Jan/2013
// web:  usgroup.eu
// mail: info@usgroup.eu

`timescale 1ns/10ps
//`define PERIOD 10 // 100 MHz clock frequency

module  xor_tb();
        //wire clk;
        reg rst, en, x1, x2;

        parameter Period = 10; // 100 MHz clock frequency

        Gen_Clock gen_clock(clk);
        xor_ dut(clk,rst,en,x1,x2,y);

        initial
        begin
                rst = 1;
                en = 0;
                x1 = 0;
                x2 = 0;
                #Period;
                rst = 0;
                $display("Reset Done");
                #(Period/2); //initial delay
                Sim(0,0);
                Sim(0,1);
                Sim(1,0);
                Sim(1,1);
                $stop;
        end

        task Sim;
                input x_1, x_2;
                begin
                        x1 = x_1;
                        x2 = x_2;
                        $display("Inputs x1=%d x2=%d",x1, x2);
                        en = 1;
                        #(Period/2);
                        en = 0;
                        #(Period/2);

                        if (y!=(x_1^x_2))
                                $display("ERROR:result: %d should been: %d ",y,(x1^x2));
                        else $display("Correct result: %d ",y);
                end
        endtask
endmodule
 

------xor.v------
// Microelectronics Students' Group
// FEUP/DEEC              Jan/2013
// web:  usgroup.eu
// mail: info@usgroup.eu

`timescale 1ns/10ps

module  xor_(clk,rst,en,x1,x2,y);

input clk, rst, en, x1, x2;
output y;
reg y;

always @(posedge clk)
begin
        if (rst)
                begin
                        y<=0;
                end
        else if (en)
                begin
                        y <= x1 ^ x2;
                end
end
endmodule

//EOF

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：Stack_and_Frame_... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:24





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





Stack_and_Frame_in_function_call    2014-4-1 16:41 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：简单链表list 

 





开通黄钻


Stack_and_Frame_in_function_call
 


int fun(int _p0,int _p1,int _p2);
int in_fun(int _p0);
int main(){
int main_i=11;

fun(1,2,3);


return 0;
}

 

int fun(int _p0,int _p1,int _p2){
int local_fun1=99;
int local_in_fun_ret=in_fun(33);
return 1;
}

int in_fun(int _p0){
int in_fun_i=44;


return 0;
}


--- ccac -S test.c ---
        .option %reg
        .file   "test_c.c"
        .globl  in_fun
        .type   in_fun,@function
        .size   in_fun, .Ltmp0-in_fun
        .globl  fun
        .type   fun,@function
        .size   fun, .Ltmp1-fun
        .globl  main
        .type   main,@function
        .size   main, .Ltmp2-main
        .equ    .CC_I,0
        .global .CC_I
        .ident  "LLVM 3.4/I-2013.12. (LLVM 3.4) -O0 -av2hs -core0 -Mm -Xbs -Xcd -Xnorm -Xsa -Xswap"
        .text
        .align  4
in_fun:                                 ; @in_fun
                                        ; @0x0
        .cfa_bf in_fun
; BB#0:                                 ; %entry
        sub_s   %sp,%sp,8               ; @0x0
        .cfa_push       8               ; @0x2
        st_s    %r0,[%sp,4]             ; @0x2
        mov     %r0,44                  ; @0x4
        st_s    %r0,[%sp,0]             ; @0x8
        mov     %r0,0                   ; @0xa
        add_s   %sp,%sp,8               ; @0xe
        .cfa_pop        8               ; @0x10
        j_s     [%blink]                ; @0x10
        .cfa_ef
.Ltmp0:                                 ; @0x12

        .align  4
fun:                                    ; @fun
                                        ; @0x14
        .cfa_bf fun
; BB#0:                                 ; %entry
        st.aw   %blink,[%sp,-24]        ; @0x14
        .cfa_push       24              ; @0x18
        .cfa_reg_offset {%blink}, 0     ; @0x18
        st_s    %r0,[%sp,20]            ; @0x18
        st_s    %r1,[%sp,16]            ; @0x1a
        st_s    %r2,[%sp,12]            ; @0x1c
        mov     %r0,99                  ; @0x1e
        st_s    %r0,[%sp,8]             ; @0x22
        mov     %r0,33                  ; @0x24
        bl_s    in_fun                  ; @0x28
        st_s    %r0,[%sp,4]             ; @0x2a
        mov     %r0,1                   ; @0x2c
        ld.ab   %blink,[%sp,24]         ; @0x30
        .cfa_restore    {%blink}        ; @0x34
        .cfa_pop        24              ; @0x34
        j_s     [%blink]                ; @0x34
        .cfa_ef
.Ltmp1:                                 ; @0x36

        .align  4
main:                                   ; @main
                                        ; @0x38
        .cfa_bf main
; BB#0:                                 ; %entry
        st.aw   %blink,[%sp,-12]        ; @0x38
        .cfa_push       12              ; @0x3c
        .cfa_reg_offset {%blink}, 0     ; @0x3c
        mov     %r0,0                   ; @0x3c
        st_s    %r0,[%sp,8]             ; @0x40
        mov     %r0,11                  ; @0x42
        st_s    %r0,[%sp,4]             ; @0x46
        mov     %r0,1                   ; @0x48
        mov     %r1,2                   ; @0x4c
        mov     %r2,3                   ; @0x50
        bl_s    fun                     ; @0x54
        mov     %r0,0                   ; @0x56
        ld.ab   %blink,[%sp,12]         ; @0x5a
        .cfa_restore    {%blink}        ; @0x5e
        .cfa_pop        12              ; @0x5e
        j_s     [%blink]                ; @0x5e
        .cfa_ef
.Ltmp2:                                 ; @0x60

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：简单链表list 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:24





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





 简单链表list    2014-3-24 17:30 阅读(2)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：perl_ARChitect2_... 

 





开通黄钻


简单链表list
 


 #include <stdio.h>
#include <stdlib.h>

typedef struct my_ {
 int data;
 struct my_ *next;
} node, *p_node;

int main() {

 p_node head = NULL;
 p_node p;
 p = malloc(sizeof(node));
 p->data = 99;
 head = p;

 p_node tmp_node = malloc(sizeof(node));
 p->next = tmp_node;
 p = p->next;

 int i = 6;
 while (i--) {

  tmp_node = malloc(sizeof(node));
  p->next = tmp_node;
  p = p->next;

 }

 tmp_node = malloc(sizeof(node));
 tmp_node->data = 99;
 p->next = tmp_node;
 p = p->next;

 p = NULL;
 p = head;
 while (p) {
  printf("%d\n", p->data);
  p_node pre = p;
  p = p->next;
  free(pre);

 }

 printf("ok---\n");
 return 0;
}

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：perl_ARChitect2_... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:24





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





perl_ARChitect2_cl_auto_bld_bat    2014-3-17 15:10 阅读(1)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：perl to generate... 

 





开通黄钻


perl_ARChitect2_cl_auto_bld_bat
 


 $ cat ARChitect2_bld_em_700_600.PL
#!perl
use feature qw(say);

@template=qw(
em4_ecc
em4_parity
em4_rtos
em4_sensor
em6_gp

ARC710D
ARC710D_AHB
ARC725D
ARC725D_AHB
ARC750D
ARC750D_AHB
ARC770D
ARC770D_AHB
ARC770D_AXI

625x2
ARC601
ARC601_AHB
ARC605
ARC610D
ARC610D_AHB
ARC625D
ARC625D_AHB
AS210
AS211SFX
AS221BD

);
$ARChitect2_cl='ARChitect2 -cl  -libraries %IP_HOME%\* -projectpath %hs_p%\p_%te                                                                                                              mplate%\  -argument_file C:\ARC\Projects\build_configuration\build_configuration                                                                                                              _%template%.txt -overwrite'."\npause";

sub out_build_bat{
$em_iphome= 'set IP_HOME=C:\Jidor_Software\synopsys\ARC_EM_Series_IP_library\ARC                                                                                                              _EM_IP-Libraries';
$_700_iphome='set IP_HOME=C:\Jidor_Software\synopsys\ARC_700_Series_IP_library\A                                                                                                              RC700_IP-Libraries\ARC700_IP-Libraries';
$_600_iphome='set IP_HOME=C:\Jidor_Software\synopsys\ARC_600_Series_IP_library\A                                                                                                              RC600_IP-Libraries';
$_=@_[0];
my $IP_HOME='';
$fn="$_".'.bat';
my $OUT;
open($OUT,'>',$fn);
say $OUT "set template=$_";
$SET_IP_HOME=$em_iphome   if m/em/;
$SET_IP_HOME=$_700_iphome if m/ARC7/;
$SET_IP_HOME=$_600_iphome if !m/em/ && !m/ARC7/;

say $OUT "$SET_IP_HOME";
say $OUT "$ARChitect2_cl";
close($OUT);

}#---END build_bat---
`mkdir -p arch_bat`;
`rm arch_bat/all_bat.bat`;
open($ALL_BAT_OUT,'>>','all_bat.bat');
say $ALL_BAT_OUT '@echo off';
map{
out_build_bat $_;
say $ALL_BAT_OUT "echo Start $_\.bat ...";
say $ALL_BAT_OUT 'start "" "'.$_.'.bat"'
}@template;
close($ALL_BAT_OUT);
`mv *.bat arch_bat/ `;

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：perl to generate... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:24





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





perl to generate Makefile    2014-2-26 22:30 阅读(3)   



赞

评论(1)
转载
分享(1)

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：Makefile 

 





开通黄钻


perl to generate Makefile
 



### .auto_create_makefile ###
$ cat Makefile
CC = ccac -arcv2hs
c_flag = -g -o
c_files =  \
$(wildcard *.cpp) $(wildcard *.c)
h_files = \
$(wildcard *.hpp) $(wildcard *.h)
o_files_mess = \
$(patsubst %.cpp,%.o,${c_files}) $(patsubst %.c,%.o,${c_files})
o_files = \
$(filter %.o, $(o_files_mess))
elf_file=  \
jidor_ccac.elf

rm_files = \
*.o *.dep *.elf  *.s


all:$(elf_file)

$(elf_file):$(o_files)
        $(CC) $(c_flag) $@ $(o_files)
%.o: %.c $(h_files)
        $(CC) $(c_flag) $@ -c $<
%.o: %.cpp $(h_files)
        $(CC) $(c_flag) $@ -c $<
#       @echo "c_file is:$(c_files)"; echo "h_files:$(h_files)"; echo "o_files:$(o_files)"

clean:
        rm -rf $(rm_files)
### --- ###

 

#!perl
use feature qw(say); 

@file_contents=`cat txt.txt`; 
#perl_c_files
#perl_h_files
$c_files=`ls *.c`;
$h_files=`ls *.h`;
$c_files =~ s/\n/ /g; 
$h_files =~ s/\n/ /g; 
$end_log=' ###---end ---###'; 
map{
chomp; 
 s/perl_c_files/$c_files/g; 
 s/perl_h_files/$h_files/g;
say ;  
}@file_contents;


### --- txt.txt --- ###
CC = ccac -arcv2hs
c_flag = -g -o
c_files =  \
perl_c_files
h_files = \
perl_h_files
o_files = $(patsubst %.c,%.o,${c_files})

elf_file=  \
jidor_ccac.elf

rm_files = \
*.o *.dep *.elf  *.s


all:$(elf_file)

$(elf_file):$(o_files)
 $(CC) $(c_flag) $@ $^
%.o: %.c $(h_files)
 $(CC) $(c_flag) $@ -c $<
clean:
 rm -rf $(rm_files)


  






赞

评论(1)
转载
分享(1)


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：Makefile 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:25





评论(1)


显示评论签名









Jidor 
Jidor 




1楼 评论时间: 2014-02-27 00:36:54

回复










ok  


-----------------------------------
该评论来自手机Qzone 








































上一页 1  下一页 
转到 页 确 定









发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   












 




日志


返回日志列表 





Makefile    2014-2-25 16:59 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：Perl Example 

 





开通黄钻


Makefile
 


 ### makefile of ccac ###
all:p_test_hss.elf

p_test_hss.elf:p_test_hss.o
        ccac -av2hs -o "$@" "$<"
p_test_hss.o:p_test_hss.c
        mkdir dep;
        ccac -av2hs -o "$@" -Humake -Hdepend="dep" -c -g "$<"
clean:
        rm -rf *.elf *.o dep/*.* *.u

### test *.c ###
#include <stdio.h>
#include <stdlib.h>
#include "hss.hss"
extern void f1(int i);
extern void f2(int i);
extern void f_h(int i);


int main(void) {

 f2(2);
 f1(1);

 


 puts("!!!Hello World!!!"); /* prints !!!Hello World!!! */
 return EXIT_SUCCESS;
}

### hss.hss ###
#include "stdio.h"
#include "stdlib.h"
void f_h(int i); 
void f1(int i); 
void f2(int i); 

 

void f1(int i){
 f_h(i); 
 
}


void f2(int i){
 f_h(i); 
 
}


void f_h(int i){
 
printf("=== %d ===\n",i); 
}
### ###
  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：Perl Example 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:25





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





Perl Example    2014-2-25 16:59 阅读(1)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：shell_for_if_mat... 

 





开通黄钻


Perl Example
 



this linker: http://note.youdao.com/share/?id=cc480371e7d15e55491ea58e24d1cd0b&type=note
"Thanks Larry for creating Perl." 



===show all file in a dir===


#perl _perl.PL *.c >txt.c 

#!perl 

use 5.010_001; 

$param_1=@ARGV[0]; 

$_=1; 

@arr=(); 

while($param_1 ne ''){ 

say "------$param_1------"; 

$lsout=`cat $param_1`; 

say $lsout; 



$param_1=@ARGV[$_]; 

 $_=$_+1; 

}; 

say "EOF";

===


#---2013 income and expenditure table---#
 my $file_name="name_keys.txt";
my $totalget=6*7000+3000;
my %outmoney=(
SonyLT22i => 1380,
mi2A=>1500,
Iphone5s => 4293,
bGX =>300,
zhloan=>11200,
bbyun=>4000,
xingGe=>500,
loanoutyang=>1000,
loanoutmother=>1000,
buyCoin=>2000,
MK=>1074,
waist=>490,
suitcase=>610,
GiantBycicle=>690,
raspberry => 280,
eat=>3*30*(8+9)+3*30*(2+2+2),
);
my $sum_out=0;
map{$sum_out+=$_; } values %outmoney;
$leave_should_be=$totalget-$sum_out;
$money_actual=1355+9500+111+700;
$theDiff=$leave_should_be-$money_actual;




say "money_actual is $money_actual";
say "leave_should_be is $leave_should_be  ";
say "theDiff is $theDiff ";

#END --------
say "END-";
close(fp);

###--time-----------------------------E10:

@timeis=localtime();
@timeis[5]+=1900;
@timeis[4]+=1;
say "@timeis[5,4,3]";
###---
#---import Module from Jidor.pm --E9
###_perl.pm###
use Jidor qw(func_1 func_2);
### Jidor.pm ###

package Jidor; 


use 5.010_001;


require Exporter; 
 our @ISA=qw(Exporter); 


our @EXPORT_OK=qw( $var1 $var2); 
our @EXPORT=qw(func_1 func_2); 

use constant NICE_VALUE => 10;
say NICE_VALUE;

sub func_1{
say "hello, func_1"; 
$var1+=9;
}

sub func_2{
say "hello, func_2"; 
$var2+=99;
}

#---

=pod

test file flag 

=cut

#------Shell interface----------E8
$filename='name_date.txt';
-e $filename || say "no exist $filename";

@lss= glob '* .*';
say "@lss";

$file__a1='__a1';
`rm -vrf $file__a1` ~~ m/remove/ && say  "right!" ;

#---

 

#edit all wildcard files--E7:

$> perl _perl name*.txt

$^I='~'; # '.bak'; 
while (<>){
 chomp;
 s/\s+//g;
 $_=$_.'end';
 say ;
}

 

#-Regex --------------E6:

 

$m="here   ?     ismine , an           .      example";
$_=$m;
s/(\W)/ /g;
s/\s+/ /g;
@array = split / / , $_;
say @array[2];

$_= join "*", @array ;
say ;

#---

$m="here ismine an example";
$_=$m;
s/(?<L1>\b\w*mi\w*\b)/\U\1\E/g;
say ;

s/(?<L1>\b\w+\b)/\u\1\E/g; # only the first char into Uppercase; 

 

 

#--Hash ----------------E5:

say if (m| ^D\W{4} |x);  #match special character; 

say  if (m|  v3   |x  && m|  k3 |x) ; 

map{say $+{L1}  if (  m/(?<L1>.*4.*)/x   ) ; } %hash_name;

map{say $+{L1}  if (  m/(?<L1>.*4.*)/x   ) ; } (keys %hash_name); 

@array_values=values %hash_name;

delete  @hash_name{1};

@hash_name{2}=nameN;
if ('nameN' ~~ @array_values ){
say "exist nameN";
};

@keys_env=keys %ENV; 
@values_env = values %ENV; 

my %rev_hash= reverse %hash ;  

##k1 v1
##k2 v2
##k3       V3
##create Hash
while(<fp>){
chomp ; 
s/\s+/ /g;
@line=split / /; 
push @lines, @line; 
};
%hash =();
%hash=@lines;
say @hash{k3};

#----

#---Sub @_------------E4:
sub sum_list{
local @array = @_;
local $sum=0;
grep {$sum+=$_;} @array; 
$sum; 
};

@array =(1..100);
$sum =sum_list(@array);
say "sum is : $sum "; 
#END --------

#------File Operation -----E3:
open (fp, "<", "好.txt");
@lines=( );
@line=();
while(<fp>){
chomp;
push @lines, $_; 
}

#as $_  as the param for <fp> ; 

while(<fp>){
s/\s+/ /g;
@line =split / /,$_;
}; 


close(fp);
#@lines= reverse @lines;
foreach (@lines){
say ;
}

#END --------

 

#-------Array push ---------E2:
#!perl 
use 5.010_001;
#use autodie;
sub println{
say "\n---------------------";
}
&println();
#----------------------
@array =(1,2,3);
@array[-1]=4444;
push @array, (0..10);
$Last_index=$#array;

for (0..$Last_index){
say @array[$_];
}
@array = sort {$a<=>$b ; } @array;  
say "@array "; 

 

grep {my ($k, $v)=each @array ;say "$k,$v";} @array; 
#END --------

 

 

#!perl
use 5.010_001;
#use autodie;
sub println{
say "\n---------------------";
}
&println();
#----------------------E1:
while(<>){
#chomp;

$r_=$_;
if(!($r_ ~~ m/  [a-z]{1,}   /xi)   && ($r_>0) ){

say $r_*2*3.1415926;
}
else {
say "exit()"; exit();
}
}

 

$m=99;
$m!=99 || say "not == 99 ";　　#if - else ,another ; 

$m!=99 or say "not == 99 ";

$m==99 && $m++;

@num=(1..9); # 闭区间；

$ave=0;
map{ $ave+=rand(1)/($#num+1) ;}@num;　#get ave; 

$a= int (rand 2+1);  # to get 01[2] 

#$x='abc';
$a=$x  // "default x";
say $a;

＝pod

comment ; comment  ;comment description ; 

=cut ; 

 use List::Util qw(first sum max shuffle maxstr);
%hash_array=qw(
a 1
b 2
c 3
);
$mysum=sum 0,values %hash_array;
say $mysum;

 


#END --------

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：shell_for_if_mat... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:25





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   











 




日志


返回日志列表 





shell_for_if_match_fun()_lib    2014-2-21 11:26 阅读(0)   



赞

评论
转载
分享

复制地址
收藏夹按钮收藏
更多

上一篇  | 下一篇：vocabunary_2014... 

 





开通黄钻


shell_for_if_match_fun()_lib
 




$ perl_show_all_file_content  *.sh
*********************
test.sh
*********************
. ./test2.sh

run="sh test2.sh"
eval "$run"
printf "\ncall test2.sh->fun()=`fun` \n"
fun ; echo $?
for i in "$@"
do
        printf "$i\n"

done

if [[ "$run" =~ "test" ]] ; then
        printf "match $run: test \n"
fi

*********************
test2.sh
*********************
printf "this is test2.sh"
function fun(){

printf "this is fun() in test2.sh\n"
return 222
}

EOF







 

#--- arch_build.sh ---#

        #export template=HS36
export arch_version=$1
export template=$2

export v0=0904
export v1=1403RC1

if [[ "$arch_version" = "" ]] || [[ "$template" = "" ]] || [[ "$arch_version" =~ "help" ]] || [[ "$template" =~ "help" ]] ; then
        printf " ---help---:\n sh arch.sh arch_version template \n\n";
        exit;
fi
if [[ "$arch_version" =~ "14" ]] || [[ "$arch_version" =~ "RC1" ]] ; then
        arch_version=$v1;
fi

if [[ "$arch_version" =~ "13" ]] || [[ "$arch_version" =~ "09" ]] ; then
        arch_version=$v0;
fi
printf "\n arch_version is :$arch_version\n \
        template is : $template \n";

export v=$arch_version;

export DIR_=${hs_p}/p_${template}

        export DIR_v=${hs_p}/p_${template}_${v}


ARChitect2 -cl \
        -libraries $IP_HOME/ARCv2HS_v1.0/* \
        -projectpath $hs_p/p_$template/ \
        -argument_file $hs_p/build_configuration/build_configuration_$template.txt
mv -f ${DIR_} ${DIR_v}
rm -f a*.log
printf "\nmv to ${DIR_v} finished !\n"
---Shell_script---

  






赞

评论
转载
分享


复制地址
收藏夹按钮收藏
更多

上一篇  下一篇：vocabunary_2014... 


个人日记 |  原创：jd_jidor@qq.com_jidor_  












主人的热评日志
 

perl_web_server_socket2016-10-10 15:23


samba_config2016-10-06 09:17


expect_usage_example2016-08-15 11:52




本文最近访客




















Jidor的头像
Jidor
09:25





评论






还没有人发表评论  来坐第一个沙发













发表评论


提示
















发表


分享此文章

匿名评论(隐身草)
















































   















































   











